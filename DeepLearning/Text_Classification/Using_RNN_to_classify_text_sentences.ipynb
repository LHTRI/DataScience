{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Text Classification_Starter Code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AkEoCKaHdpj"
      },
      "source": [
        "\n",
        "In this notebook, we will try the process of implementing RNN with Keras in order to classify text sentences.\n",
        "\n",
        "I.   **Firstly**, we'll import useful packages.\n",
        "\n",
        "II.   **Then**, we'll load the data and create a word embedding matrix using Glove.\n",
        "\n",
        "III.  **We'll try a simple RNN model** and then we will evaluate its performances.\n",
        "\n",
        "IV. Finally, we'll use techniques to increase our model's accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xY_w9I1cZni"
      },
      "source": [
        "**Task 1:** Setting Fre GPU in this Google Colab notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4iAL0E0ciDS"
      },
      "source": [
        "## Mounting Google Drive locally\n",
        "**Task 2:** Mount the Google Driver into the Google Colab Driver.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8iz8Rp8H5pG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7cbe54-a816-4ddf-e9e2-5da5822cb959"
      },
      "source": [
        "## TYPE YOUR CODE for task 2 here:\n",
        "import os\n",
        "if 'COLAB_GPU' in os.environ:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "else:\n",
        "    print(\"I'm running on JupyterLab\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeAakuO9cD5s"
      },
      "source": [
        "# I. Let import all useful packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no86DwmY2ren"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import datetime\n",
        "import time\n",
        "import subprocess\n",
        "from glob import glob\n",
        "import operator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import Metric\n",
        "import tensorflow.keras.optimizers as Optimizer\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkvCSr4EfM4k",
        "outputId": "efbd174d-2794-4247-fa92-5583491dbdee"
      },
      "source": [
        "if 'COLAB_GPU' in os.environ:\n",
        "    !pip install ipython-autotime\n",
        "else:\n",
        "    print(\"I'm running on JupyterLab\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/58/a4a65efcce5c81a67b6893ade862736de355a3a718af5533d30c991831ce/ipython_autotime-0.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (50.3.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.3.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw_GGfFdfM4l",
        "outputId": "3aed6071-10c4-482e-ea3b-68eb88a00e9b"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%load_ext autotime\n",
        "%load_ext tensorboard\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 5.82 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvFTfBIscRwC"
      },
      "source": [
        "**Task 3**: Copy the dataset from Google Drive into Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzzQsanZIZfg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e93f85a-4ef5-443d-d915-d3462631ba45"
      },
      "source": [
        "## TYPE YOUR CODE for task 3 here:\n",
        "if 'COLAB_GPU' in os.environ:\n",
        "    !cp \"{'/content/gdrive/My Drive/FUNIX_ASM_2/glove.6B.50d.txt.zip'}\"  .\n",
        "    !cp \"{'/content/gdrive/My Drive/FUNIX_ASM_2/train.csv.zip'}\"  .\n",
        "    !unzip -q  glove.6B.50d.txt.zip\n",
        "    !unzip -q  train.csv.zip\n",
        "    !rm glove.6B.50d.txt.zip\n",
        "    !rm  train.csv.zip\n",
        "else:\n",
        "    print(\"I'm running on JupyterLab\")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 20.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_GxFMl7dFJ-"
      },
      "source": [
        "# II. Load the data.\n",
        "\n",
        "## About dataset.\n",
        "An invalid question is defined as a question intended to make a statement rather than look for helpful answers. Some characteristics that can signify that a question is invalid:\n",
        "\n",
        "* Has a non-neutral tone.\n",
        "* Is disparaging or inflammatory.\n",
        "* Isn't grounded in reality.\n",
        "* Uses sexual content (incest, bestiality, pedophilia) for shock value, and not to seek genuine answers\n",
        "\n",
        "The data includes the question that was asked, and whether it was identified as invalid (target = 1). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9HhWwT-gpuN"
      },
      "source": [
        "**Task 4**: Load the dataset.\n",
        "* Load the data from CSV file.\n",
        "* Remove all the rows with NA values.\n",
        "* Split the data into 3 set: Training set, validation set and test set (0.9/0.05/0.05, random_seed = 9) with a same ratio of data number beween each class.\n",
        "* Print out these dataset's description.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9HMbZrqK1Rq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da8f1ebb-7bf2-48f1-f66e-00fc0eb39a98"
      },
      "source": [
        "def load_data(data_link):\n",
        "    '''\n",
        "    input: data link.\n",
        "    output:\n",
        "        train_set, validation_set and test_set(0.90/0.05/0.05) without NA values.\n",
        "    '''\n",
        "    ## TYPE YOUR CODE for task 4 here:\n",
        "    df = pd.read_csv(data_link)\n",
        "    df.dropna(inplace=True)\n",
        "    train, val_test = train_test_split(df, test_size=0.1, random_state=9, stratify=df['target'])\n",
        "    validation, test = train_test_split(val_test, test_size=0.5, random_state=9, stratify=val_test['target'])\n",
        "    return train, validation, test\n",
        "\n",
        "train_set, validation_set, test_set = load_data('train.csv')\n",
        "print(train_set['target'].describe())\n",
        "print(validation_set['target'].describe())\n",
        "print(test_set['target'].describe())\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    1.175509e+06\n",
            "mean     6.187022e-02\n",
            "std      2.409198e-01\n",
            "min      0.000000e+00\n",
            "25%      0.000000e+00\n",
            "50%      0.000000e+00\n",
            "75%      0.000000e+00\n",
            "max      1.000000e+00\n",
            "Name: target, dtype: float64\n",
            "count    65306.000000\n",
            "mean         0.061863\n",
            "std          0.240908\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%          0.000000\n",
            "75%          0.000000\n",
            "max          1.000000\n",
            "Name: target, dtype: float64\n",
            "count    65307.000000\n",
            "mean         0.061877\n",
            "std          0.240934\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%          0.000000\n",
            "75%          0.000000\n",
            "max          1.000000\n",
            "Name: target, dtype: float64\n",
            "time: 3.32 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIcOnRkbqofC"
      },
      "source": [
        "# Encoding text data.\n",
        "Let declare some fundamental parameters first:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F3_zcCjHwzm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd58776f-7f39-43ff-99aa-a2517505d73e"
      },
      "source": [
        "embed_size = 50 # how big is each word vector\n",
        "max_features = 20000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "max_len = 50 # max number of words in a question to use\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.36 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT8m71iixjxt"
      },
      "source": [
        "**Task 5:** Encode the dataset using Tokenizer and one-hot encoding vector.\n",
        "* Encode the text (question_text column) by turning each question text into a list of word indexes using [Tokenizer](https://stackoverflow.com/questions/51956000/what-does-keras-tokenizer-method-exactly-do) with **max_features** and all the text sentences from the training and the validation set. \n",
        "* Turn each list of word indexes into an equal length - **max_len** (with truncation or padding as needed) using [pad_sequences](https://keras.io/preprocessing/sequence/).\n",
        "* Encode the label (label column) using [to_categorical](https://keras.io/utils/) function on Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1MZKNs4xmfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa1e99d-0395-4204-e7a7-12d948154a13"
      },
      "source": [
        "def encoding_textdata(train_set, validation_set, test_set, max_features, max_len):\n",
        "    '''\n",
        "    Input:\n",
        "    - Train/validation/test dataset.\n",
        "    - max_features, max_len.\n",
        "    Output:\n",
        "    - X train/validation/test, y train/validation/test.\n",
        "    - Tokenizer.\n",
        "    '''\n",
        "    ## TYPE YOUR CODE for task 5 here:\n",
        "    \n",
        "    tokenizer = Tokenizer(num_words=max_features, split=' ', filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, oov_token=None)\n",
        "    # Fitting\n",
        "    tokenizer.fit_on_texts(train_set['question_text'])\n",
        "    tokenizer.fit_on_texts(validation_set['question_text'])\n",
        "    \n",
        "    data = [train_set, validation_set, test_set]\n",
        "    X = []\n",
        "    Y = []\n",
        "    for df in data:\n",
        "        x = df['question_text']\n",
        "        x = tokenizer.texts_to_sequences(x)\n",
        "        x = pad_sequences(x, maxlen=max_len, dtype=\"int32\", padding=\"pre\", truncating=\"pre\", value=0)\n",
        "        X.append(x)\n",
        "        y = df['target']\n",
        "        y = to_categorical(y, num_classes=2, dtype=\"float32\")\n",
        "        #y = [i[::-1] for i in y]\n",
        "        #y = np.array(y)\n",
        "        Y.append(y)\n",
        "    \n",
        "    X_tr, X_va, X_te = X\n",
        "    y_tr, y_va, y_te = Y\n",
        "\n",
        "    return  X_tr, X_va, X_te, y_tr, y_va, y_te, tokenizer\n",
        "    \n",
        "X_tr, X_va, X_te, y_tr, y_va, y_te, tokenizer = encoding_textdata(train_set, validation_set, test_set, max_features, max_len)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 40.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kpG-p30WUcc"
      },
      "source": [
        "**Task 6**: Create word embedding matrix.\n",
        "* Firstly, write a function to [load the GloVe dictionary.](https://medium.com/analytics-vidhya/basics-of-using-pre-trained-glove-vectors-in-python-d38905f356db)\n",
        "* Then, create a word embedding matrix using GloVe dictionary with these parameters:\n",
        "    - Word embedding matrix shape: (Number of word, embed_size).\n",
        "    - Embed size: 50.\n",
        "    - Number of words: The minimum of (max_features, len(word_index)), while word_index is the dictionary of word which contains in tokenizer.\n",
        "    - If a word occurs in GloVe dictionary, we should take its initialization value as in GloVe dictionary. Otherwise, take a normal random value with mean and std as mean and std of GloVe dictionary value.\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47s8-SncWT3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cd7835e-37ae-4cc8-a4f1-1f43ece23ab5"
      },
      "source": [
        "\n",
        "def get_coefs(word,*arr): \n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "def get_GloVe_dict(GloVe_link):\n",
        "    '''\n",
        "    input: GloVe link.\n",
        "    output: GloVe dictionary.\n",
        "    '''\n",
        "    ## TYPE YOUR CODE for task 6 here:\n",
        "    GloVe_dict = {}\n",
        "    with open(GloVe_link, 'r', encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            word_vector = np.asarray(values[1:], dtype='float32')\n",
        "            GloVe_dict[word] = word_vector\n",
        "    return GloVe_dict\n",
        "\n",
        "GloVe_link = 'glove.6B.50d.txt'\n",
        "#GloVe_link = 'sample.txt'\n",
        "GloVe_dict = get_GloVe_dict(GloVe_link)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 5.55 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H64SFN4ifM4q",
        "outputId": "14509380-6616-4e07-a169-f0c511ef58c8"
      },
      "source": [
        "# Check size of word vector\n",
        "print(GloVe_dict['the'].shape)\n",
        "GloVe_dict['the']\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
              "       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
              "        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
              "        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
              "       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
              "       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
              "        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
              "        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
              "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
              "        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "stream",
          "text": [
            "time: 4.47 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXRyFSLtr4_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8481f4b-898b-4e57-be19-2669044bd71c"
      },
      "source": [
        "def create_embedding_matrix(wordvector_dict, tokenizer, max_features):\n",
        "    '''\n",
        "    input: GloVe dictionaray, tokenizer from training and validation dataset, number of max features.\n",
        "    output: Word embedding matrix.\n",
        "    '''\n",
        "    \n",
        "    ## TYPE YOUR CODE for task 6 here:\n",
        "    number_words = min(len(wordvector_dict), max_features)\n",
        "    wordvector_embs = np.hstack(wordvector_dict.values())\n",
        "    mean, std = wordvector_embs.mean(), wordvector_embs.std()\n",
        "    embedding_matrix = np.random.normal(mean, std, (number_words, embed_size))\n",
        "    \n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        if i >= number_words:\n",
        "            break\n",
        "        if word in wordvector_dict:\n",
        "            embedding_matrix[i] = wordvector_dict[word]\n",
        "       \n",
        "    return embedding_matrix\n",
        "\n",
        "embedding_matrix = create_embedding_matrix(GloVe_dict, tokenizer, max_features)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time: 356 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW1tw6CbfM4r",
        "outputId": "0daa899b-ac1f-46db-9bdb-9aca97140cfa"
      },
      "source": [
        "# Check result\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "stream",
          "text": [
            "time: 2.09 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWybjdQkqWrg"
      },
      "source": [
        "III. Modelling\n",
        "There are some steps we need to finish:\n",
        "Build the model.\n",
        "\n",
        "Compile the model.\n",
        "\n",
        "Train / fit the data to the model.\n",
        "\n",
        "Evaluate the model on the testing set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6AMfqQkqcET"
      },
      "source": [
        "## Build the model\n",
        "**Task 7:** We can build an easy model composed of different layers such as:\n",
        "* [Embedding](https://keras.io/layers/embeddings/) layer with max_features, embed_size and embedding_matrix.\n",
        "* [Bidirectional LSTM layer](https://keras.io/examples/imdb_bidirectional_lstm/) with number of hidden state = 50, dropout_rate = 0.1 and recurrent_dropout_rate = 0.1.\n",
        "* GlobalMaxPool1D.\n",
        "* Dense with number of unit = 50, activation = 'relu'.\n",
        "* Dropout with rate = 0.1.\n",
        "* Final dense with number of unit = number of class, activation = 'sigmoid'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7_eizWaqi_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4361457c-e661-4e75-8c78-3c1a7789b705"
      },
      "source": [
        "def create_model(max_len, max_features, embed_size, embedding_matrix):\n",
        "    '''\n",
        "    input: max_len, max_features, embed_size\n",
        "    output: model.\n",
        "    '''\n",
        "    ## TYPE YOUR CODE for task 7 here:\n",
        "    input_layer = Input((None,))\n",
        "    embedding_layer = Embedding(input_dim=max_features,\n",
        "                                output_dim=embed_size,\n",
        "                                input_length=max_len,\n",
        "                                weights=[embedding_matrix],\n",
        "                                mask_zero=True,\n",
        "                                trainable=False)(input_layer)\n",
        "    \n",
        "    bidirectional_layer = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(embedding_layer)\n",
        "    #bidirectional_layer = LSTM(1, return_sequences=True, dropout=0.1)(embedding_layer)\n",
        "                                        \n",
        "    globalmaxpool_layer = GlobalMaxPool1D()(bidirectional_layer)\n",
        "                                        \n",
        "    dense_layer = Dense(units=50, activation='relu')(globalmaxpool_layer)\n",
        "    \n",
        "    droput_layer = Dropout(0.1)(dense_layer)\n",
        "    \n",
        "    classify_layer = Dense(units=2, activation='sigmoid')(droput_layer)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=classify_layer)\n",
        "    \n",
        "    \n",
        "    return model\n",
        "\n",
        "model = create_model(max_len, max_features, embed_size, embedding_matrix)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "time: 5.82 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWcBKhzMux9Z"
      },
      "source": [
        "**Task 8:** Compile the model and setup the callback. Then print out the model summary.\n",
        "* [Compile](https://keras.io/models/model/#compile) the model with Adam Optimizaer, lr = 1e-2, suitable loss for binary classification problem and [\"F1-score\"](https://github.com/tensorflow/addons/issues/825) as metric.\n",
        "* Print out the model summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD-K4q8ZfM4t",
        "outputId": "94e69267-7d85-4dc4-8eaf-3ce4d60fe52c"
      },
      "source": [
        "def create_f1():\n",
        "    def f1_function(y_true, y_pred):\n",
        "        y_true_class = tf.argmax(y_true, axis=1)\n",
        "        y_pred_class = tf.argmax(y_pred, axis=1)\n",
        "        tp = tf.reduce_sum(y_true_class * y_pred_class)\n",
        "        tp = tf.cast(tp, 'float32')\n",
        "        predicted_positives = tf.reduce_sum(y_pred_class)\n",
        "        predicted_positives = tf.cast(predicted_positives, 'float32')\n",
        "        possible_positives = tf.reduce_sum(y_true_class)\n",
        "        possible_positives = tf.cast(possible_positives, 'float32')\n",
        "        return tp, predicted_positives, possible_positives\n",
        "    return f1_function\n",
        "\n",
        "class F1_Score(Metric):\n",
        "    def __init__(self, name='new_f1_score', **kwargs):\n",
        "        super(F1_Score, self).__init__(name=name, **kwargs)\n",
        "        self.f1_function = create_f1()\n",
        "        self.tp_count = self.add_weight(\"tp_count\", initializer=\"zeros\")\n",
        "        self.all_predicted_positives = self.add_weight('all_predicted_positives', initializer='zeros')\n",
        "        self.all_possible_positives = self.add_weight('all_possible_positives', initializer='zeros')\n",
        "       \n",
        "    def update_state(self, y_true, y_pred,sample_weight=None):\n",
        "        tp, predicted_positives, possible_positives = self.f1_function(y_true, y_pred)\n",
        "        self.tp_count.assign_add(tp)\n",
        "        self.all_predicted_positives.assign_add(predicted_positives)\n",
        "        self.all_possible_positives.assign_add(possible_positives)\n",
        "    \n",
        "    def result(self):\n",
        "        precision = self.tp_count / self.all_predicted_positives\n",
        "        recall = self.tp_count / self.all_possible_positives\n",
        "        f1 = 2*(precision*recall)/(precision+recall)\n",
        "        return f1\n",
        "    "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 16.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9l8EbG0ur1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c882009-bbbd-4d6a-8e23-53f7e039cea1"
      },
      "source": [
        "def optimize(model):\n",
        "    '''\n",
        "    Input: \n",
        "        Model.\n",
        "    Return: \n",
        "        Complied model.\n",
        "    '''\n",
        "    ## TYPE YOUR CODE for task 8 here:\n",
        "    model.compile(optimizer=Optimizer.Adam(lr=0.01),\n",
        "                  loss='binary_crossentropy',\n",
        "                  #run_eagerly=True,\n",
        "                  metrics = [F1_Score()]\n",
        "                 )\n",
        "    return model\n",
        "\n",
        "model = optimize(model)\n",
        "print(model.summary())\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, None, 50)          1000000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 100)         40400     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 1,045,552\n",
            "Trainable params: 45,552\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n",
            "None\n",
            "time: 23 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BlenccGzLVr"
      },
      "source": [
        "**Task 9**: Setup callback.\n",
        "* Create the [tensorboard callback](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks) to save the logs.\n",
        "* Create the [checkpoint callback](https://machinelearningmastery.com/check-point-deep-learning-models-keras/) to save the checkpoint with the best accuracy after each epoch.\n",
        "* Create the [ReduceLROnPlateau](https://keras.io/callbacks/#reducelronplateau) callback with factor=0.3, patience=1 and \"Validation F1-score\" monitor.\n",
        "* Create the [early stopping callback](https://keras.io/callbacks/#earlystopping) with patience=7, mode = 'max' and \"Validation F1-score\" monitor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6x6dteutin0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b4eab09-31e5-4ef0-d9cd-105656a99abe"
      },
      "source": [
        "def get_best_result(checkpoint_name):\n",
        "    path = checkpoint_name+'**'\n",
        "    all_path_files = glob(path)\n",
        "    results = {}\n",
        "    for file in all_path_files:\n",
        "        results[file] = float(file[-9:-5])\n",
        "    best_file = max(results.items(), key=operator.itemgetter(1))[0]\n",
        "    return best_file\n",
        "\n",
        "def callback_model(checkpoint_name, logdir):\n",
        "    '''\n",
        "    Input: \n",
        "        Best checkpoint name, log dir.\n",
        "    Return: \n",
        "        Callback list, which contains tensorboard callback and checkpoint callback.\n",
        "    '''\n",
        "    ## TYPE YOUR CODE for task 9 here:\n",
        "\n",
        "    logdir = os.path.join(logdir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "    tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
        "    \n",
        "    checkpoint_name = checkpoint_name + '-{epoch:02d}-{val_new_f1_score:.3f}.hdf5'\n",
        "    checkpoint = ModelCheckpoint(checkpoint_name,\n",
        "                                 monitor='val_new_f1_score',\n",
        "                                 save_best_only=False,\n",
        "                                 mode='max',\n",
        "                                 verbose=1)\n",
        "    \n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_new_f1_score',\n",
        "                                  factor=0.3,\n",
        "                                  patience=1,\n",
        "                                  verbose=1)\n",
        "    \n",
        "    early_stopping = EarlyStopping(patience=7,\n",
        "                                   monitor='val_new_f1_score',\n",
        "                                   mode='max',\n",
        "                                   verbose=1)\n",
        "    \n",
        "    callbacks_list = [tensorboard_callback, checkpoint, reduce_lr, early_stopping]\n",
        "    \n",
        "    return callbacks_list\n",
        "\n",
        "#%rmdir /q/s training_logs\n",
        "checkpoint_name = 'weights-improvement'\n",
        "baseDir = os.path.abspath(os.getcwd())\n",
        "logs_name = 'training_logs'\n",
        "logdir = os.path.join(baseDir, logs_name)\n",
        "callbacks_list = callback_model(checkpoint_name, logdir)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 266 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nDCsHAC2HwW"
      },
      "source": [
        "**Task 10:** Train the model.\n",
        "\n",
        "* Train the model with 20 epochs with batch_size = 4096.\n",
        "* Return the model with best-checkpoint weights.\n",
        "\n",
        "*Hint*: Fit the model first, then reload the model (load_model function) with best-checkpoint weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xttwiHh4u0ES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e678b8-9b64-4fb6-9154-525972b48aca"
      },
      "source": [
        "def train_model(model, callbacks_list, skip_training=True):\n",
        "    '''\n",
        "    Input: \n",
        "        Model and callback list,\n",
        "    Return: \n",
        "        Model with best-checkpoint weights.\n",
        "    '''\n",
        "    ## TYPE YOUR CODE for task 10 here:\n",
        "    if not skip_training:\n",
        "        # Clear old folder\n",
        "        %rmdir /q/s {logs_name}\n",
        "        # Clear old file\n",
        "        path = checkpoint_name + '**'\n",
        "        all_path_files = glob(path)\n",
        "        for file in all_path_files:\n",
        "            os.remove(file)\n",
        "        # fit model\n",
        "        model.fit(X_tr, y_tr,\n",
        "                  validation_data=(X_va, y_va),\n",
        "                  batch_size=4096,\n",
        "                  epochs=20,\n",
        "                  callbacks=callbacks_list)\n",
        "\n",
        "        del model\n",
        "        \n",
        "    best_file = get_best_result(checkpoint_name)\n",
        "    model = load_model(best_file, custom_objects={'F1_Score':F1_Score()}) \n",
        "    return model\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 5.81 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqNu1WGafM4v",
        "outputId": "ba5a8813-c9cf-4c90-d67f-2a47b7efa9ff"
      },
      "source": [
        "# Train model\n",
        "model = create_model(max_len, max_features, embed_size, embedding_matrix)\n",
        "model = optimize(model)\n",
        "model = train_model(model, callbacks_list, skip_training=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/20\n",
            "  1/287 [..............................] - ETA: 0s - loss: 0.7395 - new_f1_score: 0.1036WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\my_d2l\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1544 - new_f1_score: 0.2214\n",
            "Epoch 00001: saving model to weights-improvement-01-0.533.hdf5\n",
            "287/287 [==============================] - 513s 2s/step - loss: 0.1544 - new_f1_score: 0.2214 - val_loss: 0.1260 - val_new_f1_score: 0.5329\n",
            "Epoch 2/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1244 - new_f1_score: 0.5474\n",
            "Epoch 00002: saving model to weights-improvement-02-0.610.hdf5\n",
            "\n",
            "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.0029999999329447745.\n",
            "287/287 [==============================] - 508s 2s/step - loss: 0.1244 - new_f1_score: 0.5474 - val_loss: 0.1180 - val_new_f1_score: 0.6098\n",
            "Epoch 3/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1176 - new_f1_score: 0.5821\n",
            "Epoch 00003: saving model to weights-improvement-03-0.602.hdf5\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0009000000078231095.\n",
            "287/287 [==============================] - 284s 989ms/step - loss: 0.1176 - new_f1_score: 0.5821 - val_loss: 0.1138 - val_new_f1_score: 0.6025\n",
            "Epoch 4/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1151 - new_f1_score: 0.5920\n",
            "Epoch 00004: saving model to weights-improvement-04-0.614.hdf5\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00026999999536201356.\n",
            "287/287 [==============================] - 231s 806ms/step - loss: 0.1151 - new_f1_score: 0.5920 - val_loss: 0.1131 - val_new_f1_score: 0.6137\n",
            "Epoch 5/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1140 - new_f1_score: 0.5977\n",
            "Epoch 00005: saving model to weights-improvement-05-0.622.hdf5\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 8.099999686237424e-05.\n",
            "287/287 [==============================] - 222s 773ms/step - loss: 0.1140 - new_f1_score: 0.5977 - val_loss: 0.1131 - val_new_f1_score: 0.6218\n",
            "Epoch 6/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1139 - new_f1_score: 0.5991\n",
            "Epoch 00006: saving model to weights-improvement-06-0.624.hdf5\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-05.\n",
            "287/287 [==============================] - 228s 796ms/step - loss: 0.1139 - new_f1_score: 0.5991 - val_loss: 0.1131 - val_new_f1_score: 0.6236\n",
            "Epoch 7/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1136 - new_f1_score: 0.5989\n",
            "Epoch 00007: saving model to weights-improvement-07-0.623.hdf5\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 7.289999848580919e-06.\n",
            "287/287 [==============================] - 218s 761ms/step - loss: 0.1136 - new_f1_score: 0.5989 - val_loss: 0.1130 - val_new_f1_score: 0.6234\n",
            "Epoch 8/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1136 - new_f1_score: 0.5997\n",
            "Epoch 00008: saving model to weights-improvement-08-0.624.hdf5\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.186999927289435e-06.\n",
            "287/287 [==============================] - 215s 748ms/step - loss: 0.1136 - new_f1_score: 0.5997 - val_loss: 0.1130 - val_new_f1_score: 0.6235\n",
            "Epoch 9/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1137 - new_f1_score: 0.5999\n",
            "Epoch 00009: saving model to weights-improvement-09-0.623.hdf5\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.560999509019894e-07.\n",
            "287/287 [==============================] - 220s 767ms/step - loss: 0.1137 - new_f1_score: 0.5999 - val_loss: 0.1130 - val_new_f1_score: 0.6231\n",
            "Epoch 10/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1135 - new_f1_score: 0.5992\n",
            "Epoch 00010: saving model to weights-improvement-10-0.623.hdf5\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.9682997844938655e-07.\n",
            "287/287 [==============================] - 217s 757ms/step - loss: 0.1135 - new_f1_score: 0.5992 - val_loss: 0.1130 - val_new_f1_score: 0.6232\n",
            "Epoch 11/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1137 - new_f1_score: 0.5997\n",
            "Epoch 00011: saving model to weights-improvement-11-0.623.hdf5\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 5.9048991829513396e-08.\n",
            "287/287 [==============================] - 224s 780ms/step - loss: 0.1137 - new_f1_score: 0.5997 - val_loss: 0.1130 - val_new_f1_score: 0.6232\n",
            "Epoch 12/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1136 - new_f1_score: 0.5990\n",
            "Epoch 00012: saving model to weights-improvement-12-0.623.hdf5\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.771469797517966e-08.\n",
            "287/287 [==============================] - 228s 793ms/step - loss: 0.1136 - new_f1_score: 0.5990 - val_loss: 0.1130 - val_new_f1_score: 0.6232\n",
            "Epoch 13/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1137 - new_f1_score: 0.5996\n",
            "Epoch 00013: saving model to weights-improvement-13-0.623.hdf5\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 5.314409179391077e-09.\n",
            "287/287 [==============================] - 217s 757ms/step - loss: 0.1137 - new_f1_score: 0.5996 - val_loss: 0.1130 - val_new_f1_score: 0.6232\n",
            "Epoch 00013: early stopping\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "time: 59min 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa88xu-afM4v",
        "outputId": "1916ca2a-6716-4dce-a415-4f3714900539"
      },
      "source": [
        "f1 = model.evaluate(X_te, y_te)\n",
        "f1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2041/2041 [==============================] - 58s 29ms/step - loss: 0.1119 - new_f1_score: 0.6293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11188188195228577, 0.629287600517273]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "stream",
          "text": [
            "time: 59.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsG02Ao07Mc-"
      },
      "source": [
        "**Task 11:** Show the tensorboard in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpBk-EKZ2Ut7",
        "outputId": "a027c379-ac3e-4184-af0f-40bcb7978af9"
      },
      "source": [
        "## TYPE YOUR CODE for task 11 here:\n",
        "if 'COLAB_GPU' in os.environ:\n",
        "    %tensorboard --logdir {logdir}\n",
        "else:\n",
        "    proc = subprocess.Popen([\"tensorboard\", \"--logdir\", logdir])\n",
        "    # wait process\n",
        "    time.sleep(5)\n",
        "    %tensorboard --logdir {logdir}\n",
        "    #%tensorboard --logdir {logdir}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 10980), started 5 days, 13:21:45 ago. (Use '!kill 10980' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-10246eefb77a5c28\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-10246eefb77a5c28\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 5.05 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z1ed1CY8Rxh"
      },
      "source": [
        "**Task 12:** Prediction on test set.\n",
        "\n",
        "* Complete the get_prediction_classes function.\n",
        "* Print out the precision, recall and F1 score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHTjBLZYvx26",
        "outputId": "1faf5d2d-c3e8-43c9-9097-5c73c9281316"
      },
      "source": [
        "def get_prediction_classes(model, X, y):\n",
        "    ## TYPE YOUR CODE for task 13 here:\n",
        "    '''\n",
        "    Input: \n",
        "        Model and prediction dataset.\n",
        "    Return: \n",
        "        Prediction list and groundtrurth list with predicted classes.\n",
        "    '''\n",
        "    groundtruths = np.argmax(y, axis=1) \n",
        "    predictions = model.predict(X)\n",
        "    predictions = np.argmax(predictions, axis=1) \n",
        "    return predictions, groundtruths\n",
        "\n",
        "\n",
        "test_predictions, test_groundtruths = get_prediction_classes(model, X_te, y_te)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 39.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP_xhIdVfM4w",
        "outputId": "e4bd800a-03d3-466e-9e80-d8c212fa0439"
      },
      "source": [
        "print(precision_score(test_groundtruths, test_predictions))\n",
        "print(recall_score(test_groundtruths, test_predictions))\n",
        "print(f1_score(test_groundtruths, test_predictions))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6657381615598886\n",
            "0.6505815392229646\n",
            "0.6580725907384231\n",
            "time: 47 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJwQahjp8hZs"
      },
      "source": [
        "**Task 13:** Perform the predicted result on test set using confusion matrix. Remember to show the class name in the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KKAmOGvv2Be",
        "outputId": "e8d3665f-b39a-48b6-8dc8-a3a43a9ab361"
      },
      "source": [
        "sns.set(font_scale=1.2, style='dark')\n",
        "def plot_confusion_matrix(predictions, groundtruth, class_names):\n",
        "    ## TYPE YOUR CODE for task 13 here:\n",
        "    cm = confusion_matrix(groundtruth, predictions, normalize=None)\n",
        "    cm_rate = cm / np.sum(cm) #confusion_matrix(groundtruth, predictions, normalize='true')\n",
        "    \n",
        "    values = ['{0:0.0f}'.format(value) for value in cm.flatten()] \n",
        "    percentages = [\"{0:.2%}\".format(value) for value in cm_rate.flatten()]\n",
        "    tf_label = ['TN', 'FP', 'FN', 'TP']\n",
        "    labels = [f'{l}\\n{v}\\n({p})' for l, v, p in zip(tf_label, values, percentages)]\n",
        "    labels = np.array(labels).reshape(2, 2)\n",
        "    \n",
        "    plt.figure(figsize=(9, 7))\n",
        "    sns.heatmap(cm, annot=labels, fmt=\"\", annot_kws={\"size\": 13}, xticklabels=class_names, yticklabels=class_names, linewidths=1) \n",
        "    plt.title('Confusion matrix', y=1.02, size=15)\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.ylabel('True label')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.show()\n",
        "    \n",
        "class_names = ['valid', 'invalid']\n",
        "plot_confusion_matrix(test_predictions, test_groundtruths, class_names)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 375 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGmUAFDi87Z6"
      },
      "source": [
        "**Task 14**: Model finetuning - fine tune the model using some of these approachs:\n",
        "* Increase max epochs, change batch size.\n",
        "* Replace LSTM by GRU units and check if it changes anything.\n",
        "* Add another layer of LSTM/GRU, see if things improve.\n",
        "* Play around with Dense layers (add/# units/etc).\n",
        "* Find preprocessing rules you could add to improve the quality of the data.\n",
        "* Find another GloVe dictionary.\n",
        "Requirement: The F1 score should increase by 2-3%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELLyczmROE8J"
      },
      "source": [
        "#### Dowload new dictionary - spacy (a language_model of 300-dimensional GloVe vectors)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4ucZ4QcfM4x",
        "outputId": "8a414a68-bbd9-4c54-fb0c-c3786c243524"
      },
      "source": [
        "!python -m spacy download en_vectors_web_lg"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_vectors_web_lg==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_vectors_web_lg-2.1.0/en_vectors_web_lg-2.1.0.tar.gz#egg=en_vectors_web_lg==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: spacy<3.0.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from en_vectors_web_lg==2.1.0) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (2.0.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.18.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (50.3.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.0.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_vectors_web_lg')\n",
            "time: 3.56 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0i0y-4CfM4y",
        "outputId": "67765f7d-e230-439e-94b4-8cb75d00d039"
      },
      "source": [
        "# load spacy dict\n",
        "import en_vectors_web_lg\n",
        "\n",
        "language_model = en_vectors_web_lg.load()  \n",
        "spacy_dict = {}\n",
        "for key, vector in language_model.vocab.vectors.items():\n",
        "    try:\n",
        "        word_string = language_model.vocab.strings[key]\n",
        "        spacy_dict[word_string] = vector\n",
        "\n",
        "    except KeyError:\n",
        "        print(key)\n",
        "        continue\n",
        "        "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4035656307355538346\n",
            "4183861688597294412\n",
            "9493573674140310719\n",
            "11580349482641876976\n",
            "time: 10.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VLdY3hgfM4y"
      },
      "source": [
        "# Check\n",
        "print(' shape of vector', spacy_dict['the'].shape)\n",
        "spacy_dict['the']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UhwOPSVfM4y",
        "outputId": "adee025a-4e71-4edc-df3d-d122c1ec31d7"
      },
      "source": [
        "# Init parameters, setup folder\n",
        "embed_size = 300 \n",
        "max_features = 50000 \n",
        "max_len = 100 \n",
        "\n",
        "checkpoint_name = 'new_weights-improvement'\n",
        "baseDir = os.path.abspath(os.getcwd())\n",
        "logs_name = 'new_training_logs'\n",
        "logdir = os.path.join(baseDir, logs_name)\n",
        "callbacks_list = callback_model(checkpoint_name, logdir)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 4.14 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZbW62M1wc6g",
        "outputId": "5106ec4d-52e4-412a-c953-118674a0a3e6"
      },
      "source": [
        "# Create new data and new tokenizer\r\n",
        "X_tr, X_va, X_te, y_tr, y_va, y_te, tokenizer = encoding_textdata(train_set, validation_set, test_set, max_features, max_len)\r\n",
        "X_tr.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1175509, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "stream",
          "text": [
            "time: 42 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfDjDgKsfM4y",
        "outputId": "4fce560b-c716-42ea-df04-20a2749b4dd0"
      },
      "source": [
        "# Create new embedding maxtrix\n",
        "spacy_embedding_matrix = create_embedding_matrix(spacy_dict, tokenizer, max_features)\n",
        "spacy_embedding_matrix.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "stream",
          "text": [
            "time: 5.41 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1a3xxeHfM4y",
        "outputId": "34a0dc8d-afab-407c-f819-276465970056"
      },
      "source": [
        "# Train model with new embedding maxtrix\n",
        "new_model = create_model(max_len, max_features, embed_size, spacy_embedding_matrix)\n",
        "new_model = optimize(new_model)\n",
        "new_model = train_model(new_model, callbacks_list, skip_training=False)\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "rmdir: failed to remove '/q/s': No such file or directory\n",
            "rmdir: failed to remove 'new_training_logs': Directory not empty\n",
            "Epoch 1/20\n",
            "  2/287 [..............................] - ETA: 18:39 - loss: 0.4640 - new_f1_score: nanWARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 1.9394s vs `on_train_batch_end` time: 5.9162s). Check your callbacks.\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1302 - new_f1_score: 0.4418\n",
            "Epoch 00001: saving model to new_weights-improvement-01-0.601.hdf5\n",
            "287/287 [==============================] - 379s 1s/step - loss: 0.1302 - new_f1_score: 0.4418 - val_loss: 0.1108 - val_new_f1_score: 0.6014\n",
            "Epoch 2/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1086 - new_f1_score: 0.6272\n",
            "Epoch 00002: saving model to new_weights-improvement-02-0.648.hdf5\n",
            "\n",
            "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.0029999999329447745.\n",
            "287/287 [==============================] - 370s 1s/step - loss: 0.1086 - new_f1_score: 0.6272 - val_loss: 0.1059 - val_new_f1_score: 0.6481\n",
            "Epoch 3/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1005 - new_f1_score: 0.6575\n",
            "Epoch 00003: saving model to new_weights-improvement-03-0.659.hdf5\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0009000000078231095.\n",
            "287/287 [==============================] - 368s 1s/step - loss: 0.1005 - new_f1_score: 0.6575 - val_loss: 0.1034 - val_new_f1_score: 0.6592\n",
            "Epoch 4/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.0967 - new_f1_score: 0.6733\n",
            "Epoch 00004: saving model to new_weights-improvement-04-0.660.hdf5\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00026999999536201356.\n",
            "287/287 [==============================] - 366s 1s/step - loss: 0.0967 - new_f1_score: 0.6733 - val_loss: 0.1030 - val_new_f1_score: 0.6599\n",
            "Epoch 5/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.0951 - new_f1_score: 0.6794\n",
            "Epoch 00005: saving model to new_weights-improvement-05-0.660.hdf5\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 8.099999686237424e-05.\n",
            "287/287 [==============================] - 365s 1s/step - loss: 0.0951 - new_f1_score: 0.6794 - val_loss: 0.1031 - val_new_f1_score: 0.6605\n",
            "Epoch 6/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.0947 - new_f1_score: 0.6818\n",
            "Epoch 00006: saving model to new_weights-improvement-06-0.663.hdf5\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-05.\n",
            "287/287 [==============================] - 364s 1s/step - loss: 0.0947 - new_f1_score: 0.6818 - val_loss: 0.1031 - val_new_f1_score: 0.6632\n",
            "Epoch 7/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.0945 - new_f1_score: 0.6826\n",
            "Epoch 00007: saving model to new_weights-improvement-07-0.663.hdf5\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 7.289999848580919e-06.\n",
            "287/287 [==============================] - 362s 1s/step - loss: 0.0945 - new_f1_score: 0.6826 - val_loss: 0.1031 - val_new_f1_score: 0.6630\n",
            "Epoch 8/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.0946 - new_f1_score: 0.6827\n",
            "Epoch 00008: saving model to new_weights-improvement-08-0.663.hdf5\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.186999927289435e-06.\n",
            "287/287 [==============================] - 363s 1s/step - loss: 0.0946 - new_f1_score: 0.6827 - val_loss: 0.1031 - val_new_f1_score: 0.6630\n",
            "Epoch 9/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.0945 - new_f1_score: 0.6825\n",
            "Epoch 00009: saving model to new_weights-improvement-09-0.663.hdf5\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.560999509019894e-07.\n",
            "287/287 [==============================] - 361s 1s/step - loss: 0.0945 - new_f1_score: 0.6825 - val_loss: 0.1031 - val_new_f1_score: 0.6630\n",
            "Epoch 10/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.0945 - new_f1_score: 0.6825\n",
            "Epoch 00010: saving model to new_weights-improvement-10-0.663.hdf5\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.9682997844938655e-07.\n",
            "287/287 [==============================] - 364s 1s/step - loss: 0.0945 - new_f1_score: 0.6825 - val_loss: 0.1031 - val_new_f1_score: 0.6630\n",
            "Epoch 11/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.0945 - new_f1_score: 0.6820\n",
            "Epoch 00011: saving model to new_weights-improvement-11-0.663.hdf5\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 5.9048991829513396e-08.\n",
            "287/287 [==============================] - 365s 1s/step - loss: 0.0945 - new_f1_score: 0.6820 - val_loss: 0.1031 - val_new_f1_score: 0.6632\n",
            "Epoch 12/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.0945 - new_f1_score: 0.6822\n",
            "Epoch 00012: saving model to new_weights-improvement-12-0.663.hdf5\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.771469797517966e-08.\n",
            "287/287 [==============================] - 362s 1s/step - loss: 0.0945 - new_f1_score: 0.6822 - val_loss: 0.1031 - val_new_f1_score: 0.6632\n",
            "Epoch 13/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.0945 - new_f1_score: 0.6824\n",
            "Epoch 00013: saving model to new_weights-improvement-13-0.663.hdf5\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 5.314409179391077e-09.\n",
            "287/287 [==============================] - 363s 1s/step - loss: 0.0945 - new_f1_score: 0.6824 - val_loss: 0.1031 - val_new_f1_score: 0.6632\n",
            "Epoch 14/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.0944 - new_f1_score: 0.6819\n",
            "Epoch 00014: saving model to new_weights-improvement-14-0.663.hdf5\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.5943228071080283e-09.\n",
            "287/287 [==============================] - 363s 1s/step - loss: 0.0944 - new_f1_score: 0.6819 - val_loss: 0.1031 - val_new_f1_score: 0.6632\n",
            "Epoch 15/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.0945 - new_f1_score: 0.6819\n",
            "Epoch 00015: saving model to new_weights-improvement-15-0.663.hdf5\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 4.782968354710703e-10.\n",
            "287/287 [==============================] - 364s 1s/step - loss: 0.0945 - new_f1_score: 0.6819 - val_loss: 0.1031 - val_new_f1_score: 0.6632\n",
            "Epoch 16/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.0945 - new_f1_score: 0.6819\n",
            "Epoch 00016: saving model to new_weights-improvement-16-0.663.hdf5\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.434890539719902e-10.\n",
            "287/287 [==============================] - 365s 1s/step - loss: 0.0945 - new_f1_score: 0.6819 - val_loss: 0.1031 - val_new_f1_score: 0.6632\n",
            "Epoch 17/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.0945 - new_f1_score: 0.6830\n",
            "Epoch 00017: saving model to new_weights-improvement-17-0.663.hdf5\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.3046716191597054e-11.\n",
            "287/287 [==============================] - 364s 1s/step - loss: 0.0945 - new_f1_score: 0.6830 - val_loss: 0.1031 - val_new_f1_score: 0.6632\n",
            "Epoch 18/20\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.0945 - new_f1_score: 0.6825\n",
            "Epoch 00018: saving model to new_weights-improvement-18-0.663.hdf5\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.2914014649312299e-11.\n",
            "287/287 [==============================] - 363s 1s/step - loss: 0.0945 - new_f1_score: 0.6825 - val_loss: 0.1031 - val_new_f1_score: 0.6632\n",
            "Epoch 00018: early stopping\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "time: 1h 49min 59s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EflpBKYcfM4z",
        "outputId": "e52b7d6a-8ef5-4245-bea4-1dfcd474fe98"
      },
      "source": [
        "# Evaluate model\n",
        "_, f1 = new_model.evaluate(X_te, y_te)\n",
        "f1"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2041/2041 [==============================] - 201s 99ms/step - loss: 0.1022 - new_f1_score: 0.6638\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6638029217720032"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "stream",
          "text": [
            "time: 3min 21s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}