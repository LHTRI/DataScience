{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cải tiến mô hình với dữ liệu được lọc hay cân bằng theo cự ly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "import subprocess\n",
    "from glob import glob\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import scipy.stats as ss\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, TensorBoard, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from tensorflow.keras.initializers import RandomNormal, Constant\n",
    "from tensorflow.keras.metrics import Metric\n",
    "import tensorflow.keras.optimizers as Optimizer\n",
    "import tensorflow_addons as tfa \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import os.path as path\n",
    "lib_path =  path.abspath(path.join('' ,\"../../api/common\"))\n",
    "sys.path.insert(1, lib_path)\n",
    "from transform_split_data import transform_split_data\n",
    "from predict import predict, evaluate\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext autotime\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Khởi tạo phương thức giải phóng bộ nhớ gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "time: 734 ms\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>KettoNum</th>\n",
       "      <th>id$Year</th>\n",
       "      <th>ChokyosiCode</th>\n",
       "      <th>BanusiCode</th>\n",
       "      <th>UM_BreederCode</th>\n",
       "      <th>Odds</th>\n",
       "      <th>Kyori</th>\n",
       "      <th>TenkoBaba$DirtBabaCD_0</th>\n",
       "      <th>TenkoBaba$SibaBabaCD_0</th>\n",
       "      <th>...</th>\n",
       "      <th>KS_Syotai_川崎</th>\n",
       "      <th>KS_Syotai_笠松</th>\n",
       "      <th>id$JyoCD_1</th>\n",
       "      <th>KS_ChokyosiCode_365.0</th>\n",
       "      <th>CH_Syotai_川崎</th>\n",
       "      <th>top2_ChokyosiCode</th>\n",
       "      <th>top2_BanusiCode</th>\n",
       "      <th>top2_UM_BreederCode</th>\n",
       "      <th>before_Odds</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12135</td>\n",
       "      <td>2009100729</td>\n",
       "      <td>2011</td>\n",
       "      <td>1010</td>\n",
       "      <td>949030</td>\n",
       "      <td>600016</td>\n",
       "      <td>222</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.352506</td>\n",
       "      <td>-0.921203</td>\n",
       "      <td>0.090456</td>\n",
       "      <td>0.243086</td>\n",
       "      <td>59.833795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26439</td>\n",
       "      <td>2011103176</td>\n",
       "      <td>2015</td>\n",
       "      <td>1095</td>\n",
       "      <td>477030</td>\n",
       "      <td>100046</td>\n",
       "      <td>35</td>\n",
       "      <td>0.166752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254953</td>\n",
       "      <td>-0.661138</td>\n",
       "      <td>-0.651838</td>\n",
       "      <td>-0.672843</td>\n",
       "      <td>58.230257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33661</td>\n",
       "      <td>2013100779</td>\n",
       "      <td>2017</td>\n",
       "      <td>1123</td>\n",
       "      <td>78006</td>\n",
       "      <td>703397</td>\n",
       "      <td>148</td>\n",
       "      <td>2.348416</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.206765</td>\n",
       "      <td>-0.442809</td>\n",
       "      <td>-1.241063</td>\n",
       "      <td>-0.613398</td>\n",
       "      <td>57.920792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28482</td>\n",
       "      <td>2011105992</td>\n",
       "      <td>2016</td>\n",
       "      <td>1129</td>\n",
       "      <td>547800</td>\n",
       "      <td>610012</td>\n",
       "      <td>52</td>\n",
       "      <td>1.378788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453573</td>\n",
       "      <td>-0.510523</td>\n",
       "      <td>-0.974169</td>\n",
       "      <td>-0.578217</td>\n",
       "      <td>60.876249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>291</td>\n",
       "      <td>2004104307</td>\n",
       "      <td>2008</td>\n",
       "      <td>331</td>\n",
       "      <td>142006</td>\n",
       "      <td>701079</td>\n",
       "      <td>933</td>\n",
       "      <td>0.166752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.477666</td>\n",
       "      <td>-1.938882</td>\n",
       "      <td>-0.988132</td>\n",
       "      <td>0.072652</td>\n",
       "      <td>57.627119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475191</th>\n",
       "      <td>18201</td>\n",
       "      <td>2005106482</td>\n",
       "      <td>2013</td>\n",
       "      <td>1013</td>\n",
       "      <td>789006</td>\n",
       "      <td>400018</td>\n",
       "      <td>911</td>\n",
       "      <td>3.027155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232084</td>\n",
       "      <td>-0.467961</td>\n",
       "      <td>0.392597</td>\n",
       "      <td>3.096416</td>\n",
       "      <td>49.966265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475192</th>\n",
       "      <td>7309</td>\n",
       "      <td>2006102916</td>\n",
       "      <td>2010</td>\n",
       "      <td>1076</td>\n",
       "      <td>310007</td>\n",
       "      <td>393126</td>\n",
       "      <td>369</td>\n",
       "      <td>-1.530097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.380029</td>\n",
       "      <td>0.211269</td>\n",
       "      <td>1.335489</td>\n",
       "      <td>-0.553954</td>\n",
       "      <td>60.301508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475193</th>\n",
       "      <td>16882</td>\n",
       "      <td>2007104657</td>\n",
       "      <td>2012</td>\n",
       "      <td>1102</td>\n",
       "      <td>103006</td>\n",
       "      <td>330314</td>\n",
       "      <td>63</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.541780</td>\n",
       "      <td>-1.376219</td>\n",
       "      <td>-0.335163</td>\n",
       "      <td>-0.299192</td>\n",
       "      <td>62.113587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475194</th>\n",
       "      <td>8963</td>\n",
       "      <td>2007104503</td>\n",
       "      <td>2010</td>\n",
       "      <td>221</td>\n",
       "      <td>100006</td>\n",
       "      <td>310390</td>\n",
       "      <td>109</td>\n",
       "      <td>-1.530097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.098465</td>\n",
       "      <td>-0.945524</td>\n",
       "      <td>-1.037796</td>\n",
       "      <td>-0.678908</td>\n",
       "      <td>60.050042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475195</th>\n",
       "      <td>32570</td>\n",
       "      <td>2014103689</td>\n",
       "      <td>2017</td>\n",
       "      <td>436</td>\n",
       "      <td>129008</td>\n",
       "      <td>510045</td>\n",
       "      <td>717</td>\n",
       "      <td>-0.802876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.745284</td>\n",
       "      <td>0.159340</td>\n",
       "      <td>-0.418325</td>\n",
       "      <td>-0.477525</td>\n",
       "      <td>57.849197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475196 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        race_id    KettoNum  id$Year  ChokyosiCode  BanusiCode  \\\n",
       "0         12135  2009100729     2011          1010      949030   \n",
       "1         26439  2011103176     2015          1095      477030   \n",
       "2         33661  2013100779     2017          1123       78006   \n",
       "3         28482  2011105992     2016          1129      547800   \n",
       "4           291  2004104307     2008           331      142006   \n",
       "...         ...         ...      ...           ...         ...   \n",
       "475191    18201  2005106482     2013          1013      789006   \n",
       "475192     7309  2006102916     2010          1076      310007   \n",
       "475193    16882  2007104657     2012          1102      103006   \n",
       "475194     8963  2007104503     2010           221      100006   \n",
       "475195    32570  2014103689     2017           436      129008   \n",
       "\n",
       "        UM_BreederCode  Odds     Kyori  TenkoBaba$DirtBabaCD_0  \\\n",
       "0               600016   222 -1.045283                     1.0   \n",
       "1               100046    35  0.166752                     0.0   \n",
       "2               703397   148  2.348416                     1.0   \n",
       "3               610012    52  1.378788                     1.0   \n",
       "4               701079   933  0.166752                     0.0   \n",
       "...                ...   ...       ...                     ...   \n",
       "475191          400018   911  3.027155                     0.0   \n",
       "475192          393126   369 -1.530097                     0.0   \n",
       "475193          330314    63 -1.045283                     1.0   \n",
       "475194          310390   109 -1.530097                     0.0   \n",
       "475195          510045   717 -0.802876                     0.0   \n",
       "\n",
       "        TenkoBaba$SibaBabaCD_0  ...  KS_Syotai_川崎　　　　　　　　  \\\n",
       "0                          0.0  ...                   0.0   \n",
       "1                          1.0  ...                   0.0   \n",
       "2                          0.0  ...                   0.0   \n",
       "3                          0.0  ...                   0.0   \n",
       "4                          1.0  ...                   0.0   \n",
       "...                        ...  ...                   ...   \n",
       "475191                     0.0  ...                   0.0   \n",
       "475192                     1.0  ...                   0.0   \n",
       "475193                     0.0  ...                   0.0   \n",
       "475194                     1.0  ...                   0.0   \n",
       "475195                     1.0  ...                   0.0   \n",
       "\n",
       "        KS_Syotai_笠松　　　　　　　　  id$JyoCD_1  KS_ChokyosiCode_365.0  \\\n",
       "0                        0.0         0.0                    0.0   \n",
       "1                        0.0         0.0                    0.0   \n",
       "2                        0.0         0.0                    0.0   \n",
       "3                        0.0         0.0                    0.0   \n",
       "4                        0.0         0.0                    0.0   \n",
       "...                      ...         ...                    ...   \n",
       "475191                   0.0         0.0                    0.0   \n",
       "475192                   0.0         0.0                    0.0   \n",
       "475193                   0.0         0.0                    0.0   \n",
       "475194                   0.0         0.0                    0.0   \n",
       "475195                   0.0         0.0                    0.0   \n",
       "\n",
       "        CH_Syotai_川崎　　　　　　　　  top2_ChokyosiCode  top2_BanusiCode  \\\n",
       "0                        0.0          -1.352506        -0.921203   \n",
       "1                        0.0           0.254953        -0.661138   \n",
       "2                        0.0          -0.206765        -0.442809   \n",
       "3                        0.0           0.453573        -0.510523   \n",
       "4                        0.0          -1.477666        -1.938882   \n",
       "...                      ...                ...              ...   \n",
       "475191                   0.0           0.232084        -0.467961   \n",
       "475192                   0.0          -0.380029         0.211269   \n",
       "475193                   0.0           0.541780        -1.376219   \n",
       "475194                   0.0          -1.098465        -0.945524   \n",
       "475195                   0.0          -0.745284         0.159340   \n",
       "\n",
       "        top2_UM_BreederCode  before_Odds      speed  \n",
       "0                  0.090456     0.243086  59.833795  \n",
       "1                 -0.651838    -0.672843  58.230257  \n",
       "2                 -1.241063    -0.613398  57.920792  \n",
       "3                 -0.974169    -0.578217  60.876249  \n",
       "4                 -0.988132     0.072652  57.627119  \n",
       "...                     ...          ...        ...  \n",
       "475191             0.392597     3.096416  49.966265  \n",
       "475192             1.335489    -0.553954  60.301508  \n",
       "475193            -0.335163    -0.299192  62.113587  \n",
       "475194            -1.037796    -0.678908  60.050042  \n",
       "475195            -0.418325    -0.477525  57.849197  \n",
       "\n",
       "[475196 rows x 212 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "# Load dữ liệu\n",
    "train_data = pd.read_csv('train_data_all.csv')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cân bằng dữ liệu train theo cự ly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>KettoNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22122</td>\n",
       "      <td>2009103322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16279</td>\n",
       "      <td>2007105563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25168</td>\n",
       "      <td>2012102374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21375</td>\n",
       "      <td>2011106150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12820</td>\n",
       "      <td>2009100419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959995</th>\n",
       "      <td>33275</td>\n",
       "      <td>2009103514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959996</th>\n",
       "      <td>29845</td>\n",
       "      <td>2010102928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959997</th>\n",
       "      <td>33410</td>\n",
       "      <td>2011106314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959998</th>\n",
       "      <td>29845</td>\n",
       "      <td>2011101189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959999</th>\n",
       "      <td>33410</td>\n",
       "      <td>2009101968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        race_id    KettoNum\n",
       "0         22122  2009103322\n",
       "1         16279  2007105563\n",
       "2         25168  2012102374\n",
       "3         21375  2011106150\n",
       "4         12820  2009100419\n",
       "...         ...         ...\n",
       "959995    33275  2009103514\n",
       "959996    29845  2010102928\n",
       "959997    33410  2011106314\n",
       "959998    29845  2011101189\n",
       "959999    33410  2009101968\n",
       "\n",
       "[960000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 203 ms\n"
     ]
    }
   ],
   "source": [
    "filter_balance_id = pd.read_csv('filter_balance_id.csv')\n",
    "filter_balance_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>KettoNum</th>\n",
       "      <th>id$Year</th>\n",
       "      <th>ChokyosiCode</th>\n",
       "      <th>BanusiCode</th>\n",
       "      <th>UM_BreederCode</th>\n",
       "      <th>Odds</th>\n",
       "      <th>Kyori</th>\n",
       "      <th>TenkoBaba$DirtBabaCD_0</th>\n",
       "      <th>TenkoBaba$SibaBabaCD_0</th>\n",
       "      <th>...</th>\n",
       "      <th>KS_Syotai_川崎</th>\n",
       "      <th>KS_Syotai_笠松</th>\n",
       "      <th>id$JyoCD_1</th>\n",
       "      <th>KS_ChokyosiCode_365.0</th>\n",
       "      <th>CH_Syotai_川崎</th>\n",
       "      <th>top2_ChokyosiCode</th>\n",
       "      <th>top2_BanusiCode</th>\n",
       "      <th>top2_UM_BreederCode</th>\n",
       "      <th>before_Odds</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22122</td>\n",
       "      <td>2009103322</td>\n",
       "      <td>2014</td>\n",
       "      <td>341</td>\n",
       "      <td>639009</td>\n",
       "      <td>233071</td>\n",
       "      <td>1220</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099681</td>\n",
       "      <td>-0.557335</td>\n",
       "      <td>-0.287502</td>\n",
       "      <td>-0.492083</td>\n",
       "      <td>57.831325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16279</td>\n",
       "      <td>2007105563</td>\n",
       "      <td>2012</td>\n",
       "      <td>1031</td>\n",
       "      <td>441030</td>\n",
       "      <td>913124</td>\n",
       "      <td>5035</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.931447</td>\n",
       "      <td>0.343967</td>\n",
       "      <td>0.539699</td>\n",
       "      <td>2.236292</td>\n",
       "      <td>59.178082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25168</td>\n",
       "      <td>2012102374</td>\n",
       "      <td>2015</td>\n",
       "      <td>1096</td>\n",
       "      <td>125009</td>\n",
       "      <td>833098</td>\n",
       "      <td>2165</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.812923</td>\n",
       "      <td>-1.334369</td>\n",
       "      <td>-0.519851</td>\n",
       "      <td>3.673875</td>\n",
       "      <td>59.340659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21375</td>\n",
       "      <td>2011106150</td>\n",
       "      <td>2014</td>\n",
       "      <td>359</td>\n",
       "      <td>629800</td>\n",
       "      <td>900515</td>\n",
       "      <td>59</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.359324</td>\n",
       "      <td>-1.594419</td>\n",
       "      <td>-1.553278</td>\n",
       "      <td>-0.580643</td>\n",
       "      <td>59.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12820</td>\n",
       "      <td>2009100419</td>\n",
       "      <td>2011</td>\n",
       "      <td>1014</td>\n",
       "      <td>959030</td>\n",
       "      <td>100516</td>\n",
       "      <td>5734</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.015901</td>\n",
       "      <td>-1.741161</td>\n",
       "      <td>-0.621870</td>\n",
       "      <td>1.134751</td>\n",
       "      <td>61.016949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959995</th>\n",
       "      <td>33275</td>\n",
       "      <td>2009103514</td>\n",
       "      <td>2017</td>\n",
       "      <td>1091</td>\n",
       "      <td>382004</td>\n",
       "      <td>704079</td>\n",
       "      <td>55</td>\n",
       "      <td>2.978674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.314826</td>\n",
       "      <td>-0.514318</td>\n",
       "      <td>0.306801</td>\n",
       "      <td>-0.652219</td>\n",
       "      <td>54.047244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959996</th>\n",
       "      <td>29845</td>\n",
       "      <td>2010102928</td>\n",
       "      <td>2016</td>\n",
       "      <td>1055</td>\n",
       "      <td>547800</td>\n",
       "      <td>703084</td>\n",
       "      <td>24</td>\n",
       "      <td>2.978674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.526010</td>\n",
       "      <td>-0.510523</td>\n",
       "      <td>-0.349731</td>\n",
       "      <td>-0.607332</td>\n",
       "      <td>54.047244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959997</th>\n",
       "      <td>33410</td>\n",
       "      <td>2011106314</td>\n",
       "      <td>2017</td>\n",
       "      <td>261</td>\n",
       "      <td>494800</td>\n",
       "      <td>213326</td>\n",
       "      <td>199</td>\n",
       "      <td>2.978674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.193960</td>\n",
       "      <td>0.161274</td>\n",
       "      <td>-0.494214</td>\n",
       "      <td>-0.634022</td>\n",
       "      <td>54.189474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959998</th>\n",
       "      <td>29845</td>\n",
       "      <td>2011101189</td>\n",
       "      <td>2016</td>\n",
       "      <td>1080</td>\n",
       "      <td>546800</td>\n",
       "      <td>133090</td>\n",
       "      <td>39</td>\n",
       "      <td>2.978674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.328563</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>-0.243707</td>\n",
       "      <td>-0.058988</td>\n",
       "      <td>53.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959999</th>\n",
       "      <td>33410</td>\n",
       "      <td>2009101968</td>\n",
       "      <td>2017</td>\n",
       "      <td>1006</td>\n",
       "      <td>618002</td>\n",
       "      <td>365</td>\n",
       "      <td>100</td>\n",
       "      <td>2.978674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.114980</td>\n",
       "      <td>-1.722283</td>\n",
       "      <td>-0.146472</td>\n",
       "      <td>-0.293127</td>\n",
       "      <td>54.075630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960000 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        race_id    KettoNum  id$Year  ChokyosiCode  BanusiCode  \\\n",
       "0         22122  2009103322     2014           341      639009   \n",
       "1         16279  2007105563     2012          1031      441030   \n",
       "2         25168  2012102374     2015          1096      125009   \n",
       "3         21375  2011106150     2014           359      629800   \n",
       "4         12820  2009100419     2011          1014      959030   \n",
       "...         ...         ...      ...           ...         ...   \n",
       "959995    33275  2009103514     2017          1091      382004   \n",
       "959996    29845  2010102928     2016          1055      547800   \n",
       "959997    33410  2011106314     2017           261      494800   \n",
       "959998    29845  2011101189     2016          1080      546800   \n",
       "959999    33410  2009101968     2017          1006      618002   \n",
       "\n",
       "        UM_BreederCode  Odds     Kyori  TenkoBaba$DirtBabaCD_0  \\\n",
       "0               233071  1220 -1.045283                     0.0   \n",
       "1               913124  5035 -1.045283                     0.0   \n",
       "2               833098  2165 -1.045283                     1.0   \n",
       "3               900515    59 -1.045283                     0.0   \n",
       "4               100516  5734 -1.045283                     1.0   \n",
       "...                ...   ...       ...                     ...   \n",
       "959995          704079    55  2.978674                     1.0   \n",
       "959996          703084    24  2.978674                     1.0   \n",
       "959997          213326   199  2.978674                     1.0   \n",
       "959998          133090    39  2.978674                     1.0   \n",
       "959999             365   100  2.978674                     1.0   \n",
       "\n",
       "        TenkoBaba$SibaBabaCD_0  ...  KS_Syotai_川崎　　　　　　　　  \\\n",
       "0                          1.0  ...                   0.0   \n",
       "1                          1.0  ...                   0.0   \n",
       "2                          0.0  ...                   0.0   \n",
       "3                          1.0  ...                   0.0   \n",
       "4                          0.0  ...                   0.0   \n",
       "...                        ...  ...                   ...   \n",
       "959995                     0.0  ...                   0.0   \n",
       "959996                     0.0  ...                   0.0   \n",
       "959997                     0.0  ...                   0.0   \n",
       "959998                     0.0  ...                   0.0   \n",
       "959999                     0.0  ...                   0.0   \n",
       "\n",
       "        KS_Syotai_笠松　　　　　　　　  id$JyoCD_1  KS_ChokyosiCode_365.0  \\\n",
       "0                        0.0         0.0                    0.0   \n",
       "1                        0.0         0.0                    0.0   \n",
       "2                        0.0         0.0                    0.0   \n",
       "3                        0.0         0.0                    0.0   \n",
       "4                        0.0         0.0                    0.0   \n",
       "...                      ...         ...                    ...   \n",
       "959995                   0.0         0.0                    0.0   \n",
       "959996                   0.0         0.0                    0.0   \n",
       "959997                   0.0         0.0                    0.0   \n",
       "959998                   0.0         0.0                    0.0   \n",
       "959999                   0.0         0.0                    0.0   \n",
       "\n",
       "        CH_Syotai_川崎　　　　　　　　  top2_ChokyosiCode  top2_BanusiCode  \\\n",
       "0                        0.0           0.099681        -0.557335   \n",
       "1                        0.0          -0.931447         0.343967   \n",
       "2                        0.0          -0.812923        -1.334369   \n",
       "3                        0.0          -0.359324        -1.594419   \n",
       "4                        0.0          -1.015901        -1.741161   \n",
       "...                      ...                ...              ...   \n",
       "959995                   0.0          -0.314826        -0.514318   \n",
       "959996                   0.0           3.526010        -0.510523   \n",
       "959997                   0.0          -0.193960         0.161274   \n",
       "959998                   0.0          -0.328563         0.020384   \n",
       "959999                   0.0          -1.114980        -1.722283   \n",
       "\n",
       "        top2_UM_BreederCode  before_Odds      speed  \n",
       "0                 -0.287502    -0.492083  57.831325  \n",
       "1                  0.539699     2.236292  59.178082  \n",
       "2                 -0.519851     3.673875  59.340659  \n",
       "3                 -1.553278    -0.580643  59.586207  \n",
       "4                 -0.621870     1.134751  61.016949  \n",
       "...                     ...          ...        ...  \n",
       "959995             0.306801    -0.652219  54.047244  \n",
       "959996            -0.349731    -0.607332  54.047244  \n",
       "959997            -0.494214    -0.634022  54.189474  \n",
       "959998            -0.243707    -0.058988  53.181818  \n",
       "959999            -0.146472    -0.293127  54.075630  \n",
       "\n",
       "[960000 rows x 212 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "new_train_data = pd.merge(filter_balance_id, train_data, on=['race_id', 'KettoNum'], how='left')\n",
    "new_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id$Year</th>\n",
       "      <th>race_id</th>\n",
       "      <th>KettoNum</th>\n",
       "      <th>speed</th>\n",
       "      <th>Time</th>\n",
       "      <th>KakuteiJyuni</th>\n",
       "      <th>top3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>12135</td>\n",
       "      <td>2009100729</td>\n",
       "      <td>59.833795</td>\n",
       "      <td>72.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>26439</td>\n",
       "      <td>2011103176</td>\n",
       "      <td>58.230257</td>\n",
       "      <td>105.10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>33661</td>\n",
       "      <td>2013100779</td>\n",
       "      <td>57.920792</td>\n",
       "      <td>161.60</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>28482</td>\n",
       "      <td>2011105992</td>\n",
       "      <td>60.876249</td>\n",
       "      <td>130.10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>291</td>\n",
       "      <td>2004104307</td>\n",
       "      <td>57.627119</td>\n",
       "      <td>106.20</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475191</th>\n",
       "      <td>2013</td>\n",
       "      <td>18201</td>\n",
       "      <td>2005106482</td>\n",
       "      <td>49.966265</td>\n",
       "      <td>207.50</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475192</th>\n",
       "      <td>2010</td>\n",
       "      <td>7309</td>\n",
       "      <td>2006102916</td>\n",
       "      <td>60.301508</td>\n",
       "      <td>59.70</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475193</th>\n",
       "      <td>2012</td>\n",
       "      <td>16882</td>\n",
       "      <td>2007104657</td>\n",
       "      <td>62.113587</td>\n",
       "      <td>69.55</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475194</th>\n",
       "      <td>2010</td>\n",
       "      <td>8963</td>\n",
       "      <td>2007104503</td>\n",
       "      <td>60.050042</td>\n",
       "      <td>59.95</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475195</th>\n",
       "      <td>2017</td>\n",
       "      <td>32570</td>\n",
       "      <td>2014103689</td>\n",
       "      <td>57.849197</td>\n",
       "      <td>80.90</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475196 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id$Year  race_id    KettoNum      speed    Time  KakuteiJyuni  top3\n",
       "0          2011    12135  2009100729  59.833795   72.20             1     1\n",
       "1          2015    26439  2011103176  58.230257  105.10             1     1\n",
       "2          2017    33661  2013100779  57.920792  161.60            11     0\n",
       "3          2016    28482  2011105992  60.876249  130.10             2     1\n",
       "4          2008      291  2004104307  57.627119  106.20             5     0\n",
       "...         ...      ...         ...        ...     ...           ...   ...\n",
       "475191     2013    18201  2005106482  49.966265  207.50            13     0\n",
       "475192     2010     7309  2006102916  60.301508   59.70             8     0\n",
       "475193     2012    16882  2007104657  62.113587   69.55             6     0\n",
       "475194     2010     8963  2007104503  60.050042   59.95             5     0\n",
       "475195     2017    32570  2014103689  57.849197   80.90             8     0\n",
       "\n",
       "[475196 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 390 ms\n"
     ]
    }
   ],
   "source": [
    "y_train_df = pd.read_csv('y_train_df_all.csv')\n",
    "y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>KettoNum</th>\n",
       "      <th>id$Year</th>\n",
       "      <th>speed</th>\n",
       "      <th>Time</th>\n",
       "      <th>KakuteiJyuni</th>\n",
       "      <th>top3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22122</td>\n",
       "      <td>2009103322</td>\n",
       "      <td>2014</td>\n",
       "      <td>57.831325</td>\n",
       "      <td>74.7</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16279</td>\n",
       "      <td>2007105563</td>\n",
       "      <td>2012</td>\n",
       "      <td>59.178082</td>\n",
       "      <td>73.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25168</td>\n",
       "      <td>2012102374</td>\n",
       "      <td>2015</td>\n",
       "      <td>59.340659</td>\n",
       "      <td>72.8</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21375</td>\n",
       "      <td>2011106150</td>\n",
       "      <td>2014</td>\n",
       "      <td>59.586207</td>\n",
       "      <td>72.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12820</td>\n",
       "      <td>2009100419</td>\n",
       "      <td>2011</td>\n",
       "      <td>61.016949</td>\n",
       "      <td>70.8</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959995</th>\n",
       "      <td>33275</td>\n",
       "      <td>2009103514</td>\n",
       "      <td>2017</td>\n",
       "      <td>54.047244</td>\n",
       "      <td>190.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959996</th>\n",
       "      <td>29845</td>\n",
       "      <td>2010102928</td>\n",
       "      <td>2016</td>\n",
       "      <td>54.047244</td>\n",
       "      <td>190.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959997</th>\n",
       "      <td>33410</td>\n",
       "      <td>2011106314</td>\n",
       "      <td>2017</td>\n",
       "      <td>54.189474</td>\n",
       "      <td>190.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959998</th>\n",
       "      <td>29845</td>\n",
       "      <td>2011101189</td>\n",
       "      <td>2016</td>\n",
       "      <td>53.181818</td>\n",
       "      <td>193.6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959999</th>\n",
       "      <td>33410</td>\n",
       "      <td>2009101968</td>\n",
       "      <td>2017</td>\n",
       "      <td>54.075630</td>\n",
       "      <td>190.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        race_id    KettoNum  id$Year      speed   Time  KakuteiJyuni  top3\n",
       "0         22122  2009103322     2014  57.831325   74.7            15     0\n",
       "1         16279  2007105563     2012  59.178082   73.0            12     0\n",
       "2         25168  2012102374     2015  59.340659   72.8            16     0\n",
       "3         21375  2011106150     2014  59.586207   72.5             5     0\n",
       "4         12820  2009100419     2011  61.016949   70.8            12     0\n",
       "...         ...         ...      ...        ...    ...           ...   ...\n",
       "959995    33275  2009103514     2017  54.047244  190.5             4     0\n",
       "959996    29845  2010102928     2016  54.047244  190.5             1     1\n",
       "959997    33410  2011106314     2017  54.189474  190.0             5     0\n",
       "959998    29845  2011101189     2016  53.181818  193.6             8     0\n",
       "959999    33410  2009101968     2017  54.075630  190.4             6     0\n",
       "\n",
       "[960000 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 343 ms\n"
     ]
    }
   ],
   "source": [
    "y_train_df = pd.merge(filter_balance_id, y_train_df, on=['race_id', 'KettoNum'], how='left')\n",
    "y_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shuffle dữ liệu train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>KettoNum</th>\n",
       "      <th>id$Year</th>\n",
       "      <th>ChokyosiCode</th>\n",
       "      <th>BanusiCode</th>\n",
       "      <th>UM_BreederCode</th>\n",
       "      <th>Odds</th>\n",
       "      <th>Kyori</th>\n",
       "      <th>TenkoBaba$DirtBabaCD_0</th>\n",
       "      <th>TenkoBaba$SibaBabaCD_0</th>\n",
       "      <th>...</th>\n",
       "      <th>KS_ChokyosiCode_365.0</th>\n",
       "      <th>CH_Syotai_川崎</th>\n",
       "      <th>top2_ChokyosiCode</th>\n",
       "      <th>top2_BanusiCode</th>\n",
       "      <th>top2_UM_BreederCode</th>\n",
       "      <th>before_Odds</th>\n",
       "      <th>speed</th>\n",
       "      <th>Time</th>\n",
       "      <th>KakuteiJyuni</th>\n",
       "      <th>top3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22122</td>\n",
       "      <td>2009103322</td>\n",
       "      <td>2014</td>\n",
       "      <td>341</td>\n",
       "      <td>639009</td>\n",
       "      <td>233071</td>\n",
       "      <td>1220</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099681</td>\n",
       "      <td>-0.557335</td>\n",
       "      <td>-0.287502</td>\n",
       "      <td>-0.492083</td>\n",
       "      <td>57.831325</td>\n",
       "      <td>74.7</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16279</td>\n",
       "      <td>2007105563</td>\n",
       "      <td>2012</td>\n",
       "      <td>1031</td>\n",
       "      <td>441030</td>\n",
       "      <td>913124</td>\n",
       "      <td>5035</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.931447</td>\n",
       "      <td>0.343967</td>\n",
       "      <td>0.539699</td>\n",
       "      <td>2.236292</td>\n",
       "      <td>59.178082</td>\n",
       "      <td>73.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25168</td>\n",
       "      <td>2012102374</td>\n",
       "      <td>2015</td>\n",
       "      <td>1096</td>\n",
       "      <td>125009</td>\n",
       "      <td>833098</td>\n",
       "      <td>2165</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.812923</td>\n",
       "      <td>-1.334369</td>\n",
       "      <td>-0.519851</td>\n",
       "      <td>3.673875</td>\n",
       "      <td>59.340659</td>\n",
       "      <td>72.8</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21375</td>\n",
       "      <td>2011106150</td>\n",
       "      <td>2014</td>\n",
       "      <td>359</td>\n",
       "      <td>629800</td>\n",
       "      <td>900515</td>\n",
       "      <td>59</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.359324</td>\n",
       "      <td>-1.594419</td>\n",
       "      <td>-1.553278</td>\n",
       "      <td>-0.580643</td>\n",
       "      <td>59.586207</td>\n",
       "      <td>72.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12820</td>\n",
       "      <td>2009100419</td>\n",
       "      <td>2011</td>\n",
       "      <td>1014</td>\n",
       "      <td>959030</td>\n",
       "      <td>100516</td>\n",
       "      <td>5734</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.015901</td>\n",
       "      <td>-1.741161</td>\n",
       "      <td>-0.621870</td>\n",
       "      <td>1.134751</td>\n",
       "      <td>61.016949</td>\n",
       "      <td>70.8</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959995</th>\n",
       "      <td>33275</td>\n",
       "      <td>2009103514</td>\n",
       "      <td>2017</td>\n",
       "      <td>1091</td>\n",
       "      <td>382004</td>\n",
       "      <td>704079</td>\n",
       "      <td>55</td>\n",
       "      <td>2.978674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.314826</td>\n",
       "      <td>-0.514318</td>\n",
       "      <td>0.306801</td>\n",
       "      <td>-0.652219</td>\n",
       "      <td>54.047244</td>\n",
       "      <td>190.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959996</th>\n",
       "      <td>29845</td>\n",
       "      <td>2010102928</td>\n",
       "      <td>2016</td>\n",
       "      <td>1055</td>\n",
       "      <td>547800</td>\n",
       "      <td>703084</td>\n",
       "      <td>24</td>\n",
       "      <td>2.978674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.526010</td>\n",
       "      <td>-0.510523</td>\n",
       "      <td>-0.349731</td>\n",
       "      <td>-0.607332</td>\n",
       "      <td>54.047244</td>\n",
       "      <td>190.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959997</th>\n",
       "      <td>33410</td>\n",
       "      <td>2011106314</td>\n",
       "      <td>2017</td>\n",
       "      <td>261</td>\n",
       "      <td>494800</td>\n",
       "      <td>213326</td>\n",
       "      <td>199</td>\n",
       "      <td>2.978674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.193960</td>\n",
       "      <td>0.161274</td>\n",
       "      <td>-0.494214</td>\n",
       "      <td>-0.634022</td>\n",
       "      <td>54.189474</td>\n",
       "      <td>190.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959998</th>\n",
       "      <td>29845</td>\n",
       "      <td>2011101189</td>\n",
       "      <td>2016</td>\n",
       "      <td>1080</td>\n",
       "      <td>546800</td>\n",
       "      <td>133090</td>\n",
       "      <td>39</td>\n",
       "      <td>2.978674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.328563</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>-0.243707</td>\n",
       "      <td>-0.058988</td>\n",
       "      <td>53.181818</td>\n",
       "      <td>193.6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959999</th>\n",
       "      <td>33410</td>\n",
       "      <td>2009101968</td>\n",
       "      <td>2017</td>\n",
       "      <td>1006</td>\n",
       "      <td>618002</td>\n",
       "      <td>365</td>\n",
       "      <td>100</td>\n",
       "      <td>2.978674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.114980</td>\n",
       "      <td>-1.722283</td>\n",
       "      <td>-0.146472</td>\n",
       "      <td>-0.293127</td>\n",
       "      <td>54.075630</td>\n",
       "      <td>190.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960000 rows × 215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        race_id    KettoNum  id$Year  ChokyosiCode  BanusiCode  \\\n",
       "0         22122  2009103322     2014           341      639009   \n",
       "1         16279  2007105563     2012          1031      441030   \n",
       "2         25168  2012102374     2015          1096      125009   \n",
       "3         21375  2011106150     2014           359      629800   \n",
       "4         12820  2009100419     2011          1014      959030   \n",
       "...         ...         ...      ...           ...         ...   \n",
       "959995    33275  2009103514     2017          1091      382004   \n",
       "959996    29845  2010102928     2016          1055      547800   \n",
       "959997    33410  2011106314     2017           261      494800   \n",
       "959998    29845  2011101189     2016          1080      546800   \n",
       "959999    33410  2009101968     2017          1006      618002   \n",
       "\n",
       "        UM_BreederCode  Odds     Kyori  TenkoBaba$DirtBabaCD_0  \\\n",
       "0               233071  1220 -1.045283                     0.0   \n",
       "1               913124  5035 -1.045283                     0.0   \n",
       "2               833098  2165 -1.045283                     1.0   \n",
       "3               900515    59 -1.045283                     0.0   \n",
       "4               100516  5734 -1.045283                     1.0   \n",
       "...                ...   ...       ...                     ...   \n",
       "959995          704079    55  2.978674                     1.0   \n",
       "959996          703084    24  2.978674                     1.0   \n",
       "959997          213326   199  2.978674                     1.0   \n",
       "959998          133090    39  2.978674                     1.0   \n",
       "959999             365   100  2.978674                     1.0   \n",
       "\n",
       "        TenkoBaba$SibaBabaCD_0  ...  KS_ChokyosiCode_365.0  \\\n",
       "0                          1.0  ...                    0.0   \n",
       "1                          1.0  ...                    0.0   \n",
       "2                          0.0  ...                    0.0   \n",
       "3                          1.0  ...                    0.0   \n",
       "4                          0.0  ...                    0.0   \n",
       "...                        ...  ...                    ...   \n",
       "959995                     0.0  ...                    0.0   \n",
       "959996                     0.0  ...                    0.0   \n",
       "959997                     0.0  ...                    0.0   \n",
       "959998                     0.0  ...                    0.0   \n",
       "959999                     0.0  ...                    0.0   \n",
       "\n",
       "        CH_Syotai_川崎　　　　　　　　  top2_ChokyosiCode  top2_BanusiCode  \\\n",
       "0                        0.0           0.099681        -0.557335   \n",
       "1                        0.0          -0.931447         0.343967   \n",
       "2                        0.0          -0.812923        -1.334369   \n",
       "3                        0.0          -0.359324        -1.594419   \n",
       "4                        0.0          -1.015901        -1.741161   \n",
       "...                      ...                ...              ...   \n",
       "959995                   0.0          -0.314826        -0.514318   \n",
       "959996                   0.0           3.526010        -0.510523   \n",
       "959997                   0.0          -0.193960         0.161274   \n",
       "959998                   0.0          -0.328563         0.020384   \n",
       "959999                   0.0          -1.114980        -1.722283   \n",
       "\n",
       "        top2_UM_BreederCode  before_Odds      speed   Time  KakuteiJyuni  top3  \n",
       "0                 -0.287502    -0.492083  57.831325   74.7            15     0  \n",
       "1                  0.539699     2.236292  59.178082   73.0            12     0  \n",
       "2                 -0.519851     3.673875  59.340659   72.8            16     0  \n",
       "3                 -1.553278    -0.580643  59.586207   72.5             5     0  \n",
       "4                 -0.621870     1.134751  61.016949   70.8            12     0  \n",
       "...                     ...          ...        ...    ...           ...   ...  \n",
       "959995             0.306801    -0.652219  54.047244  190.5             4     0  \n",
       "959996            -0.349731    -0.607332  54.047244  190.5             1     1  \n",
       "959997            -0.494214    -0.634022  54.189474  190.0             5     0  \n",
       "959998            -0.243707    -0.058988  53.181818  193.6             8     0  \n",
       "959999            -0.146472    -0.293127  54.075630  190.4             6     0  \n",
       "\n",
       "[960000 rows x 215 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 734 ms\n"
     ]
    }
   ],
   "source": [
    "new_train_data = pd.concat([new_train_data, y_train_df[['Time', 'KakuteiJyuni', 'top3']]], axis=1, sort=False)\n",
    "new_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>KettoNum</th>\n",
       "      <th>id$Year</th>\n",
       "      <th>ChokyosiCode</th>\n",
       "      <th>BanusiCode</th>\n",
       "      <th>UM_BreederCode</th>\n",
       "      <th>Odds</th>\n",
       "      <th>Kyori</th>\n",
       "      <th>TenkoBaba$DirtBabaCD_0</th>\n",
       "      <th>TenkoBaba$SibaBabaCD_0</th>\n",
       "      <th>...</th>\n",
       "      <th>KS_ChokyosiCode_365.0</th>\n",
       "      <th>CH_Syotai_川崎</th>\n",
       "      <th>top2_ChokyosiCode</th>\n",
       "      <th>top2_BanusiCode</th>\n",
       "      <th>top2_UM_BreederCode</th>\n",
       "      <th>before_Odds</th>\n",
       "      <th>speed</th>\n",
       "      <th>Time</th>\n",
       "      <th>KakuteiJyuni</th>\n",
       "      <th>top3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30395</td>\n",
       "      <td>2010102488</td>\n",
       "      <td>2016</td>\n",
       "      <td>1141</td>\n",
       "      <td>136007</td>\n",
       "      <td>233071</td>\n",
       "      <td>39</td>\n",
       "      <td>3.924061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.493248</td>\n",
       "      <td>0.706178</td>\n",
       "      <td>-0.287502</td>\n",
       "      <td>-0.694679</td>\n",
       "      <td>54.079039</td>\n",
       "      <td>216.35</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4807</td>\n",
       "      <td>2004102270</td>\n",
       "      <td>2009</td>\n",
       "      <td>1031</td>\n",
       "      <td>317002</td>\n",
       "      <td>400018</td>\n",
       "      <td>273</td>\n",
       "      <td>4.008904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.931447</td>\n",
       "      <td>-0.469995</td>\n",
       "      <td>0.392597</td>\n",
       "      <td>-0.466607</td>\n",
       "      <td>54.222834</td>\n",
       "      <td>218.10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26452</td>\n",
       "      <td>2013103464</td>\n",
       "      <td>2015</td>\n",
       "      <td>1147</td>\n",
       "      <td>445033</td>\n",
       "      <td>500426</td>\n",
       "      <td>1027</td>\n",
       "      <td>-0.318062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139160</td>\n",
       "      <td>-0.754837</td>\n",
       "      <td>-0.819861</td>\n",
       "      <td>0.338925</td>\n",
       "      <td>58.823529</td>\n",
       "      <td>91.80</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14770</td>\n",
       "      <td>2008103875</td>\n",
       "      <td>2012</td>\n",
       "      <td>431</td>\n",
       "      <td>453006</td>\n",
       "      <td>203061</td>\n",
       "      <td>518</td>\n",
       "      <td>0.893973</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.486647</td>\n",
       "      <td>-0.810637</td>\n",
       "      <td>-0.294696</td>\n",
       "      <td>-0.479952</td>\n",
       "      <td>59.064807</td>\n",
       "      <td>121.90</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11389</td>\n",
       "      <td>2005102326</td>\n",
       "      <td>2011</td>\n",
       "      <td>349</td>\n",
       "      <td>415800</td>\n",
       "      <td>393126</td>\n",
       "      <td>20</td>\n",
       "      <td>3.318044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397126</td>\n",
       "      <td>1.811460</td>\n",
       "      <td>1.335489</td>\n",
       "      <td>-0.698319</td>\n",
       "      <td>51.848296</td>\n",
       "      <td>208.30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959995</th>\n",
       "      <td>22551</td>\n",
       "      <td>2007105770</td>\n",
       "      <td>2014</td>\n",
       "      <td>390</td>\n",
       "      <td>546800</td>\n",
       "      <td>833394</td>\n",
       "      <td>238</td>\n",
       "      <td>0.166752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.470950</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>-0.114694</td>\n",
       "      <td>-0.373194</td>\n",
       "      <td>58.257972</td>\n",
       "      <td>105.05</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959996</th>\n",
       "      <td>32233</td>\n",
       "      <td>2014101517</td>\n",
       "      <td>2017</td>\n",
       "      <td>1014</td>\n",
       "      <td>390002</td>\n",
       "      <td>362</td>\n",
       "      <td>101</td>\n",
       "      <td>1.621195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.015901</td>\n",
       "      <td>0.253301</td>\n",
       "      <td>-1.031031</td>\n",
       "      <td>-0.646153</td>\n",
       "      <td>58.392102</td>\n",
       "      <td>141.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959997</th>\n",
       "      <td>20926</td>\n",
       "      <td>2009106062</td>\n",
       "      <td>2014</td>\n",
       "      <td>362</td>\n",
       "      <td>398002</td>\n",
       "      <td>373126</td>\n",
       "      <td>45</td>\n",
       "      <td>4.117987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.303529</td>\n",
       "      <td>1.432089</td>\n",
       "      <td>2.085967</td>\n",
       "      <td>-0.652219</td>\n",
       "      <td>54.490909</td>\n",
       "      <td>220.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959998</th>\n",
       "      <td>26535</td>\n",
       "      <td>2012105338</td>\n",
       "      <td>2015</td>\n",
       "      <td>411</td>\n",
       "      <td>523005</td>\n",
       "      <td>10013</td>\n",
       "      <td>327</td>\n",
       "      <td>3.075637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.669744</td>\n",
       "      <td>-0.260005</td>\n",
       "      <td>0.307531</td>\n",
       "      <td>1.086225</td>\n",
       "      <td>52.700656</td>\n",
       "      <td>198.10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959999</th>\n",
       "      <td>119</td>\n",
       "      <td>2003110218</td>\n",
       "      <td>2008</td>\n",
       "      <td>361</td>\n",
       "      <td>674004</td>\n",
       "      <td>620884</td>\n",
       "      <td>895</td>\n",
       "      <td>3.778617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.622906</td>\n",
       "      <td>-1.306386</td>\n",
       "      <td>-0.327030</td>\n",
       "      <td>0.072652</td>\n",
       "      <td>53.463687</td>\n",
       "      <td>214.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960000 rows × 215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        race_id    KettoNum  id$Year  ChokyosiCode  BanusiCode  \\\n",
       "0         30395  2010102488     2016          1141      136007   \n",
       "1          4807  2004102270     2009          1031      317002   \n",
       "2         26452  2013103464     2015          1147      445033   \n",
       "3         14770  2008103875     2012           431      453006   \n",
       "4         11389  2005102326     2011           349      415800   \n",
       "...         ...         ...      ...           ...         ...   \n",
       "959995    22551  2007105770     2014           390      546800   \n",
       "959996    32233  2014101517     2017          1014      390002   \n",
       "959997    20926  2009106062     2014           362      398002   \n",
       "959998    26535  2012105338     2015           411      523005   \n",
       "959999      119  2003110218     2008           361      674004   \n",
       "\n",
       "        UM_BreederCode  Odds     Kyori  TenkoBaba$DirtBabaCD_0  \\\n",
       "0               233071    39  3.924061                     1.0   \n",
       "1               400018   273  4.008904                     0.0   \n",
       "2               500426  1027 -0.318062                     1.0   \n",
       "3               203061   518  0.893973                     1.0   \n",
       "4               393126    20  3.318044                     0.0   \n",
       "...                ...   ...       ...                     ...   \n",
       "959995          833394   238  0.166752                     0.0   \n",
       "959996             362   101  1.621195                     1.0   \n",
       "959997          373126    45  4.117987                     1.0   \n",
       "959998           10013   327  3.075637                     1.0   \n",
       "959999          620884   895  3.778617                     0.0   \n",
       "\n",
       "        TenkoBaba$SibaBabaCD_0  ...  KS_ChokyosiCode_365.0  \\\n",
       "0                          0.0  ...                    0.0   \n",
       "1                          0.0  ...                    0.0   \n",
       "2                          0.0  ...                    0.0   \n",
       "3                          0.0  ...                    0.0   \n",
       "4                          0.0  ...                    0.0   \n",
       "...                        ...  ...                    ...   \n",
       "959995                     1.0  ...                    0.0   \n",
       "959996                     0.0  ...                    0.0   \n",
       "959997                     0.0  ...                    0.0   \n",
       "959998                     0.0  ...                    0.0   \n",
       "959999                     0.0  ...                    0.0   \n",
       "\n",
       "        CH_Syotai_川崎　　　　　　　　  top2_ChokyosiCode  top2_BanusiCode  \\\n",
       "0                        0.0          -0.493248         0.706178   \n",
       "1                        0.0          -0.931447        -0.469995   \n",
       "2                        0.0           0.139160        -0.754837   \n",
       "3                        0.0          -0.486647        -0.810637   \n",
       "4                        0.0           0.397126         1.811460   \n",
       "...                      ...                ...              ...   \n",
       "959995                   0.0           0.470950         0.020384   \n",
       "959996                   0.0          -1.015901         0.253301   \n",
       "959997                   0.0           1.303529         1.432089   \n",
       "959998                   0.0           0.669744        -0.260005   \n",
       "959999                   0.0          -1.622906        -1.306386   \n",
       "\n",
       "        top2_UM_BreederCode  before_Odds      speed    Time  KakuteiJyuni  \\\n",
       "0                 -0.287502    -0.694679  54.079039  216.35             5   \n",
       "1                  0.392597    -0.466607  54.222834  218.10             4   \n",
       "2                 -0.819861     0.338925  58.823529   91.80            10   \n",
       "3                 -0.294696    -0.479952  59.064807  121.90             8   \n",
       "4                  1.335489    -0.698319  51.848296  208.30             3   \n",
       "...                     ...          ...        ...     ...           ...   \n",
       "959995            -0.114694    -0.373194  58.257972  105.05             4   \n",
       "959996            -1.031031    -0.646153  58.392102  141.80             2   \n",
       "959997             2.085967    -0.652219  54.490909  220.00             2   \n",
       "959998             0.307531     1.086225  52.700656  198.10             5   \n",
       "959999            -0.327030     0.072652  53.463687  214.80             3   \n",
       "\n",
       "        top3  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  \n",
       "...      ...  \n",
       "959995     0  \n",
       "959996     1  \n",
       "959997     1  \n",
       "959998     0  \n",
       "959999     1  \n",
       "\n",
       "[960000 rows x 215 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.75 s\n"
     ]
    }
   ],
   "source": [
    "new_train_data = new_train_data.sample(frac=1).reset_index(drop=True)\n",
    "new_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kyori</th>\n",
       "      <th>TenkoBaba$DirtBabaCD_0</th>\n",
       "      <th>TenkoBaba$SibaBabaCD_0</th>\n",
       "      <th>TenkoBaba$SibaBabaCD_1</th>\n",
       "      <th>TenkoBaba$DirtBabaCD_1</th>\n",
       "      <th>id$RaceNum</th>\n",
       "      <th>TrackCD_52</th>\n",
       "      <th>TrackCD_17</th>\n",
       "      <th>JyokenInfo$SyubetuCD_18</th>\n",
       "      <th>GradeCD_</th>\n",
       "      <th>...</th>\n",
       "      <th>KS_Syotai_フランス</th>\n",
       "      <th>KS_Syotai_川崎</th>\n",
       "      <th>KS_Syotai_笠松</th>\n",
       "      <th>id$JyoCD_1</th>\n",
       "      <th>KS_ChokyosiCode_365.0</th>\n",
       "      <th>CH_Syotai_川崎</th>\n",
       "      <th>top2_ChokyosiCode</th>\n",
       "      <th>top2_BanusiCode</th>\n",
       "      <th>top2_UM_BreederCode</th>\n",
       "      <th>before_Odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.924061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.673597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.493248</td>\n",
       "      <td>0.706178</td>\n",
       "      <td>-0.287502</td>\n",
       "      <td>-0.694679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.008904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.673597</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.931447</td>\n",
       "      <td>-0.469995</td>\n",
       "      <td>0.392597</td>\n",
       "      <td>-0.466607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.318062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.550314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139160</td>\n",
       "      <td>-0.754837</td>\n",
       "      <td>-0.819861</td>\n",
       "      <td>0.338925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.893973</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.495360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.486647</td>\n",
       "      <td>-0.810637</td>\n",
       "      <td>-0.294696</td>\n",
       "      <td>-0.479952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.318044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.673597</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397126</td>\n",
       "      <td>1.811460</td>\n",
       "      <td>1.335489</td>\n",
       "      <td>-0.698319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959995</th>\n",
       "      <td>0.166752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.664316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.470950</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>-0.114694</td>\n",
       "      <td>-0.373194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959996</th>\n",
       "      <td>1.621195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.381357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.015901</td>\n",
       "      <td>0.253301</td>\n",
       "      <td>-1.031031</td>\n",
       "      <td>-0.646153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959997</th>\n",
       "      <td>4.117987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.381357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.303529</td>\n",
       "      <td>1.432089</td>\n",
       "      <td>2.085967</td>\n",
       "      <td>-0.652219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959998</th>\n",
       "      <td>3.075637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.673597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.669744</td>\n",
       "      <td>-0.260005</td>\n",
       "      <td>0.307531</td>\n",
       "      <td>1.086225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959999</th>\n",
       "      <td>3.778617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.495360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.622906</td>\n",
       "      <td>-1.306386</td>\n",
       "      <td>-0.327030</td>\n",
       "      <td>0.072652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960000 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Kyori  TenkoBaba$DirtBabaCD_0  TenkoBaba$SibaBabaCD_0  \\\n",
       "0       3.924061                     1.0                     0.0   \n",
       "1       4.008904                     0.0                     0.0   \n",
       "2      -0.318062                     1.0                     0.0   \n",
       "3       0.893973                     1.0                     0.0   \n",
       "4       3.318044                     0.0                     0.0   \n",
       "...          ...                     ...                     ...   \n",
       "959995  0.166752                     0.0                     1.0   \n",
       "959996  1.621195                     1.0                     0.0   \n",
       "959997  4.117987                     1.0                     0.0   \n",
       "959998  3.075637                     1.0                     0.0   \n",
       "959999  3.778617                     0.0                     0.0   \n",
       "\n",
       "        TenkoBaba$SibaBabaCD_1  TenkoBaba$DirtBabaCD_1  id$RaceNum  \\\n",
       "0                          1.0                     0.0   -0.673597   \n",
       "1                          1.0                     1.0   -0.673597   \n",
       "2                          1.0                     0.0   -1.550314   \n",
       "3                          0.0                     0.0    0.495360   \n",
       "4                          1.0                     1.0   -0.673597   \n",
       "...                        ...                     ...         ...   \n",
       "959995                     0.0                     0.0    1.664316   \n",
       "959996                     1.0                     0.0   -0.381357   \n",
       "959997                     1.0                     0.0   -0.381357   \n",
       "959998                     1.0                     0.0   -0.673597   \n",
       "959999                     1.0                     1.0    0.495360   \n",
       "\n",
       "        TrackCD_52  TrackCD_17  JyokenInfo$SyubetuCD_18  GradeCD_   ...  \\\n",
       "0              0.0         0.0                      1.0        1.0  ...   \n",
       "1              1.0         0.0                      1.0        1.0  ...   \n",
       "2              0.0         1.0                      0.0        1.0  ...   \n",
       "3              0.0         1.0                      0.0        1.0  ...   \n",
       "4              1.0         0.0                      0.0        1.0  ...   \n",
       "...            ...         ...                      ...        ...  ...   \n",
       "959995         0.0         0.0                      0.0        0.0  ...   \n",
       "959996         0.0         0.0                      0.0        1.0  ...   \n",
       "959997         0.0         0.0                      0.0        1.0  ...   \n",
       "959998         0.0         0.0                      1.0        1.0  ...   \n",
       "959999         1.0         0.0                      0.0        0.0  ...   \n",
       "\n",
       "        KS_Syotai_フランス　　　　　　  KS_Syotai_川崎　　　　　　　　  KS_Syotai_笠松　　　　　　　　  \\\n",
       "0                        0.0                   0.0                   0.0   \n",
       "1                        0.0                   0.0                   0.0   \n",
       "2                        0.0                   0.0                   0.0   \n",
       "3                        0.0                   0.0                   0.0   \n",
       "4                        0.0                   0.0                   0.0   \n",
       "...                      ...                   ...                   ...   \n",
       "959995                   0.0                   0.0                   0.0   \n",
       "959996                   0.0                   0.0                   0.0   \n",
       "959997                   0.0                   0.0                   0.0   \n",
       "959998                   0.0                   0.0                   0.0   \n",
       "959999                   0.0                   0.0                   0.0   \n",
       "\n",
       "        id$JyoCD_1  KS_ChokyosiCode_365.0  CH_Syotai_川崎　　　　　　　　  \\\n",
       "0              0.0                    0.0                   0.0   \n",
       "1              0.0                    0.0                   0.0   \n",
       "2              1.0                    0.0                   0.0   \n",
       "3              0.0                    0.0                   0.0   \n",
       "4              0.0                    0.0                   0.0   \n",
       "...            ...                    ...                   ...   \n",
       "959995         0.0                    0.0                   0.0   \n",
       "959996         0.0                    0.0                   0.0   \n",
       "959997         0.0                    0.0                   0.0   \n",
       "959998         0.0                    0.0                   0.0   \n",
       "959999         0.0                    0.0                   0.0   \n",
       "\n",
       "        top2_ChokyosiCode  top2_BanusiCode  top2_UM_BreederCode  before_Odds  \n",
       "0               -0.493248         0.706178            -0.287502    -0.694679  \n",
       "1               -0.931447        -0.469995             0.392597    -0.466607  \n",
       "2                0.139160        -0.754837            -0.819861     0.338925  \n",
       "3               -0.486647        -0.810637            -0.294696    -0.479952  \n",
       "4                0.397126         1.811460             1.335489    -0.698319  \n",
       "...                   ...              ...                  ...          ...  \n",
       "959995           0.470950         0.020384            -0.114694    -0.373194  \n",
       "959996          -1.015901         0.253301            -1.031031    -0.646153  \n",
       "959997           1.303529         1.432089             2.085967    -0.652219  \n",
       "959998           0.669744        -0.260005             0.307531     1.086225  \n",
       "959999          -1.622906        -1.306386            -0.327030     0.072652  \n",
       "\n",
       "[960000 rows x 204 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 516 ms\n"
     ]
    }
   ],
   "source": [
    "ref_col = ['ChokyosiCode', 'BanusiCode', 'UM_BreederCode', 'Odds']\n",
    "drop_columns = ['race_id', 'KettoNum', 'id$Year', 'speed'] + ref_col + ['Time', 'KakuteiJyuni', 'top3']\n",
    "X_train = new_train_data.drop(drop_columns, axis=1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id$Year</th>\n",
       "      <th>race_id</th>\n",
       "      <th>KettoNum</th>\n",
       "      <th>speed</th>\n",
       "      <th>Time</th>\n",
       "      <th>KakuteiJyuni</th>\n",
       "      <th>top3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>30395</td>\n",
       "      <td>2010102488</td>\n",
       "      <td>54.079039</td>\n",
       "      <td>216.35</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>4807</td>\n",
       "      <td>2004102270</td>\n",
       "      <td>54.222834</td>\n",
       "      <td>218.10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>26452</td>\n",
       "      <td>2013103464</td>\n",
       "      <td>58.823529</td>\n",
       "      <td>91.80</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>14770</td>\n",
       "      <td>2008103875</td>\n",
       "      <td>59.064807</td>\n",
       "      <td>121.90</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>11389</td>\n",
       "      <td>2005102326</td>\n",
       "      <td>51.848296</td>\n",
       "      <td>208.30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959995</th>\n",
       "      <td>2014</td>\n",
       "      <td>22551</td>\n",
       "      <td>2007105770</td>\n",
       "      <td>58.257972</td>\n",
       "      <td>105.05</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959996</th>\n",
       "      <td>2017</td>\n",
       "      <td>32233</td>\n",
       "      <td>2014101517</td>\n",
       "      <td>58.392102</td>\n",
       "      <td>141.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959997</th>\n",
       "      <td>2014</td>\n",
       "      <td>20926</td>\n",
       "      <td>2009106062</td>\n",
       "      <td>54.490909</td>\n",
       "      <td>220.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959998</th>\n",
       "      <td>2015</td>\n",
       "      <td>26535</td>\n",
       "      <td>2012105338</td>\n",
       "      <td>52.700656</td>\n",
       "      <td>198.10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959999</th>\n",
       "      <td>2008</td>\n",
       "      <td>119</td>\n",
       "      <td>2003110218</td>\n",
       "      <td>53.463687</td>\n",
       "      <td>214.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id$Year  race_id    KettoNum      speed    Time  KakuteiJyuni  top3\n",
       "0          2016    30395  2010102488  54.079039  216.35             5     0\n",
       "1          2009     4807  2004102270  54.222834  218.10             4     0\n",
       "2          2015    26452  2013103464  58.823529   91.80            10     0\n",
       "3          2012    14770  2008103875  59.064807  121.90             8     0\n",
       "4          2011    11389  2005102326  51.848296  208.30             3     1\n",
       "...         ...      ...         ...        ...     ...           ...   ...\n",
       "959995     2014    22551  2007105770  58.257972  105.05             4     0\n",
       "959996     2017    32233  2014101517  58.392102  141.80             2     1\n",
       "959997     2014    20926  2009106062  54.490909  220.00             2     1\n",
       "959998     2015    26535  2012105338  52.700656  198.10             5     0\n",
       "959999     2008      119  2003110218  53.463687  214.80             3     1\n",
       "\n",
       "[960000 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms\n"
     ]
    }
   ],
   "source": [
    "y_train_df = new_train_data[['id$Year', 'race_id', 'KettoNum', 'speed', 'Time', 'KakuteiJyuni', 'top3']]\n",
    "y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    960000.000000\n",
       "mean         55.137771\n",
       "std           2.699565\n",
       "min          50.704225\n",
       "25%          53.107438\n",
       "50%          54.181153\n",
       "75%          57.370518\n",
       "max          66.666667\n",
       "Name: speed, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 63 ms\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train_df['speed']\n",
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>KettoNum</th>\n",
       "      <th>id$Year</th>\n",
       "      <th>Kyori</th>\n",
       "      <th>TenkoBaba$DirtBabaCD_0</th>\n",
       "      <th>TenkoBaba$SibaBabaCD_0</th>\n",
       "      <th>TenkoBaba$SibaBabaCD_1</th>\n",
       "      <th>TenkoBaba$DirtBabaCD_1</th>\n",
       "      <th>id$RaceNum</th>\n",
       "      <th>TrackCD_52</th>\n",
       "      <th>...</th>\n",
       "      <th>KS_Syotai_川崎</th>\n",
       "      <th>KS_Syotai_笠松</th>\n",
       "      <th>id$JyoCD_1</th>\n",
       "      <th>KS_ChokyosiCode_365.0</th>\n",
       "      <th>CH_Syotai_川崎</th>\n",
       "      <th>top2_ChokyosiCode</th>\n",
       "      <th>top2_BanusiCode</th>\n",
       "      <th>top2_UM_BreederCode</th>\n",
       "      <th>before_Odds</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34535</td>\n",
       "      <td>2015101022</td>\n",
       "      <td>2018</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.550314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398731</td>\n",
       "      <td>-0.216783</td>\n",
       "      <td>0.174543</td>\n",
       "      <td>-0.638874</td>\n",
       "      <td>58.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34535</td>\n",
       "      <td>2015103483</td>\n",
       "      <td>2018</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.550314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.415822</td>\n",
       "      <td>-0.318228</td>\n",
       "      <td>-1.717806</td>\n",
       "      <td>4.068149</td>\n",
       "      <td>57.908847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34535</td>\n",
       "      <td>2015106010</td>\n",
       "      <td>2018</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.550314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.351113</td>\n",
       "      <td>-2.011561</td>\n",
       "      <td>-0.232294</td>\n",
       "      <td>-0.547888</td>\n",
       "      <td>59.178082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34535</td>\n",
       "      <td>2015102342</td>\n",
       "      <td>2018</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.550314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.812923</td>\n",
       "      <td>-0.653485</td>\n",
       "      <td>-1.837928</td>\n",
       "      <td>0.188494</td>\n",
       "      <td>58.775510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34535</td>\n",
       "      <td>2015102323</td>\n",
       "      <td>2018</td>\n",
       "      <td>-1.045283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.550314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.469803</td>\n",
       "      <td>-0.723257</td>\n",
       "      <td>-0.230315</td>\n",
       "      <td>-0.456902</td>\n",
       "      <td>57.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19140</th>\n",
       "      <td>35925</td>\n",
       "      <td>2014105425</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.409159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.664316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252109</td>\n",
       "      <td>1.811460</td>\n",
       "      <td>1.335489</td>\n",
       "      <td>-0.671629</td>\n",
       "      <td>58.378378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19141</th>\n",
       "      <td>35925</td>\n",
       "      <td>2014105543</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.409159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.664316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.897933</td>\n",
       "      <td>2.023608</td>\n",
       "      <td>1.335489</td>\n",
       "      <td>-0.698319</td>\n",
       "      <td>57.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19142</th>\n",
       "      <td>35925</td>\n",
       "      <td>2011106130</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.409159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.664316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.608380</td>\n",
       "      <td>0.873101</td>\n",
       "      <td>-1.450211</td>\n",
       "      <td>1.291248</td>\n",
       "      <td>57.754011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19143</th>\n",
       "      <td>35925</td>\n",
       "      <td>2012102418</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.409159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.664316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.897933</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.435675</td>\n",
       "      <td>-0.701958</td>\n",
       "      <td>57.497782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19144</th>\n",
       "      <td>35925</td>\n",
       "      <td>2013104045</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.409159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.664316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291467</td>\n",
       "      <td>0.204303</td>\n",
       "      <td>-0.451692</td>\n",
       "      <td>-0.032299</td>\n",
       "      <td>57.243816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19145 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       race_id    KettoNum  id$Year     Kyori  TenkoBaba$DirtBabaCD_0  \\\n",
       "0        34535  2015101022     2018 -1.045283                     0.0   \n",
       "1        34535  2015103483     2018 -1.045283                     0.0   \n",
       "2        34535  2015106010     2018 -1.045283                     0.0   \n",
       "3        34535  2015102342     2018 -1.045283                     0.0   \n",
       "4        34535  2015102323     2018 -1.045283                     0.0   \n",
       "...        ...         ...      ...       ...                     ...   \n",
       "19140    35925  2014105425     2018  0.409159                     0.0   \n",
       "19141    35925  2014105543     2018  0.409159                     0.0   \n",
       "19142    35925  2011106130     2018  0.409159                     0.0   \n",
       "19143    35925  2012102418     2018  0.409159                     0.0   \n",
       "19144    35925  2013104045     2018  0.409159                     0.0   \n",
       "\n",
       "       TenkoBaba$SibaBabaCD_0  TenkoBaba$SibaBabaCD_1  TenkoBaba$DirtBabaCD_1  \\\n",
       "0                         1.0                     0.0                     1.0   \n",
       "1                         1.0                     0.0                     1.0   \n",
       "2                         1.0                     0.0                     1.0   \n",
       "3                         1.0                     0.0                     1.0   \n",
       "4                         1.0                     0.0                     1.0   \n",
       "...                       ...                     ...                     ...   \n",
       "19140                     1.0                     0.0                     1.0   \n",
       "19141                     1.0                     0.0                     1.0   \n",
       "19142                     1.0                     0.0                     1.0   \n",
       "19143                     1.0                     0.0                     1.0   \n",
       "19144                     1.0                     0.0                     1.0   \n",
       "\n",
       "       id$RaceNum  TrackCD_52  ...  KS_Syotai_川崎　　　　　　　　  \\\n",
       "0       -1.550314         0.0  ...                   0.0   \n",
       "1       -1.550314         0.0  ...                   0.0   \n",
       "2       -1.550314         0.0  ...                   0.0   \n",
       "3       -1.550314         0.0  ...                   0.0   \n",
       "4       -1.550314         0.0  ...                   0.0   \n",
       "...           ...         ...  ...                   ...   \n",
       "19140    1.664316         0.0  ...                   0.0   \n",
       "19141    1.664316         0.0  ...                   0.0   \n",
       "19142    1.664316         0.0  ...                   0.0   \n",
       "19143    1.664316         0.0  ...                   0.0   \n",
       "19144    1.664316         0.0  ...                   0.0   \n",
       "\n",
       "       KS_Syotai_笠松　　　　　　　　  id$JyoCD_1  KS_ChokyosiCode_365.0  \\\n",
       "0                       0.0         0.0                    0.0   \n",
       "1                       0.0         0.0                    0.0   \n",
       "2                       0.0         0.0                    0.0   \n",
       "3                       0.0         0.0                    0.0   \n",
       "4                       0.0         0.0                    0.0   \n",
       "...                     ...         ...                    ...   \n",
       "19140                   0.0         0.0                    0.0   \n",
       "19141                   0.0         0.0                    0.0   \n",
       "19142                   0.0         0.0                    0.0   \n",
       "19143                   0.0         0.0                    0.0   \n",
       "19144                   0.0         0.0                    0.0   \n",
       "\n",
       "       CH_Syotai_川崎　　　　　　　　  top2_ChokyosiCode  top2_BanusiCode  \\\n",
       "0                       0.0           0.398731        -0.216783   \n",
       "1                       0.0          -1.415822        -0.318228   \n",
       "2                       0.0          -1.351113        -2.011561   \n",
       "3                       0.0          -0.812923        -0.653485   \n",
       "4                       0.0          -1.469803        -0.723257   \n",
       "...                     ...                ...              ...   \n",
       "19140                   0.0           0.252109         1.811460   \n",
       "19141                   0.0           1.897933         2.023608   \n",
       "19142                   0.0          -0.608380         0.873101   \n",
       "19143                   0.0           1.897933         0.945055   \n",
       "19144                   0.0           0.291467         0.204303   \n",
       "\n",
       "       top2_UM_BreederCode  before_Odds      speed  \n",
       "0                 0.174543    -0.638874  58.064516  \n",
       "1                -1.717806     4.068149  57.908847  \n",
       "2                -0.232294    -0.547888  59.178082  \n",
       "3                -1.837928     0.188494  58.775510  \n",
       "4                -0.230315    -0.456902  57.142857  \n",
       "...                    ...          ...        ...  \n",
       "19140             1.335489    -0.671629  58.378378  \n",
       "19141             1.335489    -0.698319  57.857143  \n",
       "19142            -1.450211     1.291248  57.754011  \n",
       "19143             0.435675    -0.701958  57.497782  \n",
       "19144            -0.451692    -0.032299  57.243816  \n",
       "\n",
       "[19145 rows x 208 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 437 ms\n"
     ]
    }
   ],
   "source": [
    "# Load dữ liệu test\n",
    "test_data = pd.read_csv('test_data_all.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id$Year</th>\n",
       "      <th>race_id</th>\n",
       "      <th>KettoNum</th>\n",
       "      <th>speed</th>\n",
       "      <th>Time</th>\n",
       "      <th>KakuteiJyuni</th>\n",
       "      <th>top3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>34535</td>\n",
       "      <td>2015101022</td>\n",
       "      <td>58.064516</td>\n",
       "      <td>74.4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>34535</td>\n",
       "      <td>2015103483</td>\n",
       "      <td>57.908847</td>\n",
       "      <td>74.6</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>34535</td>\n",
       "      <td>2015106010</td>\n",
       "      <td>59.178082</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>34535</td>\n",
       "      <td>2015102342</td>\n",
       "      <td>58.775510</td>\n",
       "      <td>73.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>34535</td>\n",
       "      <td>2015102323</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>75.6</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19140</th>\n",
       "      <td>2018</td>\n",
       "      <td>35925</td>\n",
       "      <td>2014105425</td>\n",
       "      <td>58.378378</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19141</th>\n",
       "      <td>2018</td>\n",
       "      <td>35925</td>\n",
       "      <td>2014105543</td>\n",
       "      <td>57.857143</td>\n",
       "      <td>112.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19142</th>\n",
       "      <td>2018</td>\n",
       "      <td>35925</td>\n",
       "      <td>2011106130</td>\n",
       "      <td>57.754011</td>\n",
       "      <td>112.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19143</th>\n",
       "      <td>2018</td>\n",
       "      <td>35925</td>\n",
       "      <td>2012102418</td>\n",
       "      <td>57.497782</td>\n",
       "      <td>112.7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19144</th>\n",
       "      <td>2018</td>\n",
       "      <td>35925</td>\n",
       "      <td>2013104045</td>\n",
       "      <td>57.243816</td>\n",
       "      <td>113.2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19145 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id$Year  race_id    KettoNum      speed   Time  KakuteiJyuni  top3\n",
       "0         2018    34535  2015101022  58.064516   74.4            10     0\n",
       "1         2018    34535  2015103483  57.908847   74.6            11     0\n",
       "2         2018    34535  2015106010  59.178082   73.0             2     1\n",
       "3         2018    34535  2015102342  58.775510   73.5             6     0\n",
       "4         2018    34535  2015102323  57.142857   75.6            16     0\n",
       "...        ...      ...         ...        ...    ...           ...   ...\n",
       "19140     2018    35925  2014105425  58.378378  111.0             1     1\n",
       "19141     2018    35925  2014105543  57.857143  112.0             5     0\n",
       "19142     2018    35925  2011106130  57.754011  112.2             6     0\n",
       "19143     2018    35925  2012102418  57.497782  112.7             8     0\n",
       "19144     2018    35925  2013104045  57.243816  113.2            12     0\n",
       "\n",
       "[19145 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 62 ms\n"
     ]
    }
   ],
   "source": [
    "y_test_df = pd.read_csv('y_test_df_all.csv')\n",
    "y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 391 ms\n"
     ]
    }
   ],
   "source": [
    "y_train.hist(bins=100);\n",
    "plt.xlabel('speed');\n",
    "plt.ylabel('frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kyori</th>\n",
       "      <th>TenkoBaba$DirtBabaCD_0</th>\n",
       "      <th>TenkoBaba$SibaBabaCD_0</th>\n",
       "      <th>TenkoBaba$SibaBabaCD_1</th>\n",
       "      <th>TenkoBaba$DirtBabaCD_1</th>\n",
       "      <th>id$RaceNum</th>\n",
       "      <th>TrackCD_52</th>\n",
       "      <th>TrackCD_17</th>\n",
       "      <th>JyokenInfo$SyubetuCD_18</th>\n",
       "      <th>GradeCD_</th>\n",
       "      <th>...</th>\n",
       "      <th>KS_Syotai_フランス</th>\n",
       "      <th>KS_Syotai_川崎</th>\n",
       "      <th>KS_Syotai_笠松</th>\n",
       "      <th>id$JyoCD_1</th>\n",
       "      <th>KS_ChokyosiCode_365.0</th>\n",
       "      <th>CH_Syotai_川崎</th>\n",
       "      <th>top2_ChokyosiCode</th>\n",
       "      <th>top2_BanusiCode</th>\n",
       "      <th>top2_UM_BreederCode</th>\n",
       "      <th>before_Odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.045283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.550314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398731</td>\n",
       "      <td>-0.216783</td>\n",
       "      <td>0.174543</td>\n",
       "      <td>-0.638874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.045283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.550314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.415822</td>\n",
       "      <td>-0.318228</td>\n",
       "      <td>-1.717806</td>\n",
       "      <td>4.068149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.045283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.550314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.351113</td>\n",
       "      <td>-2.011561</td>\n",
       "      <td>-0.232294</td>\n",
       "      <td>-0.547888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.045283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.550314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.812923</td>\n",
       "      <td>-0.653485</td>\n",
       "      <td>-1.837928</td>\n",
       "      <td>0.188494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.045283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.550314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.469803</td>\n",
       "      <td>-0.723257</td>\n",
       "      <td>-0.230315</td>\n",
       "      <td>-0.456902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19140</th>\n",
       "      <td>0.409159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.664316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252109</td>\n",
       "      <td>1.811460</td>\n",
       "      <td>1.335489</td>\n",
       "      <td>-0.671629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19141</th>\n",
       "      <td>0.409159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.664316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.897933</td>\n",
       "      <td>2.023608</td>\n",
       "      <td>1.335489</td>\n",
       "      <td>-0.698319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19142</th>\n",
       "      <td>0.409159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.664316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.608380</td>\n",
       "      <td>0.873101</td>\n",
       "      <td>-1.450211</td>\n",
       "      <td>1.291248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19143</th>\n",
       "      <td>0.409159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.664316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.897933</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.435675</td>\n",
       "      <td>-0.701958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19144</th>\n",
       "      <td>0.409159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.664316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291467</td>\n",
       "      <td>0.204303</td>\n",
       "      <td>-0.451692</td>\n",
       "      <td>-0.032299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19145 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Kyori  TenkoBaba$DirtBabaCD_0  TenkoBaba$SibaBabaCD_0  \\\n",
       "0     -1.045283                     0.0                     1.0   \n",
       "1     -1.045283                     0.0                     1.0   \n",
       "2     -1.045283                     0.0                     1.0   \n",
       "3     -1.045283                     0.0                     1.0   \n",
       "4     -1.045283                     0.0                     1.0   \n",
       "...         ...                     ...                     ...   \n",
       "19140  0.409159                     0.0                     1.0   \n",
       "19141  0.409159                     0.0                     1.0   \n",
       "19142  0.409159                     0.0                     1.0   \n",
       "19143  0.409159                     0.0                     1.0   \n",
       "19144  0.409159                     0.0                     1.0   \n",
       "\n",
       "       TenkoBaba$SibaBabaCD_1  TenkoBaba$DirtBabaCD_1  id$RaceNum  TrackCD_52  \\\n",
       "0                         0.0                     1.0   -1.550314         0.0   \n",
       "1                         0.0                     1.0   -1.550314         0.0   \n",
       "2                         0.0                     1.0   -1.550314         0.0   \n",
       "3                         0.0                     1.0   -1.550314         0.0   \n",
       "4                         0.0                     1.0   -1.550314         0.0   \n",
       "...                       ...                     ...         ...         ...   \n",
       "19140                     0.0                     1.0    1.664316         0.0   \n",
       "19141                     0.0                     1.0    1.664316         0.0   \n",
       "19142                     0.0                     1.0    1.664316         0.0   \n",
       "19143                     0.0                     1.0    1.664316         0.0   \n",
       "19144                     0.0                     1.0    1.664316         0.0   \n",
       "\n",
       "       TrackCD_17  JyokenInfo$SyubetuCD_18  GradeCD_   ...  \\\n",
       "0             0.0                      0.0        1.0  ...   \n",
       "1             0.0                      0.0        1.0  ...   \n",
       "2             0.0                      0.0        1.0  ...   \n",
       "3             0.0                      0.0        1.0  ...   \n",
       "4             0.0                      0.0        1.0  ...   \n",
       "...           ...                      ...        ...  ...   \n",
       "19140         0.0                      0.0        1.0  ...   \n",
       "19141         0.0                      0.0        1.0  ...   \n",
       "19142         0.0                      0.0        1.0  ...   \n",
       "19143         0.0                      0.0        1.0  ...   \n",
       "19144         0.0                      0.0        1.0  ...   \n",
       "\n",
       "       KS_Syotai_フランス　　　　　　  KS_Syotai_川崎　　　　　　　　  KS_Syotai_笠松　　　　　　　　  \\\n",
       "0                       0.0                   0.0                   0.0   \n",
       "1                       0.0                   0.0                   0.0   \n",
       "2                       0.0                   0.0                   0.0   \n",
       "3                       0.0                   0.0                   0.0   \n",
       "4                       0.0                   0.0                   0.0   \n",
       "...                     ...                   ...                   ...   \n",
       "19140                   0.0                   0.0                   0.0   \n",
       "19141                   0.0                   0.0                   0.0   \n",
       "19142                   0.0                   0.0                   0.0   \n",
       "19143                   0.0                   0.0                   0.0   \n",
       "19144                   0.0                   0.0                   0.0   \n",
       "\n",
       "       id$JyoCD_1  KS_ChokyosiCode_365.0  CH_Syotai_川崎　　　　　　　　  \\\n",
       "0             0.0                    0.0                   0.0   \n",
       "1             0.0                    0.0                   0.0   \n",
       "2             0.0                    0.0                   0.0   \n",
       "3             0.0                    0.0                   0.0   \n",
       "4             0.0                    0.0                   0.0   \n",
       "...           ...                    ...                   ...   \n",
       "19140         0.0                    0.0                   0.0   \n",
       "19141         0.0                    0.0                   0.0   \n",
       "19142         0.0                    0.0                   0.0   \n",
       "19143         0.0                    0.0                   0.0   \n",
       "19144         0.0                    0.0                   0.0   \n",
       "\n",
       "       top2_ChokyosiCode  top2_BanusiCode  top2_UM_BreederCode  before_Odds  \n",
       "0               0.398731        -0.216783             0.174543    -0.638874  \n",
       "1              -1.415822        -0.318228            -1.717806     4.068149  \n",
       "2              -1.351113        -2.011561            -0.232294    -0.547888  \n",
       "3              -0.812923        -0.653485            -1.837928     0.188494  \n",
       "4              -1.469803        -0.723257            -0.230315    -0.456902  \n",
       "...                  ...              ...                  ...          ...  \n",
       "19140           0.252109         1.811460             1.335489    -0.671629  \n",
       "19141           1.897933         2.023608             1.335489    -0.698319  \n",
       "19142          -0.608380         0.873101            -1.450211     1.291248  \n",
       "19143           1.897933         0.945055             0.435675    -0.701958  \n",
       "19144           0.291467         0.204303            -0.451692    -0.032299  \n",
       "\n",
       "[19145 rows x 204 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32 ms\n"
     ]
    }
   ],
   "source": [
    "drop_columns = ['race_id', 'KettoNum', 'id$Year', 'speed']\n",
    "X_test = test_data.drop(drop_columns, axis=1)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19145.000000\n",
       "mean        58.013408\n",
       "std          2.305421\n",
       "min         38.876890\n",
       "25%         56.509695\n",
       "50%         58.142665\n",
       "75%         59.558824\n",
       "max         65.573770\n",
       "Name: speed, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "y_test = test_data['speed']\n",
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWHUlEQVR4nO3df5BdZ33f8fcHEYyxArZjZ8ex3MikAgLYOHjr8mOGruIkdrAT0RYXMSYRxBk1jMFu605jN53SNuPBIXH4UWJmFEzixCSLaqDWQMyPiuzQdMA/BARhOy4arBrJRgrBGEQYB5lv/7hHyWW9q3O12nvu3bvv18zOvfe5597zPHNW+uzzPOc8J1WFJElH85RRV0CSNP4MC0lSK8NCktTKsJAktTIsJEmtnjrqCgzLaaedVuvXr+9sf9/5znc46aSTOtvfKNjGyWAbJ8Ow2rhr166vV9Xp88snNizWr1/PPffc09n+5ubmmJmZ6Wx/o2AbJ4NtnAzDamOS/7dQucNQkqRWhoUkqZVhIUlqNbSwSPK+JAeTfKmv7NQkn0zy5ebxlL73rkuyJ8kDSS7qKz8/ye7mvXclybDqLEla2DB7Fn8IXDyv7FpgZ1VtAHY2r0nyfGAz8ILmMzclWdN85j3AVmBD8zP/OyVJQza0sKiqTwPfmFe8CbileX4L8Kq+8tmqeryqHgT2ABckOQN4ZlV9pnorHv5R32ckSR3pes5iqqoeAWgef7QpPxP4at92+5qyM5vn88slSR0al+ssFpqHqKOUL/wlyVZ6Q1ZMTU0xNze3LJUbxKFDhzrd3yjYxslgGydD123sOiwOJDmjqh5phpgONuX7gLP6tlsHPNyUr1ugfEFVtQ3YBjA9PV1dXpTjRUCTwTZOBtu4/LoehtoBbGmebwFu7yvfnOSEJGfTm8i+qxmq+naSlzRnQf1y32ckTZD113707380fobWs0jyp8AMcFqSfcBbgBuA7UmuAB4CLgOoqnuTbAfuAw4DV1bVE81XvZHemVUnAnc0P5KkDg0tLKrqtYu8deEi218PXL9A+T3AC5exapKkY+QV3JKkVuNyNpQk/b3+eYu9N1wywproCHsWkqRWhoUkqZVhIUlqZVhIkloZFpKkVoaFJKmVYSFJamVYSJJaGRaSpFaGhSSplWEhSWplWEiSWhkWkqRWhoUkqZVhIUlqZVhIklp58yNJI9N/kyONN8NC0ljzrnnjwWEoSVIrw0KS1MqwkCS1MiwkSa2c4JY0dE5Sr3z2LCRJrQwLSVIrw0KS1MqwkCS1coJb0rJxInty2bOQJLWyZyFpxbDnMjr2LCRJrUYSFkn+bZJ7k3wpyZ8meXqSU5N8MsmXm8dT+ra/LsmeJA8kuWgUdZak1azzsEhyJnAVMF1VLwTWAJuBa4GdVbUB2Nm8Jsnzm/dfAFwM3JRkTdf1lqTVbFRzFk8FTkzyPeAZwMPAdcBM8/4twBzw68AmYLaqHgceTLIHuAD4TMd1lnQMFruxkTc8WplSVd3vNLkauB74LvCJqro8yTer6uS+bR6tqlOSvBv4bFXd2pTfDNxRVbct8L1bga0AU1NT58/OznbQmp5Dhw6xdu3azvY3CrZxMgyzjbv3PzaU713IOWc+a9H3PI5Lt3Hjxl1VNT2/vPOeRTMXsQk4G/gm8D+SvO5oH1mgbMGEq6ptwDaA6enpmpmZOa66Hou5uTm63N8o2MbJMMw2vr7DXsPey2cWfc/juPxGMcH9M8CDVfXXVfU94EPAy4ADSc4AaB4PNtvvA87q+/w6esNWkqSOjCIsHgJekuQZSQJcCNwP7AC2NNtsAW5vnu8ANic5IcnZwAbgro7rLEmrWufDUFV1Z5LbgM8Bh4HP0xs6WgtsT3IFvUC5rNn+3iTbgfua7a+sqie6rrckrWYjORuqqt4CvGVe8eP0ehkLbX89vQlxSdIIeAW3JKmVa0NJWpFcJ6pb9iwkSa0MC0lSK8NCktTKsJAktTIsJEmtDAtJUivDQpLUyrCQJLUyLCRJrQwLSVIrw0KS1MqwkCS1MiwkSa1cdVbScVnf4X23B6mDK9AOhz0LSVIrw0KS1MqwkCS1MiwkSa0MC0lSK8NCktTKU2clDcTTU1c3exaSpFaGhSSplcNQko7ZOFy1rW7Zs5AktTIsJEmtDAtJUivDQpLUyrCQJLVqDYsk9yS5MskpXVRIkjR+BulZbAZ+DLg7yWySi5JkyPWSJI2R1rCoqj1V9RvAc4A/Ad4HPJTkvyY5dSk7TXJyktuS/FWS+5O8NMmpST6Z5MvN4yl921+XZE+SB5JctJR9SpKWbqA5iyTnAjcCvw18EHg18C3gU0vc7zuBj1XV84AXAfcD1wI7q2oDsLN5TZLn0+vdvAC4GLgpyZol7leStASDzFnsAt4O3A2cW1VXVdWdVXUj8JVj3WGSZwKvAG4GqKq/q6pvApuAW5rNbgFe1TzfBMxW1eNV9SCwB7jgWPcraXVYf+1H2b3/Ma8yX2apqqNvkDy7qo45FI7yfecB24D76PUqdgFXA/ur6uS+7R6tqlOSvBv4bFXd2pTfDNxRVbct8N1bga0AU1NT58/Ozi5XtVsdOnSItWvXdra/UbCNk2Gpbdy9/7Eh1GY4pk6EA9+Fc8581qirMjTD+l3duHHjrqqanl8+yNpQv5rkbc1f/zRzCddU1X9aYl2eCrwYeHNV3ZnknTRDTotYaDJ9wYSrqm30gojp6emamZlZYhWP3dzcHF3ubxRs42RYahtfv4L+Ur/mnMPcuPup7L18ZtRVGZquf1cHmbP4+SNBAVBVjwKvPI597gP2VdWdzevb6IXHgSRnADSPB/u2P6vv8+uAh49j/5KkYzRIWKxJcsKRF0lOBE44yvZHVVVfA76a5LlN0YX0hqR2AFuasi3A7c3zHcDmJCckORvYANy11P1Lko7dIMNQtwI7k/wBveGfX+EfJqKX6s3A+5M8jd4k+RvoBdf2JFcADwGXAVTVvUm20wuUw8CVVfXEce5fknQMWsOiqt6WZDe9HkCA36yqjx/PTqvqC8CTJlCafSy0/fXA9cezT0nS0g1086OqugO4Y8h1kSSNqUGus/gXzVXVjyX5VpJvJ/lWF5WTJI2HQXoWbwN+oaruH3ZlJEnjaZCzoQ4YFJK0ug3Ss7gnyQeA/wk8fqSwqj40rEpJ0nLoX/Jj7w2XjLAmK98gYfFM4G+Bn+srK8CwkKRVYpBTZ9/QRUUkSeNrkLOhnpNkZ5IvNa/PTbLUdaEkSSvQIBPcvw9cB3wPoKq+SO/+EpKkVWKQsHhGVc1fi+nwMCojSRpPg4TF15P8BM2y4EleDTwy1FpJksbKIGdDXUnvHhHPS7IfeBB43VBrJWlkPN1UCxnkbKivAD+T5CTgKVX17eFXS9I4mKRbkxqCx6c1LJL853mvAaiq/zakOkmSxswgw1Df6Xv+dOBSwOU/JGkVGWQY6sb+10l+h97d6yRJq8QgZ0PN9wzg2ctdEUnS+BpkzmI3zWmzwBrgdMD5CklaRQaZs7i07/lhekuWe1GeNEEm6awnDccgYTH/VNlnHjkjCqCqvrGsNZIkjZ1BwuJzwFnAo0CAk4GHmvcK5y8kaeINMsH9MXq3VT2tqn6E3rDUh6rq7KoyKCRpFRgkLP5JVf3ZkRdVdQfwz4ZXJUnSuBlkGOrrzf0rbqU37PQ64G+GWitJ0lgZpGfxWnqny364+Tm9KZMkrRKDXMH9DeDqJGur6lAHdZIkjZlBbqv6siT3Afc1r1+U5Kah10ySNDYGGYZ6O3ARzTxFVf0l8IphVkqSNF4GWhuqqr46r+iJIdRFkjSmBjkb6qtJXgZUkqcBV+ES5ZK0qgzSs/g1erdWPRPYB5zXvJYkrRJH7VkkWQO8o6ou76g+kqQxdNSeRVU9AZzeDD9JklapQeYs9gL/J8kO+m6xWlW/ezw7bnot9wD7q+rSJKcCHwDWN/v8V1X1aLPtdcAV9CbWr6qqjx/PviVJx2bRnkWSP26evgb4SLPtD/f9HK+r+cGJ8muBnVW1AdjZvCbJ84HNwAuAi4GbmqCRJHXkaD2L85P8OL3lyP/7cu40yTrgEuB64N81xZuAmeb5LcAc8OtN+WxVPQ48mGQPcAHwmeWskyRpcamqhd9IrgLeCJwNPNz/FlDHszx5ktuAt9Lrofz7Zhjqm1V1ct82j1bVKUneDXy2qm5tym8G7qiq2xb43q3AVoCpqanzZ2dnl1rFY3bo0CHWrl3b2f5GwTZOhoXauHv/YyOqzXBMnQgHvrv4++ec+azuKjMkw/pd3bhx466qmp5fvmjPoqreBbwryXuq6o3LVZEklwIHq2pXkplBPrJQ9RbasKq2AdsApqena2ZmkK9fHnNzc3S5v1GwjZNhoTa+fsJuq3rNOYe5cffiAyd7L5/prjJD0vXv6iALCS5bUDReDvxiklcCT6d3m9ZbgQNJzqiqR5KcARxstt9H7059R6zjB3s6kqQhG2i5j+VUVddV1bqqWk9v4vpTVfU6YAewpdlsC3B783wHsDnJCUnOBjYAd3VcbWkirL/2o+ze/xjrJ6wnoeEb5NTZrtwAbE9yBb1J9csAqureJNvprXp7GLiyuf5DktSRkYZFVc3RO+uJqvob4MJFtrue3plTkqQR6HwYSpK08hgWkqRW4zRnIUmdmD/Bv/eGS0ZUk5XDnoUkqZVhIUlqZVhIklo5ZyGtUl6Yp2Nhz0KS1MqwkCS1MiwkSa0MC0lSKye4pQnmJLaWiz0LSVIrw0KS1MqwkCS1cs5CmjDOU2gYDAtJq15/wLoC7cIchpIktTIsJEmtDAtJUivDQpLUyrCQJLUyLCRJrQwLSVIrw0KS1MqwkCS1MiwkSa1c7kOS+rj0x8IMC2kCuHighs1hKElSK8NCktTKYShJWoTzF//AsJCkAaz24Oh8GCrJWUn+PMn9Se5NcnVTfmqSTyb5cvN4St9nrkuyJ8kDSS7qus6StNqNYs7iMHBNVf0k8BLgyiTPB64FdlbVBmBn85rmvc3AC4CLgZuSrBlBvSVp1eo8LKrqkar6XPP828D9wJnAJuCWZrNbgFc1zzcBs1X1eFU9COwBLui00pK0yqWqRrfzZD3waeCFwENVdXLfe49W1SlJ3g18tqpubcpvBu6oqtsW+L6twFaAqamp82dnZ4ffiMahQ4dYu3ZtZ/sbBds4vnbvf2zgbadOhAPfHWJlxsCw23jOmc8a3pcPaFi/qxs3btxVVdPzy0c2wZ1kLfBB4N9U1beSLLrpAmULJlxVbQO2AUxPT9fMzMwy1HQwc3NzdLm/UbCN4+UHL8Qb/J/yNecc5sbdk31uy7DbuPfymaF996C6/l0dyXUWSX6IXlC8v6o+1BQfSHJG8/4ZwMGmfB9wVt/H1wEPd1VXSdJozoYKcDNwf1X9bt9bO4AtzfMtwO195ZuTnJDkbGADcFdX9ZUkjWYY6uXALwG7k3yhKfuPwA3A9iRXAA8BlwFU1b1JtgP30TuT6sqqeqLzWkvSKtZ5WFTVX7DwPATAhYt85nrg+qFVSpJ0VJM9yyVNGFeXHT+r5cpuw0KSjtFqDG1XnZUktTIsJEmtDAtJUivDQpLUygluacytxslUjR97FpKkVoaFJKmVYSFJauWchTSGnKfQuLFnIUlqZVhIklo5DCVJy2SSFxW0ZyFJamVYSJJaGRaSpFbOWUjSEEza/IVhIY0Jr63QOHMYSpLUyrCQJLUyLCRJrZyzkEbIeQqtFPYsJEmtDAtJUiuHoaSOOfSklciwkKQhm4QL9AwLqQP2JrTSOWchSWplz0IaEnsTmiSGhbSMDAhNKsNCkjq02B8U4z7xbVhI0hhY7IypcTmTasWERZKLgXcCa4D3VtUNI66SVjGHm7TarIiwSLIG+D3gZ4F9wN1JdlTVfaOtmSR1p/+PlD+8+KRO970iwgK4ANhTVV8BSDILbAIMCwFP/kt/sW58m2vOOczMUb5X6sIgv3e79z/G65vtuhieSlUNfSfHK8mrgYur6leb178E/NOqetO87bYCW5uXzwUe6LCapwFf73B/o2AbJ4NtnAzDauOPV9Xp8wtXSs8iC5Q9KeWqahuwbfjVebIk91TV9Cj23RXbOBls42Touo0r5QrufcBZfa/XAQ+PqC6StOqslLC4G9iQ5OwkTwM2AztGXCdJWjVWxDBUVR1O8ibg4/ROnX1fVd074mrNN5Lhr47ZxslgGydDp21cERPckqTRWinDUJKkETIsJEmtDIslSrImyeeTfKR5fWqSTyb5cvN4yqjreLwWaON/SbI/yRean1eOuo7HI8neJLubttzTlE3UcVykjZN2HE9OcluSv0pyf5KXTuBxXKiNnR5Hw2Lprgbu73t9LbCzqjYAO5vXK938NgK8varOa37+bBSVWmYbm7YcOV99Eo/j/DbCZB3HdwIfq6rnAS+i9zs7acdxoTZCh8fRsFiCJOuAS4D39hVvAm5pnt8CvKrjai2rRdq4GkzUcZx0SZ4JvAK4GaCq/q6qvskEHcejtLFThsXSvAP4D8D3+8qmquoRgObxR0dQr+X0Dp7cRoA3Jflikvet9K49vVUAPpFkV7NUDEzecVyojTA5x/HZwF8Df9AMmb43yUlM1nFcrI3Q4XE0LI5RkkuBg1W1a9R1GZajtPE9wE8A5wGPADd2XLXl9vKqejHw88CVSV4x6goNwUJtnKTj+FTgxcB7quqngO+w8oec5lusjZ0eR8Pi2L0c+MUke4FZ4KeT3AocSHIGQPN4cHRVPG4LtrGqDlTVE1X1feD36a0GvGJV1cPN40Hgw/TaM0nHccE2Tthx3Afsq6o7m9e30fuPdZKO44Jt7Po4GhbHqKquq6p1VbWe3rIjn6qq19FbfmRLs9kW4PYRVfG4LdbGI//4Gv8c+NJIKrgMkpyU5IePPAd+jl57JuY4LtbGSTqOVfU14KtJntsUXUjv1gUTcxwXa2PXx3FFLPexQtwAbE9yBfAQcNmI6zMMb0tyHr1x8L3Avx5pbY7PFPDhJND7d/AnVfWxJHczOcdxsTb+8QQdR4A3A+9v1o37CvAGen8IT8pxhIXb+K4uj6PLfUiSWjkMJUlqZVhIkloZFpKkVoaFJKmVYSFJamVYSCtAkrkk0+1bSsNhWEiSWhkW0hI1V0h/NMlfJvlSktc094/4rSR3NT//uNn29CQfTHJ38/Pyvu94X1P2+SSbmvITk8w2i8R9ADhxhE2VvIJbOg4XAw9X1SUASZ4F/Bbwraq6IMkv01u991J69yN4e1X9RZJ/BHwc+EngN+gtp/IrSU4G7kryv+hdjfu3VXVuknOBz3XcNukHeAW3tERJnkPvP/3twEeq6n83iy/+dFV9JckPAV+rqh9JchB4uO/jpwPPA/4ceDpwuCk/FbgIeCvwrqr6VLOvzwFbq+qeDpomPYk9C2mJqur/JjkfeCXw1iSfOPJW/2bN41OAl1bVd/u/I72Fm/5lVT0wr3z+90gj5ZyFtERJfozeUNGtwO/QWxob4DV9j59pnn8CeFPfZ89rnn4ceHMTGiT5qab808DlTdkLgXOH0wppMPYspKU7B/jtJN8Hvge8kd69Bk5Icie9P8Ze22x7FfB7Sb5I79/dp4FfA36T3rzGF5vA2EtvjuM99O6M9kXgC8Bd3TRJWphzFtIyauYspqvq66Oui7ScHIaSJLWyZyFJamXPQpLUyrCQJLUyLCRJrQwLSVIrw0KS1Or/A3edYcLphVJWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 281 ms\n"
     ]
    }
   ],
   "source": [
    "y_test.hist(bins=100);\n",
    "plt.xlabel('speed');\n",
    "plt.ylabel('frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train with ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create and compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7_eizWaqi_7",
    "outputId": "4361457c-e661-4e75-8c78-3c1a7789b705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def my_r2_score(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true) ) ) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "def BatchNorm():\n",
    "    return BatchNormalization(\n",
    "                momentum=0.95, \n",
    "                epsilon=0.005,\n",
    "                beta_initializer=RandomNormal(mean=0.0, stddev=0.05), \n",
    "                gamma_initializer=Constant(value=0.9)\n",
    "                )\n",
    "\n",
    "def build_and_compile_model(X_train, num_units=100, activation='sigmoid'):\n",
    "    input_shape = X_train.shape[1] \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=num_units, activation=activation, kernel_initializer='he_normal',\n",
    "                    input_shape=(input_shape,)))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "      \n",
    "    model.compile(loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(), my_r2_score], optimizer=Optimizer.Adam(0.01)) #my_r2_score\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setup callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I6x6dteutin0",
    "outputId": "0b4eab09-31e5-4ef0-d9cd-105656a99abe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "class My_checkoint(Callback):\n",
    "        \n",
    "    def __init__(self, model, X_test, y_test, checkpoint_name):\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.mode = model\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        cpn = checkpoint_name + format(epoch, '02d') + '-.hdf5'\n",
    "        #cpn = os.path.join(checkpoint_dir, 'model'+format(epoch, '02d') + '-.hdf5')\n",
    "        val_loss = self.mode.evaluate(self.X_test, self.y_test)\n",
    "        print('my_val_loss', val_loss)\n",
    "        self.mode.save(cpn)\n",
    "        \n",
    "def callback_model(model, checkpoint_name, logdir, X_test, y_test):\n",
    "  \n",
    "    _logdir = os.path.join(logdir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = TensorBoard(_logdir, histogram_freq=1)\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                  factor=0.3,\n",
    "                                  patience=1,\n",
    "                                  mode='min',\n",
    "                                  verbose=1)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=7,\n",
    "                                   monitor='val_loss',\n",
    "                                   mode='min',\n",
    "                                   verbose=1)\n",
    "    \n",
    "    csv_logger = CSVLogger('log.log', separator=',', append=False)\n",
    "    \n",
    "    callbacks_list = [tensorboard_callback, reduce_lr, early_stopping, csv_logger, My_checkoint(model, X_test, y_test, checkpoint_name)]\n",
    "    \n",
    "    return callbacks_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xttwiHh4u0ES",
    "outputId": "31e678b8-9b64-4fb6-9154-525972b48aca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, X_train, y_train, X_test, y_test, checkpoint_name, logdir, batch_size=32, epochs=10, re_train=True):\n",
    "\n",
    "    if re_train:\n",
    "        # Clear old folder\n",
    "        %rmdir /q/s {logdir}\n",
    "        # Clear old file\n",
    "        path = checkpoint_name + '**'\n",
    "        all_path_files = glob(path)\n",
    "        for file in all_path_files:\n",
    "            os.remove(file)\n",
    "        # fit model\n",
    "        callbacks_list = callback_model(model, checkpoint_name, logdir, X_test, y_test)\n",
    "        model.fit(X_train, y_train,\n",
    "                  validation_data=(X_test, y_test),\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  callbacks=callbacks_list)\n",
    "        \n",
    "        #del model\n",
    "        \n",
    "    # Get best file by reading log file\n",
    "    df = pd.read_csv('log.log')\n",
    "    best_epoch = df.loc[df['val_loss']==df['val_loss'].min(), 'epoch'].values[0]\n",
    "    best_file = 'model-' + format(best_epoch, '02d') + '-.hdf5'\n",
    "    #best_file = os.path.join(checkpoint_dir, 'model'+format(best_epoch, '02d') + '-.hdf5')\n",
    "    model = load_model(best_file, custom_objects={'my_r2_score': my_r2_score})\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <span style=\"color:blue\">Train với bộ thông số tốt nhất:\n",
    "    - units: 260\n",
    "    - batch_size: 112\n",
    "    - activation: tanh\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "checkpoint_name = 'model-'\n",
    "baseDir = os.path.abspath(os.getcwd())\n",
    "logs_name = 'training_logs'\n",
    "logdir = os.path.join(baseDir, logs_name)\n",
    "#checkpoint_dir = os.path.join(baseDir, checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "   1/8572 [..............................] - ETA: 0s - loss: 3050.3660 - root_mean_squared_error: 55.2301 - my_r2_score: -354.2344WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\my_d2l\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/8572 [..............................] - ETA: 40:21 - loss: 2777.1008 - root_mean_squared_error: 52.6982 - my_r2_score: -358.6963WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.5570s). Check your callbacks.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.0748 - root_mean_squared_error: 1.0367 - my_r2_score: 0.7060\n",
      "my_val_loss [1.074776291847229, 1.0367141962051392, 0.7060438990592957]\n",
      "8572/8572 [==============================] - 25s 3ms/step - loss: 2.4948 - root_mean_squared_error: 1.5795 - my_r2_score: 0.6548 - val_loss: 1.0748 - val_root_mean_squared_error: 1.0367 - val_my_r2_score: 0.7060\n",
      "Epoch 2/15\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.9246 - root_mean_squared_error: 0.9615 - my_r2_score: 0.7491\n",
      "my_val_loss [0.9245691895484924, 0.9615452289581299, 0.7490848898887634]\n",
      "8572/8572 [==============================] - 23s 3ms/step - loss: 0.2928 - root_mean_squared_error: 0.5411 - my_r2_score: 0.9590 - val_loss: 0.9246 - val_root_mean_squared_error: 0.9615 - val_my_r2_score: 0.7491\n",
      "Epoch 3/15\n",
      "8569/8572 [============================>.] - ETA: 0s - loss: 0.2379 - root_mean_squared_error: 0.4877 - my_r2_score: 0.9667\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0029999999329447745.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.9430 - root_mean_squared_error: 0.9711 - my_r2_score: 0.7429\n",
      "my_val_loss [0.9430040717124939, 0.97108393907547, 0.7428766489028931]\n",
      "8572/8572 [==============================] - 24s 3ms/step - loss: 0.2379 - root_mean_squared_error: 0.4878 - my_r2_score: 0.9667 - val_loss: 0.9430 - val_root_mean_squared_error: 0.9711 - val_my_r2_score: 0.7429\n",
      "Epoch 4/15\n",
      "8554/8572 [============================>.] - ETA: 0s - loss: 0.1787 - root_mean_squared_error: 0.4227 - my_r2_score: 0.9750\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009000000078231095.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.0270 - root_mean_squared_error: 1.0134 - my_r2_score: 0.7182\n",
      "my_val_loss [1.0270497798919678, 1.013434648513794, 0.7182068824768066]\n",
      "8572/8572 [==============================] - 24s 3ms/step - loss: 0.1786 - root_mean_squared_error: 0.4227 - my_r2_score: 0.9750 - val_loss: 1.0270 - val_root_mean_squared_error: 1.0134 - val_my_r2_score: 0.7182\n",
      "Epoch 5/15\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.8940 - root_mean_squared_error: 0.9455 - my_r2_score: 0.7563\n",
      "my_val_loss [0.893990159034729, 0.9455105066299438, 0.7562665343284607]\n",
      "8572/8572 [==============================] - 24s 3ms/step - loss: 0.1576 - root_mean_squared_error: 0.3970 - my_r2_score: 0.9780 - val_loss: 0.8940 - val_root_mean_squared_error: 0.9455 - val_my_r2_score: 0.7563\n",
      "Epoch 6/15\n",
      "8567/8572 [============================>.] - ETA: 0s - loss: 0.1529 - root_mean_squared_error: 0.3910 - my_r2_score: 0.9786\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00026999999536201356.\n",
      "  1/171 [..............................] - ETA: 0s - loss: 1.3880 - root_mean_squared_error: 1.1781 - my_r2_score: 0.6854WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0020s). Check your callbacks.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.9567 - root_mean_squared_error: 0.9781 - my_r2_score: 0.7392\n",
      "my_val_loss [0.9566648006439209, 0.9780924320220947, 0.7391809225082397]\n",
      "8572/8572 [==============================] - 23s 3ms/step - loss: 0.1529 - root_mean_squared_error: 0.3910 - my_r2_score: 0.9786 - val_loss: 0.9567 - val_root_mean_squared_error: 0.9781 - val_my_r2_score: 0.7392\n",
      "Epoch 7/15\n",
      "8553/8572 [============================>.] - ETA: 0s - loss: 0.1461 - root_mean_squared_error: 0.3823 - my_r2_score: 0.9796\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 8.099999686237424e-05.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.9386 - root_mean_squared_error: 0.9688 - my_r2_score: 0.7443\n",
      "my_val_loss [0.9385851621627808, 0.9688060283660889, 0.7443436980247498]\n",
      "8572/8572 [==============================] - 25s 3ms/step - loss: 0.1461 - root_mean_squared_error: 0.3823 - my_r2_score: 0.9796 - val_loss: 0.9386 - val_root_mean_squared_error: 0.9688 - val_my_r2_score: 0.7443\n",
      "Epoch 8/15\n",
      "8570/8572 [============================>.] - ETA: 0s - loss: 0.1438 - root_mean_squared_error: 0.3792 - my_r2_score: 0.9799\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-05.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.9418 - root_mean_squared_error: 0.9704 - my_r2_score: 0.7437\n",
      "my_val_loss [0.9417721629142761, 0.9704494476318359, 0.7436632513999939]\n",
      "8572/8572 [==============================] - 24s 3ms/step - loss: 0.1438 - root_mean_squared_error: 0.3792 - my_r2_score: 0.9799 - val_loss: 0.9418 - val_root_mean_squared_error: 0.9704 - val_my_r2_score: 0.7437\n",
      "Epoch 9/15\n",
      "8564/8572 [============================>.] - ETA: 0s - loss: 0.1430 - root_mean_squared_error: 0.3781 - my_r2_score: 0.9800\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 7.289999848580919e-06.\n",
      "  1/171 [..............................] - ETA: 0s - loss: 1.3824 - root_mean_squared_error: 1.1758 - my_r2_score: 0.6867WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0020s). Check your callbacks.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.9381 - root_mean_squared_error: 0.9685 - my_r2_score: 0.7447\n",
      "my_val_loss [0.9380586743354797, 0.9685342907905579, 0.744691014289856]\n",
      "8572/8572 [==============================] - 24s 3ms/step - loss: 0.1430 - root_mean_squared_error: 0.3781 - my_r2_score: 0.9800 - val_loss: 0.9381 - val_root_mean_squared_error: 0.9685 - val_my_r2_score: 0.7447\n",
      "Epoch 10/15\n",
      "8554/8572 [============================>.] - ETA: 0s - loss: 0.1427 - root_mean_squared_error: 0.3777 - my_r2_score: 0.9801\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.186999927289435e-06.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.9386 - root_mean_squared_error: 0.9688 - my_r2_score: 0.7445\n",
      "my_val_loss [0.9386321902275085, 0.9688303470611572, 0.744536817073822]\n",
      "8572/8572 [==============================] - 23s 3ms/step - loss: 0.1427 - root_mean_squared_error: 0.3778 - my_r2_score: 0.9801 - val_loss: 0.9386 - val_root_mean_squared_error: 0.9688 - val_my_r2_score: 0.7445\n",
      "Epoch 11/15\n",
      "8562/8572 [============================>.] - ETA: 0s - loss: 0.1426 - root_mean_squared_error: 0.3776 - my_r2_score: 0.9801\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 6.560999509019894e-07.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.9328 - root_mean_squared_error: 0.9658 - my_r2_score: 0.7462\n",
      "my_val_loss [0.9328001737594604, 0.9658157825469971, 0.7462034821510315]\n",
      "8572/8572 [==============================] - 23s 3ms/step - loss: 0.1426 - root_mean_squared_error: 0.3776 - my_r2_score: 0.9801 - val_loss: 0.9328 - val_root_mean_squared_error: 0.9658 - val_my_r2_score: 0.7462\n",
      "Epoch 12/15\n",
      "8557/8572 [============================>.] - ETA: 0s - loss: 0.1426 - root_mean_squared_error: 0.3776 - my_r2_score: 0.9801\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.9682997844938655e-07.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.9377 - root_mean_squared_error: 0.9683 - my_r2_score: 0.7448\n",
      "my_val_loss [0.9376983046531677, 0.9683482646942139, 0.7447721362113953]\n",
      "8572/8572 [==============================] - 24s 3ms/step - loss: 0.1426 - root_mean_squared_error: 0.3776 - my_r2_score: 0.9801 - val_loss: 0.9377 - val_root_mean_squared_error: 0.9683 - val_my_r2_score: 0.7448\n",
      "Epoch 00012: early stopping\n",
      "time: 4min 51s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = build_and_compile_model(X_train, num_units=260, activation='tanh')\n",
    "\n",
    "model = train_model(model, X_train, y_train, X_test, y_test, checkpoint_name, logdir,\n",
    "                    batch_size=112, epochs=15, re_train=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sai số rmse:                    0.397\n",
      "Hệ số xác định r2-score: 0.978\n",
      "Tỉ lệ True positive:           0.113\n",
      "time: 55.8 s\n"
     ]
    }
   ],
   "source": [
    "# On train\n",
    "train_result_df = evaluate(model, X_train, y_train_df)\n",
    "#train_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sai số rmse:                    0.946\n",
      "Hệ số xác định r2-score: 0.832\n",
      "Tỉ lệ True positive:           0.374\n",
      "time: 625 ms\n"
     ]
    }
   ],
   "source": [
    "# On test\n",
    "test_result_df = evaluate(model, X_test, y_test_df)\n",
    "#test_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <span style=\"color:blue\">Nhận xét:\n",
    "    Độ chính xác tập train kém đi mãnh liệt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>my_r2_score</th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_my_r2_score</th>\n",
       "      <th>val_root_mean_squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.494816</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.654844</td>\n",
       "      <td>1.579499</td>\n",
       "      <td>1.074776</td>\n",
       "      <td>0.706044</td>\n",
       "      <td>1.036714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.292794</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.958960</td>\n",
       "      <td>0.541104</td>\n",
       "      <td>0.924569</td>\n",
       "      <td>0.749085</td>\n",
       "      <td>0.961545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.237903</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.966705</td>\n",
       "      <td>0.487753</td>\n",
       "      <td>0.943004</td>\n",
       "      <td>0.742877</td>\n",
       "      <td>0.971084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.178635</td>\n",
       "      <td>3.000000e-03</td>\n",
       "      <td>0.975049</td>\n",
       "      <td>0.422653</td>\n",
       "      <td>1.027050</td>\n",
       "      <td>0.718207</td>\n",
       "      <td>1.013435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.157598</td>\n",
       "      <td>9.000000e-04</td>\n",
       "      <td>0.977981</td>\n",
       "      <td>0.396986</td>\n",
       "      <td>0.893990</td>\n",
       "      <td>0.756267</td>\n",
       "      <td>0.945511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.152910</td>\n",
       "      <td>9.000000e-04</td>\n",
       "      <td>0.978639</td>\n",
       "      <td>0.391037</td>\n",
       "      <td>0.956665</td>\n",
       "      <td>0.739181</td>\n",
       "      <td>0.978092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.146128</td>\n",
       "      <td>2.700000e-04</td>\n",
       "      <td>0.979593</td>\n",
       "      <td>0.382267</td>\n",
       "      <td>0.938585</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.968806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.143765</td>\n",
       "      <td>8.100000e-05</td>\n",
       "      <td>0.979921</td>\n",
       "      <td>0.379164</td>\n",
       "      <td>0.941772</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>0.970449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.142963</td>\n",
       "      <td>2.430000e-05</td>\n",
       "      <td>0.980034</td>\n",
       "      <td>0.378104</td>\n",
       "      <td>0.938059</td>\n",
       "      <td>0.744691</td>\n",
       "      <td>0.968534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.142696</td>\n",
       "      <td>7.290000e-06</td>\n",
       "      <td>0.980074</td>\n",
       "      <td>0.377752</td>\n",
       "      <td>0.938632</td>\n",
       "      <td>0.744537</td>\n",
       "      <td>0.968830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.142617</td>\n",
       "      <td>2.187000e-06</td>\n",
       "      <td>0.980081</td>\n",
       "      <td>0.377647</td>\n",
       "      <td>0.932800</td>\n",
       "      <td>0.746203</td>\n",
       "      <td>0.965816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.142590</td>\n",
       "      <td>6.560999e-07</td>\n",
       "      <td>0.980095</td>\n",
       "      <td>0.377610</td>\n",
       "      <td>0.937698</td>\n",
       "      <td>0.744772</td>\n",
       "      <td>0.968348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch      loss            lr  my_r2_score  root_mean_squared_error  \\\n",
       "0       1  2.494816  1.000000e-02     0.654844                 1.579499   \n",
       "1       2  0.292794  1.000000e-02     0.958960                 0.541104   \n",
       "2       3  0.237903  1.000000e-02     0.966705                 0.487753   \n",
       "3       4  0.178635  3.000000e-03     0.975049                 0.422653   \n",
       "4       5  0.157598  9.000000e-04     0.977981                 0.396986   \n",
       "5       6  0.152910  9.000000e-04     0.978639                 0.391037   \n",
       "6       7  0.146128  2.700000e-04     0.979593                 0.382267   \n",
       "7       8  0.143765  8.100000e-05     0.979921                 0.379164   \n",
       "8       9  0.142963  2.430000e-05     0.980034                 0.378104   \n",
       "9      10  0.142696  7.290000e-06     0.980074                 0.377752   \n",
       "10     11  0.142617  2.187000e-06     0.980081                 0.377647   \n",
       "11     12  0.142590  6.560999e-07     0.980095                 0.377610   \n",
       "\n",
       "    val_loss  val_my_r2_score  val_root_mean_squared_error  \n",
       "0   1.074776         0.706044                     1.036714  \n",
       "1   0.924569         0.749085                     0.961545  \n",
       "2   0.943004         0.742877                     0.971084  \n",
       "3   1.027050         0.718207                     1.013435  \n",
       "4   0.893990         0.756267                     0.945511  \n",
       "5   0.956665         0.739181                     0.978092  \n",
       "6   0.938585         0.744344                     0.968806  \n",
       "7   0.941772         0.743663                     0.970449  \n",
       "8   0.938059         0.744691                     0.968534  \n",
       "9   0.938632         0.744537                     0.968830  \n",
       "10  0.932800         0.746203                     0.965816  \n",
       "11  0.937698         0.744772                     0.968348  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms\n"
     ]
    }
   ],
   "source": [
    "log_data = pd.read_csv('log.log')\n",
    "log_data['epoch'] = log_data['epoch'] + 1\n",
    "log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAGPCAYAAACqMyKIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABE80lEQVR4nO3deXxcdb3/8dcnk32SbhlIVzphaVG2lhYoIEtBoCzKIiCCCFy5lYsKckUB709BxRWvilcEUbCKSFlkkx2xZS/QAkLZytItLd3XJE2zfX5/nEk6TSfJJJ3MmaTv5+Mxj8ycc+bMe6ZpPnO+5/s9X3N3REREpG/LCzuAiIiIbD8VdBERkX5ABV1ERKQfUEEXERHpB1TQRURE+gEVdBERkX5ABV2kl5jZNWa2KuwcnTGz883Mzaws7Cwisn1U0EV2bA8DBwN1YQcRke2TH3YAEcksMytx903pbOvuK4GVvRwpK8wsAkTcvSHsLCJh0BG6SEjMbG8ze9jMNiZud5vZ0KT1UTP7rZm9Z2Z1ZjbfzG4wswHt9uNm9t9m9mszWwm8mbT8UjP7sZmtNLMViecXJT13qyZ3M4snHp9pZr83s/VmVm1m3zezvHave4aZvW9mm8xshpmNTzz3/DTe+2gzu8PMViXe2xtmdnZi3ZGJ/ezd7jkzzeyepMfTzGy2mZ1iZm8B9cBBieee0O65ETNbZmY/TPfzF+lrVNBFQmBmuwPPA8XAucD5wF7AP8zMEpuVAhHgf4Djge8CRwF3p9jlt4BhiX1dkrT8m8Bw4IvAdcBXgEvTiPhzoAY4Hfgr8L3E/db8E4HpwKvAqcCDwJ1p7Bcz2xl4ETgAuBz4DHALMCqd57cTT2T9CXACMB94Gfh8u+2OACpbM6b5+Yv0KWpyFwnH1cAy4PjWJmIzewN4l6AwPZxoDv+v1ieYWT5BwXrOzHZx90VJ+1vm7u2LGMACdz8/cf9xMzsUOI2gCHbmGXf/ZuL+k2Y2JfG8uxLLrgDeAc7yYEKIx8ysAPhZGu/9MmAgMMHdP04seyqN56VSAXza3V9vXWBm04FrzKzI3TcnFn8eeNvd5yYed/n59zCPSGh0hC4Sjk8D9wEtZpafVKwXABNbNzKzc83sNTOrARqB5xKrxrTbX0cF6Il2j98GRqaRr6vnHQD8w7ee3enB5CeYWV7re0vcWv/eHAU8llTMt8eS5GKecBdQDkxJ5Mgn+DIyPWmbtD5/kb5EBV0kHDGCo9zGdrddSTQ9m9mpwF8ImqfPACYRNG9D0FScbHkHr7Ou3eOGFM/tyfOGsm1nuvaPv8fW7+17ieUVQCaKOaR43+6+hOCLT2uLxdEEn3dyQe/y8xfpa9TkLhKONQRHiH9Msa517PoZwEvufnHrCjM7ooP9ZXse5GXATu2WtX98M/BQ0uOliZ+rCc73d6Q+8bOw3fIhbPlsWnX0vu8EfmpmJQSF/TV3fz9pfTqfv0ifooIuEo6ngL2BOe2arZOVAJvbLTunV1Ol7xXgM2b2naT8n03ewN2XsqWIJ3sKuMTMKt09VctCdeLnJwg63WFmo4CxwLw0890NXE/QonEqQae59hm6+vxF+hQVdJHeVWhmp6dYfj3wOPCwmd1KcFQ4AjgGmObuM4EngRvM7H+Alwg6ax2dldRd+xlBpulm9ieC4vufiXUtXTz3V8CXgGfN7EfA4sTzo+7+c3evNrNXgB+aWR3BqcHvEBxVp8XdV5jZTOAXwCC2dOZrdQ1Bb/jOPn+RPkUFXaR3lZN6mNlkgnPi1xI0TZcASwiOHD9IbPN7gnO6lxKcv34SOBuY1buRu+bus83sC8CPgZOB2QQ98p8ENnTx3JWJ3vY/B34NFAHvs/VR9NkEzeF/JThi/zZB7/jumA78AZjl7gvaZZhnZl19/iJ9iqm1SUQywcy+CNwG7Oru88POI7Kj0RG6iPSImd1IcES+Ftgf+H8E4+dVzEVCoIIuIj1VAfwu8XM1Qc/yb4eaSGQHpiZ3ERGRfkAXlhEREekHVNBFRET6ARV0ERGRfkAFXUREpB9QQRcREekHVNBFRET6ARV0ERGRfkAFXUREpB9QQRcREekH+vSlX2OxmMfj8Yztr7a2lmg0mrH9ZYIypUeZ0qNM6VGm9ORaplzLA72Tac6cOavcfadtVrh7n71NmDDBM2nGjBkZ3V8mKFN6lCk9ypQeZUpPrmXKtTzuvZMJmO0paqKa3EVERPoBFXQREZF+QAVdRESkH8hKpzgzuxU4CVjh7nt3sM2RwK+BAmCVux+RjWwiIpI5jY2NVFdXU19fn/XXHjhwIO+8807WX7cz25OpuLiYkSNHUlBQkNb22erlPg34LfCXVCvNbBDwO2CKuy8ys52zlEtERDKourqa8vJy4vE4ZpbV1964cSPl5eVZfc2u9DSTu7N69Wqqq6upqqpK6zlZaXJ392eANZ1scjZwr7svSmy/Ihu5REQks+rr66moqMh6Me9vzIyKioputXTkyjn0McBgM5tpZnPM7EthBxIRkZ5RMc+M7n6OFgxp631mFgceSnUO3cx+C0wEjgZKgBeBE919XoptpwJTASorKydMnz49YxlramooKyvL2P4yQZnSo0zpUab0KFN6UmUaOHAgu+++eyh5mpubiUQiobx2R7Y30wcffMD69eu3WjZ58uQ57j5xm41TDU7vjRsQB+Z2sO5K4Jqkx7cAZ3S1T11YJhzKlB5lSo8ypaevZHr77bfTfv6qjfW+aHXtNrdVG+t7lGfDhg2+du1av+GGG7r93OOPP97Xrl3b7eedd955fvfdd3eaaXuk+jzp4MIyuXLp1weA35pZPlAIHAT8KhsvvLpmM3UNzQCMGLMvi9fUAVBaGKGirCgbEUREdkh1Dc0c9vMZ2yx/9tuTqejhPtetW8fvfvc7Lr744q2Wd3Wk/Mgjj/TwFXNHtoat3QEcCcTMrBq4mmB4Gu5+k7u/Y2aPAW8ALcAf3X1uNrL1xi+UiIjA9//xFm8v3dDh+iuO3zPl8pU1m7n87n+nXPfJ4QO4+jN7dbjPK6+8kg8//JBx48ZRUFBAWVkZw4YN4/XXX+ftt9/mlFNOYfHixdTX13PppZcydepUAOLxOLNnz6ampobjjz+eT33qU7zwwguMGDGCBx54gJKSki7f71NPPcXll19OU1MTBxxwADfeeGNbpgcffJD8/HyOPfZYfvGLX3D33Xfz/e9/n0gkwsCBA3nmmWe63H9XslLQ3f0LaWxzHXBdFuKIiEg/9dOf/pS5c+fy+uuvM3PmTE488UTmzp3bNvTr1ltvZciQIWzatIkDDjiAz33uc1RUbH349v7773PHHXfwhz/8gTPPPJO///3vfPGLX+z0devr6zn//PN56qmnGDNmDF/60pe48cYbOfXUU7nvvvt49913MTPWrVsHwA9+8AMef/xxRowY0bZse+VKk7uIiPQznR1JA22nONvbqayIO79ycEYyHHjggVuN4/7Nb37DfffdF7z+4sW8//772xT0qqoqxo0bB8CECRNYsGBBl6/z3nvvUVVVxZgxYwA477zzuOGGGzjvvPMoLi7mwgsv5MQTT+Skk04C4NBDD+X888/nzDPP5LTTTsvAO82dYWsiIiIZlzx16cyZM/nnP//Jiy++yL///W/Gjx+fcpx3UdGW/lORSISmpqYuX8c7GDGWn5/Pyy+/zOc+9znuv/9+pkyZAsBNN93Etddey+LFixk3bhyrV6/u7lvb9rW2ew8iIiI9UFoY4dlvT065vKfKy8vZuHFjynXr169n8ODBlJaW8u677zJr1qwev057e+65JwsWLOCDDz5g991357bbbuOII46gpqaGSCTCCSecwKRJk9qG9H344YccdNBBHHTQQfzjH/9g8eLF27QUdNcOX9CTf6GWrd9EQX6Eimjhdv1CiYhI1yrKijLe+biiooJDDz2Uvffem5KSEiorK9vWTZkyhZtuuol9992XsWPHMmnSpIy9bnFxMX/6058444wz2jrFXXTRRSxatIhzzjmH+vp63J1f/SoYwPWtb32L999/H3fn6KOPZr/99tvuDDt8QU/+hbpk2jPUWglPXKZ5YURE+qq//e1vKZcXFRXx6KOPplzXep48Fosxd+6WQVaXX355p681bdq0tvtHH300r7322lbrhw4dyssvv7zN8+69995O99sTOoeepLLUWLi6jpaW7Fw9T0REJFN2+CP0ZJWleWxuauLjDfWMGNT1mEMREdkxfPWrX+X555/fatmll17KBRdcEFKibamgJ6mMBg0WC1bVqqCLiEibG264IewIXVKTe5LK0mBmmwWra0NOIiIi0j0q6EkGFxtF+XksWKWCLiIifYsKepI8M+IVUeavSn31IhERkVylgt7O6IpSNbmLiEifo4LeTlUsyqLVdTRr6JqISO+qXQVrF257q12VtQhlZWUdrluwYAF777131rJsL/Vybycei9LQ3MLSdZsYNaQ07DgiIv1XQy1cv++2yy99A6Kx7Ofp41TQ24lXBBfyX7C6VgVdRGR7PHolLHuz4/Wfvib18poVcP/FqdcN3QeO/2mHu7ziiisYPXo0F18cPP+aa67BzHjmmWdYu3YtjY2NXHvttZx88slpvolAfX09//Vf/8Xs2bPJz8/nl7/8JZMnT+att97iggsuoKGhgZaWFv7+978zfPhwzjzzTKqrq2lsbOTqq6/m85//fLderydU0NupiiUK+qpaDttjp5DTiIhId5x11ll84xvfaCvod911F4899hiXXXYZAwYMYNWqVUyaNInPfvazmFna+20dh/7mm2/y7rvvcuyxxzJv3jxuuukmLr30Us455xwaGhpobm7mkUceYfjw4Tz88MNs3LiRlpaWXnmv7amgt1M5oIiSgggLVqunu4jIdunkSBoIzpenUrYzXPBwj15y/PjxrFixgqVLl7Jy5UoGDx7MsGHDuOyyy3jmmWfIy8tjyZIlLF++nKFDh6a93+eee46vf/3rQDCz2ujRo5k3bx4HH3wwP/rRj6iurua0005jjz32YJ999uHyyy/niiuu4KijjuK4447r0XvpLnWKa8fMgp7uGosuItInnX766dxzzz3ceeednHXWWdx+++2sXLmSOXPm8Prrr1NZWZlyHvTOdDTf+dlnn82DDz5ISUkJxx13HP/6178YM2YMc+bMYZ999uGaa67hBz/4QSbeVpd0hJ5CvCLKvBWp59MVEZEMKYwGHeBSLd8OZ511Fv/5n//JqlWrePrpp7nrrrvYeeedKSgoYMaMGSxc2EHLQCcOP/xwbr/9do466ijmzZvHokWLGDt2LB999BG77rorl1xyCR999BFvvPEGe+65J0OGDOGLX/wikUiEO++8c7veT7pU0FOIx6I89e5ymppbyI+oEUNEpFdEY73Sm32vvfZi48aNjBgxgmHDhnHOOefwmc98hokTJzJu3Dj23HPPbu/z4osv5qKLLmKfffYhPz+fadOmUVRUxJ133slf//pXCgoKGDp0KN/73vd45ZVX+Na3vkVeXh55eXncfPPNGX+Pqaigp1AVK6Wx2Vm6rp5dKtTTXUSkr3nzzS2962OxGC+++GLK7WpqajrcRzweb5sbvbi4eKu5z1tdddVVXHXVVVstO+6449rOm2/cuJHy8vLuxu8RHX6m0Dp0bb6uGCciIn2EjtBTSB66dsQYDV0TEenP3nzzTc4999ytlhUVFfHSSy+FlKhnVNBT2Km8iGhhRNd0FxHpAXfv1hjvsO2zzz68/vrrYcfYRkc96zuiJvcUgqFrUQ1dExHppuLiYlavXt3tYiRbc3dWr15NcXFx2s/REXoHqmJR3v54Q9gxRET6lJEjR1JdXc3KlSuz/tr19fXdKoDZsD2ZiouLGTlyZNrbq6B3YHRFKY+/tUxD10REuqGgoICqqqpQXnvmzJmMHz8+lNfuSDYzqVJ1IB6L0tTiVK/dFHYUERGRLqmgd6C1p7uGromISF+ggt6BtmlU1TFORET6ABX0DsTKCikryldBFxGRPkEFvQNmRjxWqmlURUSkT1BB70S8IqqLy4iISJ+ggt6JeEWU6rWbaGxuCTuKiIhIp1TQOxGPRWlucRavUbO7iIjkNhX0TlTFgqlT1ewuIiK5TgW9E23TqK7SEbqIiOQ2FfRODIkWUl6soWsiIpL7VNA7YWZUxdTTXUREcp8Kehc0dE1ERPoCFfQuxGNRlqzdREOThq6JiEjuykpBN7NbzWyFmc3tYrsDzKzZzE7PRq50xCtKaXFYpKFrIiKSw7J1hD4NmNLZBmYWAX4GPJ6NQOmKxzRJi4iI5L6sFHR3fwZY08VmXwf+Dqzo/UTpq2qddU3n0UVEJIflxDl0MxsBnArcFHaW9gZHCxlYUsB8HaGLiEgOM3fPzguZxYGH3H3vFOvuBv7X3WeZ2bTEdvd0sJ+pwFSAysrKCdOnT89YxpqaGsrKyrZZ/oMXN1GcD98+oCRjr7W9mcKkTOlRpvQoU3qUqWu5lgd6J9PkyZPnuPvEbVa4e1ZuQByY28G6+cCCxK2GoNn9lK72OWHCBM+kGTNmpFx+6R2v+iE/eSqjr5WujjKFSZnSo0zpUab0KFPXci2Pe+9kAmZ7ipqYE03u7l7l7nF3jwP3ABe7+/3hptoiHouydP0m6hubw44iIiKSUn42XsTM7gCOBGJmVg1cDRQAuHvOnTdvL14RxR0Wr6ljj8rysOOIiIhsIysF3d2/0I1tz+/FKD3SOnRt/qpaFXQREclJOdHknus0dE1ERHKdCnoaBpYWMLi0QNOoiohIzlJBT1M8FtXV4kREJGepoKepSrOuiYhIDlNBT1M8FuXj9fUauiYiIjlJBT1NrT3dF67WeXQREck9KuhpileUAuia7iIikpNU0NPUNo2qzqOLiEgOUkFP04DiAiqiherpLiIiOUkFvRvisaia3EVEJCepoHdDXEPXREQkR6mgd0NVrJTlGzZT19AUdhQREZGtqKB3g4auiYhIrlJB74Z46yQtOo8uIiI5RgW9G9qmUdV5dBERyTEq6N1QVpRPrKxIR+giIpJzVNC7qSpWygJNoyoiIjlGBb2b4hVRNbmLiEjOUUHvpngsysqNm6nZrKFrIiKSO1TQu6kqpp7uIiKSe1TQu6l16JrGoouISC5RQe+m0YlpVHUJWBERySUq6N0ULcpn5/IiTdIiIiI5RQW9B+KxqM6hi4hITlFB74EqzbomIiI5RgW9B+KxKKtqGthY3xh2FBEREUAFvUeqYomOcbpinIiI5AgV9B5onaRFze4iIpIrVNB7YPQQXVxGRERyiwp6D5QURhg6oFjXdBcRkZyhgt5D8VipjtBFRCRnqKD3UFUsygJd/lVERHKECnoPxSuirKltYP0mDV0TEZHwqaD3UFyzromISA5RQe+hKg1dExGRHKKC3kO7DCnFTBeXERGR3KCC3kPFBRGGDSjWEbqIiOQEFfTtEI9FNY2qiIjkBBX07RCPadY1ERHJDSro26GqIsq6ukbW1TWEHUVERHZwWSnoZnarma0ws7kdrD/HzN5I3F4ws/2ykWt7tQ5dU7O7iIiELVtH6NOAKZ2snw8c4e77Aj8Ebs5GqO3VNo2qmt1FRCRk+dl4EXd/xszinax/IenhLGBkr4fKgFFDSskzmK+hayIiErJcPIf+ZeDRsEOkoyg/wvBBJSzUEbqIiITM3D07LxQcoT/k7nt3ss1k4HfAp9x9dQfbTAWmAlRWVk6YPn16xjLW1NRQVlbWredc98om6prg6oNLMpZjezP1NmVKjzKlR5nSo0xdy7U80DuZJk+ePMfdJ26zwt2zcgPiwNxO1u8LfAiMSXefEyZM8EyaMWNGt5/zP/e94ftc/Zi3tLRkNEurnmTqbcqUHmVKjzKlR5m6lmt53HsnEzDbU9TEnGhyN7NdgHuBc919Xth5uiNeEWVDfRNr6zTrmoiIhCcrneLM7A7gSCBmZtXA1UABgLvfBHwPqAB+Z2YATZ6qOSEHVSUNXRsSLQw5jYiI7Kiy1cv9C12svxC4MBtZMi15GtUJoweHnEZERHZUOdHk3peNGhwMXdNYdBERCZMK+nYqzM9j5OBSFqzWWHQREQmPCnoGjK4oZYEu/yoiIiFSQc+AqliUBatqW4ffiYiIZJ0KegbEK6Js3NzE6lrNuiYiIuFQQc+AqqSe7iIiImFQQc8ATaMqIiJhU0HPgJGDS4jkmYauiYhIaFTQM6AgkseowSUs0DSqIiISkg6vFGdm30lzH03u/vMM5emz4rGojtBFRCQ0nV369QfAs2ns4wBABb0iyivz1+DuJK5HLyIikjWdFfRN7j65qx2Y2doM5umz4hWl1DY0s7JmMzuXF4cdR0REdjCdnUM/Kc19nJyJIH3dlkladB5dRESyr8OC7u5Pp7MDd38mc3H6Lo1FFxGRMHXWKe5L6ezA3f+SuTh914hBJeTnGfPVMU5ERELQ2Tn077Z7vEvi5wpg58T9hYAKOpAfyWOXIZqkRUREwtFhQXf3PVrvm9m3gThwubvXmVmUoGf7gt4O2JfEY1FdLU5EREKR7oVlvgFc5u51AO5eC1wOXNZLufqkeEWUhavrNOuaiIhkXboFPQIMb7dsGJ032e9w4rFSNjU2s2Lj5rCjiIjIDibdgn478KiZnW9mk83sAuChxHJJiFdokhYREQlHukfY3wbWAt8BRgJLgNuAn/RSrj4peejapF0rQk4jIiI7krQKurs3AT9M3KQDwweVUBjJ09A1ERHJurRnWzOzgWZ2tpl9K/F4qJm1P6++Q4vkGaOGlGjomoiIZF1aBd3M9gc+AK4EvpdYvC/wf72Uq8+qikV1+VcREcm6dI/Qrwe+7e77Ak2JZS8Ak3olVR8Wr4iycE0tLS0auiYiItmTbkHfC5iWuO8A7l4DRHshU582OhalvrGF5Rvrw44iIiI7kHQL+kq2XPoVADPbnaC3uySp0tA1EREJQboF/c/AdDP7FGBmNgH4I/CHXkvWR8VjpYCmURURkexKdxz6z4Ay4JHEzxkE59V/00u5+qzhA0sozM9jgYauiYhIFqU7Dr2Z4KIy3zGzmLuv6t1YfVdenjF6SKma3EVEJKu6Mw49YmaHAEcnHpeaWUmvJevD4rGoxqKLiEhWpTsOfTdgLkGT+y2Jxceic+gpVcWiLFxTp6FrIiKSNekeof8fMB0YAjQmls0EDuuFTNlVuwrWLoS1C5k0dljbfWp7flYhXhGloamFjzdo6JqIiGRHup3iDgQ+6+4tZtY6Dn2dmQ3qtWTZ0lAL1+8LQHHy8kvfgGisR7uMV7T2dK9lxCCdlRARkd6X7hH6BmBQ8oLEddyXZzpQfxCPaSy6iIhkV7oF/V7gVjMbCWBmFcCvCZrh+6men/8eOqCYovw8dYwTEZGsSbegfxeoARYRHKmvADYDP+6dWDlgw1J4/vqgSb6b8vKMeEVUY9FFRCRr0iro7r7J3c8GdiI4nz7U3c919/7b6ytSAE9+D67fD174P2jo3pXf4jGNRRcRkexJt1Ncq4LEz0img4SmMBp0gAPq6+spLi7esvw/HoeZP4En/l9wtH7oN2Dif0BhaZe7jceizHh3Jc0tTiTPevEN7MBqV7W1oLSNUIDg366HHRpFRPqqtAq6me0E/BU4JrHIzeyfwLnuvqK3wmVFNNb2x3/WzJkceeSRW6/70gOw8MVEYf+foLB/6htBYS/ouAd7VUWUhuYWlq7bxKghXX8BkB7ohREKIiJ9Vbrn0G8GaoE9CI7SxwIbE8v7v9EHw3kPwvmPwE5j4fHvBE3xs26Exk2pn5KYdU3n0UVEJBvSLehHAF9y9w/dvdndPwD+I7G8S2Z2q5mtMLO5Haw3M/uNmX1gZm+Y2f5p5squ+KFw/kNw/sMQGwOPXQnXj4NZN0Hj1t0JqhJD19TTPcPq1sCb98B9F8GGDmbvbW7IbiYRkRzQnfnQ27cvFxP0dk/HNGBKJ+uPJzj63wOYCtyY5n7DEf9UUNjPewgqdoPHroDfjIOXbm4r7JUDiigpiDBf06hun5ZmqJ4DM38Kf/w0XLcb/P3LMO9xyC9O/ZyaZTDtJJj3BLguvysiO4Z0O8X9HLjbzK4BFgJxgqFsP0tcYAYAd1+a6snu/oyZxTvZ/8nAX9zdgVlmNsjMhrn7x2nmC0fVYUFxX/AszPgJPPoteO5XcNh/Y/t/idEVpWpy74malfDhU/DBP+GDp2DTGsBgxAQ44grY/dMwfDysr079/OLBsOYj+NsZsNOecMjXYZ8zIL8oq29DRCSbzNM4gjGzlqSHDliKx+7uHfZ+TxT0h9x97xTrHgJ+6u7PJR4/BVzh7rNTbDuV4CieysrKCdOnZ+7aNjU1NZSVlfXsye4MWvcm8QV3MGj929QXVfAXO4XbNh/BD48YGE6mXpLpTNbSTPnGeQxZ8yoVq+dQXvMhAA0FA1kzZP/EbRxNBQO2et64MaMotiYAWtzJs+DXst7z+fe789l5xXOMWnw/ZbXz2Vw4mCUjTmLp8Ck0FWTn89wR/u0yQZnSo0xdy7U80DuZJk+ePMfdJ26zwt27vAGj07l1sY84MLeDdQ8Dn0p6/BQwoatcEyZM8EyaMWPG9u+kpcX9g3+5//EY96sH+JLvVXnTS39wb9wcXqYMy0im9UvdX73N/c4vuf9klPvVA9yvGex+y3HuT//cfclr7s3N25+p9d/jL6cEr3HtMPdHrnBfs2D730NPM4VImdKjTOnJtUy5lse9dzIBsz1FTUyryd3dFyY/NrNioMXdM9X7qBoYlfR4JJCy+T7nmcFuk2HXI3n60bsom3Udwx/5Jjz/azjsv2HcFyG/MOyU2dfcCItfgvefDJrRl78ZLC8fBp/4DOx+DOx6BJQMzuzrtv577DYZls2FF38Lr/wBXv49fPKUoDl+RG72wRQR6Y50x6FfCzzo7i+b2THAA0CLmZ3m7k9kIMeDwNfMbDpwELDec/38eVfMKPnEMXzumSgPTNnMfh/cCA9dBs/+Cg7/Jux3dv8v7OsWJ86D/xM+ehoaNkJePuxyMHz6+8G58Mq9gqKbDUP3hlNvgqO+Cy/dBHOmwVv3QvywoLDvfgzkpdtPtA/RBXhEdgjpdoo7j6BjHASd4a4gmIHtR0CXBd3M7gCOBGJmVg1cTeKqc+5+E/AIcALwAVAHXJD2O8hhwTSqxuuFE9jvy4kj05k/hn9cCs/+Lxx2OYw7O7jMbH/QtBkWvrCliK98N1g+YCTs87mgYFYdDsUDOt9Pbxs4Ao79IRz+LXj1L8H1BP52ZtCB7uCvwb5n9q8OdLoAj8gOId2CPsDdN5hZFNgPOMrdm8zs1+k82d2/0MV6B76aZpY+Y6fyIqKFkeCa7mawx6dh96ODYjfjx/CPS4LCfvi3YL+zcruwd3SUlxeB9x4N3tP8Z6CxDiKFMPoQGH9ucBS+09jsHYV3R/EAOORrcNBX4K374IXfwINfg3/9EA6cGlwNsHRI2Cl7rrkJVr4D1kGrQ+1KmPEjKB649a1oQLtlg4LPKpO/n7nYaqBMfTdTrgnpM0q3oK82sz2BvYGXEsW84+ueCgBmxuj2s66ZwR7HBIXu/SeDI/YHvwbP/iIo7PueBZHuXmI/Czo6yjv/IXjkchgch3HnBO+r6rDgF7eviBQER+X7nAHzn4bnfxMU9Wd/CfufC5P+K3h/uW7jcqh+JbgtmQNLXoXG2uDfKJWWZlg0C+rXw+YN4C2pt2tVEG1X6NsX/lS3QVu+ICSfYsq1VgP33MsEypSOXPyCEdJnlG7l+DUwJ3H/nMTPw4F3Mh2ov6mKRXlr6fptV5jBmGOD4j4vMQnMA1+FZ34BZ/2trSBm7Be0pQUaaqB+XfAHvH49bEq639XyszsYHlg8GL7+KgzZNTePwrvDDHY9Mrgtmwsv3gCv3AIv3wyfPBkOuSR3OtA11sOyN7YU8Oo5sH5RsC4vH4buC+O/CCMPgPLhqfdRPhS+EUxM1Pb7sXlD0r99qts6qE9sU7MCVr2/ZZ03d545v2RLoT/5t6m3qVsVXFrZW4IvHN4S7Lf1fktz8Dj5fktLimXNHeyjg+29peMvPusXwW8ngkWCFqm8yJb7Fgk+77y8pPuty/OCx23Pyw9aS7Z6XmTLsq22TWwzsYOzj5vWBr+fJIYdtw0/7s7jjtaRYtukxwdO7SDTOph9C+QVBF+S8/KD1rq2+wVb1iXf32pdYXBAk84+8hKjpNMtni0t0NIILU3Brblpy/2WxuB3oaUp6MDb0pR43J3tk267Hpn6M+pl6fZy/42ZPQo0ufv8xOL5JMaDS8fisVIee2sZjc0tFERSNH2awdgpMOY4mPdYUNg3rYYbDwba/4L+O/hlSVmI13VeoNM5AitK/LEtSRxZDalKNLcODNalfE45DB7drc+kTxi6N5x6Ixyd6EA3+09Bs/zoTwUd6PY4Nnsd6Nxh7QKonp04+p4NH78R/FEBGDgKRk6ESRfBiIkwbN+tJw5q/ULYmby8xBH3ABg4smcZG2q3/M5t88Vg3daPO/ry19wYXBSotSC2Fc7k+wUpliUVyq2KZl6KZcmPk/bR4e/4QDj4q4k/1q1fDpq2/oLQ0rTlS0NLU7svF63bJrZr2py0bXO7LxvtXmO/s1JnaqiFN+4M7rd9ltb9x91+LrD/eR1kqgkug93S2PXfmkywvKC4n3tf6vXrq+F3k7YU3C3fVHpfR18Oe1nabbvu/n67x/MyH6f/iVdEaW5xqtduaru+e0pmMPZ4GDMFVr6Xepv1i4NLmnakoDTpnOdAKBsadPTa6lxoUnNoSdLjogFbvvGmkk5R6I8GDIdjfhB0YGztQHfH5yE2Njj/vs+ZUNDBJWh7qn4DLH01ceQ9O7jVrQrWFZTC8P2DAjPygKCQlw/tfH+dTRGcKWZQVBbcBo7oevuOfp/Kh8HFL2YuV3d0lKl4IHz6mqxGadNRpoEj4cqQ/k92lum7iauBtx4NNzcGcyu0Hck2Jo50E8vb7jcmbd9+uy72UdjBRVsKo3DAlxMtIQVbWkRaj/bb31qP+jOxfd3q3vnsu9BhQTezh939xK52YGYPuvtnMxur/0iepKXTgt7KrONpWYsHwUm/SirKg7cu0P19GFyYtupAdz+8cD08+HV46odw0FSY+OWedaBraQ6+wLU1nc9OjA5IHE3ExgStNyMnBkffO3+y+30sOpsiWKQ35OVBXlF2Rot09AWjZDAce23vv34qdWtCednO/jIcYWYHs/VlXlM5LIN5+p2MTqNaNCDoeR2GbBzl9QWRAtj3DNjn9KAD3Qv/B/+6NuhAN/5cOPSSoEjTQf+HmpVBk3lb57XXgvH5EHxhG3kA7HVqooDvn/kL7eSKXPx9Uqa+mynXhPQZdVbQS4Hn09hHfdeb7LhiZYWUFeX3/WlUdZS3teQOdMvfghd+C7NvhU9+pu20yFYN8f85A/5wFKxLFHiLBOfp9/t8UMRHTAxm7uvrHQvTlYu/T8qUnlzLlItfMEL6jDos6O7eDy+ZlX1mRjxWyvzV3ZhGNRd/QaVjlXtt6UBXuzL1Nk31MGw/OODCoIAP2w8KS7ObU6Q/yrUvGCHKwQHP/U+8Isob1SmGrnVEv6B904DhQaedlOtGwOdvy24eEdmh6Cg8C6piUarX1tHQlIWhHCIiskNSQc+CeEWUFofFa7vR7C4iItINanLPgnjS0LXddsrsRPeSY9T/QURC0uURupnlm9nDiTnQpQdax5/P7+s93aVr0Vhw5bzBo5n13sdt9zVphYj0ti4Lurs3AROApt6P0z8NLi2gvDifhd3p6S4iItIN6Z5Dvw34Wm8G6c/MjKpYNDMXlxEREUkh3XPo+wOXmtnXgAVAW3dtdz+2F3L1O/GKKK8uWht2DBER6afSLejPJG7SQ/FYlIfeWMrmpmaK8juZBEVERKQH0p0+9fu9HaS/q4qVBkPX1tSx+87lYccREZF+Ju1ha2Y2CjgbGAUsBv7m7ot7K1h/E69o7emugi4iIpmXVqc4M/sU8A5wMjAQ+CzwjplpprU0JU+jKiIikmnpHqH/HLjE3W9tXWBm5wPXAZN6IVe/M6i0kIElBcxXT3cREekF6Q5b+wQwrd2y24CxGU3Tz8VjURaqoIuISC9It6AvJxi6lmx/YEVm4/RvVRWlLFili8uIiEjmpdvkfj3wiJn9HvgIqAK+Aqj3ezfEY1Ee+PdS6hubKS7Q0DUREcmcdIet3Whm64Dzgc8R9HL/hrvf0XvR+p+qWBR3WLSmjjGV6ukuIiKZ02VBN7N8giP0b6qAb58tQ9dqVdBFRCSj0p2c5Sxgc+/H6d/iGromIiK9JN1OcQ8QNLXLdhhYUsCQaKEmaRERkYxLt1NcIfBXM7uIbSdnmdoLufqt0erpLiIivSDdI/RG4A6CznARoCDpJt1QVaFpVEVEJPPS7RT3DvB/7r6p9yP1b/FYlHtfW8KmhmZKCjV0TUREMiPdTnHfUTHPjNaOcQvX6ChdREQyJ90m9xlmdkSvJtlBVFWop7uIiGReup3iFgAPmNk9bNsp7seZj9V/xWOlQDCNqoiISKakW9DHAa8BuyVurRxQQe+G8uICYmWFOkIXEZGMSvfSr5N7O8iOJF4R1TSqIiKSUZ2eQzezvbpYf0Jm4+wYRldoGlUREcmsrjrFvZj8wMzWtFs/PbNxdgxVsVKWb9hMXUNT2FFERKSf6KqgWzcfSxq2XNNdHeNERCQzuiro3s3HkobWWdd0xTgREcmUdMehbzczm2Jm75nZB2Z2ZYr1A83sH2b2bzN7y8wuyFa2bGs9Qp+vnu4iIpIhXfVyLzSz7yQ9Lm73OK1ruZtZBLgBOAaoBl4xswfd/e2kzb4KvO3unzGznYD3zOx2d29I5zX6krKifHYqL9LQNRERyZiuCvosgiLc6qV2j2el+ToHAh+4+0cAZjYdOBlILugOlJuZAWXAGqDf9hrTJC0iIpJJnRZ0dz8yQ68zgmCmtlbVwEHttvkt8CCwFCgHPu/uLfRToytKmfHeyrBjiIhIP2Huvd+vzczOAI5z9wsTj88FDnT3rydtczpwKPDfBFejexLYz903tNvXVGAqQGVl5YTp0zM3cq6mpoaysrKM7a8zD33YwD3vN3Ljp0spye94sEA2M6VLmdKjTOlRpvQoU9dyLQ/0TqbJkyfPcfeJ26xw916/AQcDjyc9vgq4qt02DwOHJT3+F0HR73C/EyZM8EyaMWNGRvfXmYffWOqjr3jI36xe1+l22cyULmVKjzKlR5nSo0xdy7U87r2TCZjtKWpitnq5vwLsYWZVZlYInEXQvJ5sEXA0gJlVAmOBj7KUL+s0dE1ERDIp3clZtou7N5nZ14DHgQhwq7u/ZWYXJdbfBPwQmGZmbxJcsOYKd1+VjXxhaJ11TT3dRUQkE7JS0AHc/RHgkXbLbkq6vxQ4Nlt5wlZamE/lgCJNoyoiIhmRtQvLyLbiGromIiIZooIeoqpYVE3uIiKSESroIRpdEWV1bQMb6hvDjiIiIn2cCnqIqhId4xbqPLqIiGwnFfQQtU3SovPoIiKynVTQQzR6SOu86CroIiKyfVTQQ1RSGGHYwGIVdBER2W4q6CGLV0TV5C4iIttNBT1kcQ1dExGRDFBBD1m8opS1dY2sr9PQNRER6TkV9JC19nTXFeNERGR7qKCHrEoFXUREMkAFPWS7DCnFDObrPLqIiGwHFfSQFRdEGD6wRB3jRERku6ig54B4rJT5q3X5VxER6TkV9BwQr9DQNRER2T4q6DmgKhZl/aZG1tY2hB1FRET6KBX0HDC6QpO0iIjI9lFBzwFt06iqoIuISA+poOeAUUNKyTOYr3nRRUSkh1TQc0BRfoThgzR0TUREek4FPUdUxaK6WpyIiPSYCnqOiFdEmb+qFncPO4qIiPRBKug5Ih6LsrG+iTUauiYiIj2ggp4j4hVBT3c1u4uISE+ooOeItmlU1dNdRER6QAU9R4waHAxd0xG6iIj0hAp6jijMz2Pk4FJNoyoiIj2igp5D4hq6JiIiPaSCnkOqKkpZsKpOQ9dERKTbVNBzSDwWpWZzE6tqNHRNRES6RwU9h7T1dFezu4iIdJMKeg6Jt06jqo5xIiLSTSroOWTk4BIieaZpVEVEpNtU0HNIQSSPUYNLdHEZERHpNhX0HBOPRdXkLiIi3aaCnmPiFcFYdA1dExGR7lBBzzFVsSh1Dc2s3Lg57CgiItKHqKDnmNaha2p2FxGR7lBBzzFVFRqLLiIi3Ze1gm5mU8zsPTP7wMyu7GCbI83sdTN7y8yezla2XDJ8UDH5ecZ89XQXEZFuyM/Gi5hZBLgBOAaoBl4xswfd/e2kbQYBvwOmuPsiM9s5G9lyTX4kj12GlGosuoiIdEu2jtAPBD5w94/cvQGYDpzcbpuzgXvdfRGAu6/IUraco6FrIiLSXdkq6COAxUmPqxPLko0BBpvZTDObY2ZfylK2nBOviLJwtWZdExGR9Fk2ioaZnQEc5+4XJh6fCxzo7l9P2ua3wETgaKAEeBE40d3ntdvXVGAqQGVl5YTp06dnLGdNTQ1lZWUZ219PPbWokdvebuBXR5ZQ0FSXE5mS5crnlEyZ0qNM6VGm9ORaplzLA72TafLkyXPcfeI2K9y912/AwcDjSY+vAq5qt82VwDVJj28BzuhsvxMmTPBMmjFjRkb311PPzFvho694yF/4YFXOZEqmTOlRpvQoU3qUqWu5lse9dzIBsz1FTcxWk/srwB5mVmVmhcBZwIPttnkAOMzM8s2sFDgIeCdL+XJKXEPXRESkm7LSy93dm8zsa8DjQAS41d3fMrOLEutvcvd3zOwx4A2gBfiju8/NRr5cM3xQCYWRPBasqmVYadhpRESkL8hKQQdw90eAR9otu6nd4+uA67KVKVdF8oxRQ0qYv6qWg3cJO42IiPQFulJcjqqKBT3dRURE0qGCnqNaZ11r0dA1ERFJgwp6jorHomxuamFtvQq6iIh0TQU9R1UlZl1bXqeCLiIiXVNBz1Gt06gur20JOYmIiPQFKug5atiAYgrz81hep4IuIiJdU0HPUXl5xughpWpyFxGRtGRtHLqkb3XNZuoamrnujP1obGpm8Zpg+FppYYSKsqKQ04mISC5SQc9BdQ3NHPbzGdssf/bbk6kIIY+IiOQ+Nbn3IRqTLiIiHVFB70M+Xl/PhX+ezcNvfEx9Y3PYcUREJIeoyb0PKSvK543qdfzzneWUFeUzZe+hnDp+BJN2rSCSZ2HHExGREKmg9yEDSwp48aqjmfXRau57bQmPzV3GPXOqqRxQxGf2Hc4p40ew1/ABmKm4i4jsaFTQc1BpYYRnvz0ZgPr6eoqLi9uWR/KMQ3ePcejuMa49ZW+eemcF9722hD+/uIA/Pjef3Xcu45Rxwzl53AhGDdHcqyIiOwoV9BxUUVbU1pt95syXOfLII1NuV1wQ4cR9h3HivsNYW9vAI3M/5v7XlvCLJ+bxiyfmMXH0YE4eP4KT9hnG4Ghh1vKLiEj2qaD3E4OjhZxz0GjOOWg0i9fU8eC/l3L/a0v47v1z+f6Db3Hk2J04ZfwIPv2JSooLImHHFRGRDFNB74dGDSnlq5N35+Ijd+PtjzfwwOtLeeD1JfzznRWUFeVz3F5DOWX8cA7ZLabOdCIi/YQKej9mZuw1fCB7DR/IFVP25KWPVnP/60t49M1l/P3VanYuL+Iz+w3nVHWmExHp81TQdxCRPOOQ3WMcsnuMH5y8N/96dwX3v7aEv7y4gFuem89uO0U5ZdwIThmvznQiIn2RCvoOqLggwgn7DOOEfYaxrq6BR95cxv2vL+F/n5zH/z45jwmjB3PKuOGcuO9whqgznYhIn6CCvoMbVFrI2QftwtkH7UL12qAz3QOvLeW7D7zF9//xNkeM2YmTx4/g4F2HUN8YTOU6Ysy+mjBGRCTHqKBLm5GDS7n4yN25+MjdeefjDdz/2hIeeH0pT727gjunTuLzN8/a5jmaMEZEJDeooEtKnxg2gE8MGxB0ppu/hpJCDXUTEcllmpxFOpWXZxy8WwWDS1OfS19b18A7H2/IcioREWlPBV22y6aGZo6//lm+cPMsnnhrGc0tmuJVRCQMKuiyXYYNLOaq4/dk4epapt42h8m/mMktz81nY31j2NFERHYoOocuaelswpivHLEbX/5UFU+8vZxbn5vPDx96m189OY/TJ4zk/EPixGPRMKOLiOwQVNAlLV1NGJMfyWsb2/5G9Tr+9PwCbn9pIX9+cQFH77kzFxxaxSG7VehqdCIivUQFXTJu35GD+NXnx3HV8Xvy11kLuf2lRfzznZcYW1nOBYfGOWX8CE0QIyKSYTqHLr1m5wHF/PexY3n+yqO47vR9ycszrrz3TQ7+yVNc9/i7LFtfH3ZEEZF+Q0fo0uuKCyKcMXEUp08YyUvz13Drc/P53cwP+f3TH3HCPsO44NA443cZHHZMEZE+TQVdssbMmLRrBZN2rWDR6jr+/OIC7nplMQ/+eynjdxnEBYdWcfzeQymIqOFIRKS7VNAlFLtUlPLdkz7JZceM4Z7Zi5n2wgIuueM1hg4o5tyDR3P2gbswWBPDiIikTYdCEqqyonzOP7SKf33zSG45byK771zGdY+/x6SfPMVV977Be8s2hh1RRKRP0BG65IS8POPoT1Ry9CcqeW/ZRqa9MJ97X13CHS8v5tDdK/iPQ6uYPHZn8vI07E1EJBUdoUvOGTu0nJ+cti8vXnU03zpuLB+uqOXLf57NUf87kz89P5+azU1hRxQRyTk6QpecNSRayFcn787Uw3fl0bnL+NPz8/n+P97ml0/M44yJo7jwsKq2a8drjnYR2dGpoEvOK4jk8dn9hvPZ/Ybz2qK1/On5BfzlxQUcu1clZ2mOdhERQAVd+pjxuwxm/C6D+c4Jn2B17eaU22xqbOaDFRuJV0TJ1xA4EdlBqKBLnzR0YDGNzS0p162pbeCsm2dRGMlj152ijB1azpjKcsZWljN2aDkjBpWoc52I9Dsq6NLv7FxexC/P3I/3lm9k3rKNzF6wlgdeX9q2vrQwwh6V5YytLAsK/dCg2O9UXqTJY0Skz8paQTezKcD1QAT4o7v/tIPtDgBmAZ9393uylU/6j4JIHqftP3KrZRvqG3l/eQ3zlm/kvWUbmbd8I/96dwV3za5u22ZQaQFjdi5nzNAyxlaWtxX7QaW6wI2I5L6sFHQziwA3AMcA1cArZvagu7+dYrufAY9nI5f0bZ3N0d7egOICJowezITRW18zflXNZuYljuTfSxT8B15bysakoXE7lxdt1Ww/Zmg5e+xcRrRo2/8+q2s2U9fQDKjnvYhkV7aO0A8EPnD3jwDMbDpwMvB2u+2+DvwdOCBLuaQP62qO9nTEyoqIlRVxyG6xtmXuzsfr64NCv3wj7y0LCv3tLy2kvnHLeftRQ0q2OpIfU1lOWVE+h/18xjavo573ItLbzN17/0XMTgemuPuFicfnAge5+9eSthkB/A04CrgFeChVk7uZTQWmAlRWVk6YPn16xnLW1NRQVlaWsf1lgjKlJxuZWtxZWedU17SwpKaF6o3Bz2W1TnPiv9H0qZNSDqX7x1cncd/Tr1IYMYoiUBQxCvOgMELbstafESOj5/J32eOTNFvw3d3d2/Yd8SYWvd/+O3X27ai/T92lTF3LtTzQO5kmT548x90ntl+erSP0VH+d2n+T+DVwhbs3d/bHzN1vBm4GmDhxovfkqKwjM2fO7NFRXm9SpvSEmamhqYX5q2p5b/lGyotT/5eqbYRb5zaktb9InlFSEKG4IEJpYSS4XxihpCCPkoIIpYX5FBdEKCkMHpcURCgpzA/WFwbPa92upDAPCgs55n+f3uZ1nv325Jz4d9TvU3qUqWu5lgeymylbBb0aGJX0eCSwtN02E4HpiWIeA04wsyZ3vz8rCUV6qDA/L+gpP7S87Zx5e8MGFvPcFZOpb2xmU0MLdQ1NbGpsDh4nlgU/m7Z6HGzfTF1jM/UNzayqaWBT4yY2NQTr6hqC53dm+tRJKZcvW1/PhX+eTXlxfuJWsNXPASmWtd0vyt+uoX/qayCSedkq6K8Ae5hZFbAEOAs4O3kDd69qvW9m0wia3O/PUj6RXpVnxsjBpb2yb3dnc1MLmxLFfVPiS0Drz4oOpqEtKsgjHitlY30Tq2oamL+qlo31TWysb6KhgzH+ycqK8jv8MhB8IUj6ElC09Xp35/DrZm6zzzD7GuTilwxl6nt5wsyUlYLu7k1m9jWC3usR4FZ3f8vMLkqsvykbOUR6W3d63meKmVGcaKIfnGJ9R60Gg0sL+f2525yGA6C+sTlR3Bvbinzr/Q0plm3c3Mia2gYWrq5jY30jG+qbaGjq+EtBR60GyzfU8+U/v0J+Xh4FESM/EvwsiOSRnxf8LIjkkR8x8vPyKMwPfuZHjMKtlgfbd/b8gsS2BYltBkcLOTrFqYmZlx9JXUMzZsEXs/Y/gxsYhuXR9jgvceow+bF1s39EXUNzznWyzLVMuZYHwsuUtXHo7v4I8Ei7ZSkLubufn41MIpmWiZ73uaD1C8JO5T0/mtjc1Lxt4U8U+4ElBSmfUxDJY7edymhsdppaWmhsbqGx2and3ERjs9PY3EJTS+Jn8uOmFhpbgmVNLT3r6NvhqYkN9Sk7OvaUWdCpqPXLQMdfFOD3505IuY+P19dzxk0v0vrdwNj6i0Lb8rb1lnLbtmfYlvtmlnR/2+dfe8reKTOt2FjPV26bs9XzUr33lMtTdrPq6jmB731mrw7ybOZrd7zW4X7b76c7uvpO9t0TP9mDvW4/XSlOpJ8Lo9UAoCg/QlFZhFiKJsaOWg2GRAu58Yupi1i63H3LF4Imbyv0wZeDLV8IGpudpsTPxuaWDk9NDC4t5Bdn7EeLO+5Oi5O4z1aPWxKPPelxS2IUUUtL8vMS27L1vlpaHCfpsTslBan/jYoL8jh8TCzxfrf0MPbEfoMHW360jmbyxDZJq4PMbR/elue3bdduWUfzI0Ty8hg+qIRt+ztv2U/K5akXt2Xr6jkddeXIMxjUwRfHdF67u5mShXXBSRV0kX6uv7QapMvMKMw3CsmDblzkr6MvGaWFEU6fMDLlut7W2emSn5++X5bTBDrKVBEt5I/npT6F05s6yhMrK+LP/3FgltMEOsrU21TQRSTrwmo1EOnPVNBFJOtysdUgF79kKFPfyxNmJk0WLSJC8CVj1JBSRg0pZcm8N9ruhzkuXpn6Xp4wM6mgi4iI9AMq6CIiIv2ACrqIiEg/oIIuIiLSD6igi4iI9AMq6CIiIv2ACrqIiEg/oIIuIiLSD6igi4iI9AMq6CIiIv2ApTMVXK4ys5XAwgzuMgasyuD+MkGZ0qNM6VGm9ChTenItU67lgd7JNNrdd2q/sE8X9Ewzs9nunv35/zqhTOlRpvQoU3qUKT25linX8kB2M6nJXUREpB9QQRcREekHVNC3dnPYAVJQpvQoU3qUKT3KlJ5cy5RreSCLmXQOXUREpB/QEbqIiEg/oIIOmNmtZrbCzOaGnaWVmY0ysxlm9o6ZvWVml+ZApmIze9nM/p3I9P2wMwGYWcTMXjOzh8LO0srMFpjZm2b2upnNDjsPgJkNMrN7zOzdxO/VwSFmGZv4bFpvG8zsG2HlScp1WeJ3e66Z3WFmxTmQ6dJEnrfC+oxS/Y00syFm9qSZvZ/4OTgHMp2R+JxazCzrvd07yHRd4v/cG2Z2n5kN6q3XV0EPTAOmhB2inSbgm+7+CWAS8FUz+2TImTYDR7n7fsA4YIqZTQo3EgCXAu+EHSKFye4+LoeG0VwPPObuewL7EeJn5u7vJT6bccAEoA64L6w8AGY2ArgEmOjuewMR4KyQM+0N/CdwIMG/2UlmtkcIUaax7d/IK4Gn3H0P4KnE47AzzQVOA57JcpZW09g205PA3u6+LzAPuKq3XlwFHXD3Z4A1YedI5u4fu/urifsbCf74jgg5k7t7TeJhQeIWaicMMxsJnAj8Mcwcuc7MBgCHA7cAuHuDu68LNdQWRwMfunsmLxLVU/lAiZnlA6XA0pDzfAKY5e517t4EPA2cmu0QHfyNPBn4c+L+n4FTws7k7u+4+3vZzNHu9VNleiLxbwcwCxjZW6+vgt4HmFkcGA+8FHKU1ubt14EVwJPuHnamXwPfBlpCztGeA0+Y2Rwzmxp2GGBXYCXwp8TpiT+aWTTsUAlnAXeEHcLdlwC/ABYBHwPr3f2JcFMxFzjczCrMrBQ4ARgVcqZWle7+MQQHIMDOIefpC/4DeLS3dq6CnuPMrAz4O/ANd98Qdh53b040k44EDkw0CYbCzE4CVrj7nLAydOJQd98fOJ7gdMnhIefJB/YHbnT38UAt2W8i3YaZFQKfBe7OgSyDCY46q4DhQNTMvhhmJnd/B/gZQbPtY8C/CU7HSR9jZv9D8G93e2+9hgp6DjOzAoJifru73xt2nmSJ5tqZhNv34FDgs2a2AJgOHGVmfw0xTxt3X5r4uYLg3PCB4SaiGqhOalG5h6DAh+144FV3Xx52EODTwHx3X+nujcC9wCEhZ8Ldb3H3/d39cILm3PfDzpSw3MyGASR+rgg5T84ys/OAk4BzvBfHiqug5ygzM4Lzne+4+y/DzgNgZju19tA0sxKCP4DvhpXH3a9y95HuHidotv2Xu4d6RAVgZlEzK2+9DxxL0HQaGndfBiw2s7GJRUcDb4cYqdUXyIHm9oRFwCQzK038/zuaHOhsaWY7J37uQtDhK1c+rweB8xL3zwMeCDFLzjKzKcAVwGfdva43Xyu/N3feV5jZHcCRQMzMqoGr3f2WcFNxKHAu8GbinDXAd9z9kfAiMQz4s5lFCL4M3uXuOTNULIdUAvcFNYF84G/u/li4kQD4OnB7opn7I+CCMMMkzgkfA3wlzByt3P0lM7sHeJWgafQ1cuPKY383swqgEfiqu6/NdoBUfyOBnwJ3mdmXCb4MnZEDmdYA/wfsBDxsZq+7+3EhZ7oKKAKeTPxNmOXuF/XK6+tKcSIiIn2fmtxFRET6ARV0ERGRfkAFXUREpB9QQRcREekHVNBFRET6ARV0Eel1Zna+mX0Qdg6R/kwFXWQHYmYzzWyzmdW0u+0TdjYR2T4q6CI7nh+6e1m725thhxKR7aOCLiJA29H7r83socRR+1tmdny7bf7LzN4zs/VmNsvMDmu3/jQzm51Yv8zMftRu/SVmVm1ma83s94mrDopIBqigi0iyLwPXA4OAHxNcwjYOYGZfAH4IfAmoAP4APGZmoxPrjyeYF/uaxPoxbD1V5GiCy+LuBhxAcKnQs3r5/YjsMFTQRXY8/2Nm65JvSevud/cn3b3J3W8HZgNnJ9ZdAPze3V9KrL8FeCNp/deBm9z9ocT6De7+XNK+NwHfc/fN7v4B8BQwsTffqMiORAVdZMfzI3cflHxLWreg3bYLgJGJ+6MIJnVJ9mFiOUAcmNfJ665w9+akx7VAefqxRaQzKugikiye4nF14v5ioKrd+l0TyyEo/nv0Ui4R6YIKuogkO8XMjjazSOKc+QHA9MS6acBXzOxAM8s3s/OBcWyZn/sG4CIzOz6xfoCZHZrl/CI7LBV0kR3Pd1OMQz8pse4W4L+B9cD3gNPc/SMAd/8b8H3gr8Bq4GLgBHdfkFj/MHAhQWe6NcB7wJTsvS2RHZvmQxcRIBi2BvzT3a8NO4uIdJ+O0EVERPoBFXQREZF+QE3uIiIi/YCO0EVERPoBFXQREZF+QAVdRESkH1BBFxER6QdU0EVERPoBFXQREZF+4P8DD40vkQ8uMH8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 297 ms\n"
     ]
    }
   ],
   "source": [
    "def plot_loss(log_data):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    #fig.add_subplot(1, 2, 1)\n",
    "    sns.lineplot(x='epoch', y='root_mean_squared_error', data=log_data, marker='s', label='train_loss');\n",
    "    sns.lineplot(x='epoch', y='val_root_mean_squared_error', data=log_data, marker='s', label='val_loss');\n",
    "    plt.xlabel('Epoch', size=13)\n",
    "    plt.xticks(np.arange(1, log_data['epoch'].max()+1, step=1))\n",
    "    plt.ylabel('Error [speed]', size=13)\n",
    "    plt.legend()\n",
    "    plt.title('Learning-curve', size=15, y=1.02)\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_loss(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 266 ms\n"
     ]
    }
   ],
   "source": [
    "def plot_r2(log_data):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    #fig.add_subplot(1, 2, 1)\n",
    "    sns.lineplot(x='epoch', y='my_r2_score', data=log_data, marker='s', label='train_score');\n",
    "    sns.lineplot(x='epoch', y='val_my_r2_score', data=log_data, marker='s', label='val_score');\n",
    "    plt.xlabel('Epoch', size=13)\n",
    "    plt.xticks(np.arange(1, log_data['epoch'].max()+1, step=1))\n",
    "    plt.ylabel('rate', size=13)\n",
    "    plt.legend()\n",
    "    plt.title('Score-curve', size=15, y=1.02)\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_r2(log_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tune parameter\n",
    "- Điều chỉnh các siêu tham số bằng phương pháp BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 266 ms\n"
     ]
    }
   ],
   "source": [
    "from kerastuner.tuners.bayesian import BayesianOptimization\n",
    "from kerastuner import HyperModel\n",
    "\n",
    "class RegressionHyperModel(HyperModel):\n",
    "    \n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=hp.Int('units', 100, 300, 5, default=100),\n",
    "                activation=hp.Choice(\n",
    "                    'activation',\n",
    "                    values=['sigmoid', 'tanh'],\n",
    "                    default='sigmoid'),\n",
    "                kernel_initializer='he_normal',\n",
    "                input_shape=self.input_shape\n",
    "            )\n",
    "        )\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "                                           optimizer=Optimizer.Adam(0.01)) \n",
    "        return model\n",
    "    \n",
    "class MyTuner(BayesianOptimization):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        kwargs['batch_size'] = trial.hyperparameters.Int('batch_size', 16, 128, step=16)\n",
    "        #kwargs['epochs'] = trial.hyperparameters.Int('epochs', 10, 20, 5)\n",
    "        super(MyTuner, self).run_trial(trial, *args, **kwargs)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 11m 14s]\n",
      "val_loss: 0.9532705247402191\n",
      "\n",
      "Best val_loss So Far: 0.8536230027675629\n",
      "Total elapsed time: 01h 38m 13s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "time: 1h 38min 13s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape = (X_train.shape[1], )\n",
    "hypermodel = RegressionHyperModel(input_shape)\n",
    "project_name = 'balance_search'\n",
    "\n",
    "tuner = MyTuner(\n",
    "            hypermodel,\n",
    "            objective='val_loss',\n",
    "            max_trials=10,\n",
    "            executions_per_trial=2,\n",
    "            seed=42,\n",
    "            project_name=project_name,\n",
    "            overwrite=True\n",
    "            )\n",
    "tuner.search(X_train, y_train, validation_data=(X_test, y_test), epochs=15, callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=3)], verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các bộ tham số tốt nhất\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>activation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>sigmoid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  batch_size activation\n",
       "0    280          32       relu\n",
       "1    290          32       relu\n",
       "2    110          80    sigmoid"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "list_best_hp = tuner.get_best_hyperparameters(num_trials=3)\n",
    "list_best_units = []\n",
    "list_best_batch_size = []\n",
    "list_best_activation = []\n",
    "\n",
    "for best_hp in list_best_hp:\n",
    "    best_units = best_hp.get('units')\n",
    "    list_best_units.append(best_units)\n",
    "    best_batch_size = best_hp.get('batch_size')\n",
    "    list_best_batch_size.append(best_batch_size)\n",
    "    best_activation = best_hp.get('activation')\n",
    "    list_best_activation.append(best_activation)\n",
    "\n",
    "hp_result = pd.DataFrame({'units':list_best_units,\n",
    "                            'batch_size': list_best_batch_size,\n",
    "                            'activation': list_best_activation\n",
    "                            })\n",
    "print('Các bộ tham số tốt nhất')\n",
    "hp_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <span style=\"color:blue\">Phương pháp:\n",
    "    - Ta train lại 3 mô hình tốt nhất để đánh giá\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "    2/30000 [..............................] - ETA: 28:35:20 - loss: 2920.6211 - root_mean_squared_error: 54.0428 - my_r2_score: -365.6091WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 6.8568s). Check your callbacks.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 1.0802 - root_mean_squared_error: 1.0393 - my_r2_score: 0.3657- ETA: 4s - loss: 1.2125 - root_\n",
      "my_val_loss [1.0801670551300049, 1.0393108129501343, 0.365707665681839]\n",
      "30000/30000 [==============================] - 77s 3ms/step - loss: 1.1616 - root_mean_squared_error: 1.0778 - my_r2_score: 0.8265 - val_loss: 1.0802 - val_root_mean_squared_error: 1.0393 - val_my_r2_score: 0.3657\n",
      "Epoch 2/15\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 0.9481 - root_mean_squared_error: 0.9737 - my_r2_score: 0.4456\n",
      "my_val_loss [0.9481135010719299, 0.9737111926078796, 0.44560906291007996]\n",
      "30000/30000 [==============================] - 64s 2ms/step - loss: 0.3680 - root_mean_squared_error: 0.6066 - my_r2_score: 0.9453 - val_loss: 0.9481 - val_root_mean_squared_error: 0.9737 - val_my_r2_score: 0.4456\n",
      "Epoch 3/15\n",
      "29993/30000 [============================>.] - ETA: 0s - loss: 0.3372 - root_mean_squared_error: 0.5807 - my_r2_score: 0.9498\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0029999999329447745.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 1.1875 - root_mean_squared_error: 1.0897 - my_r2_score: 0.2936\n",
      "my_val_loss [1.1875115633010864, 1.0897300243377686, 0.2936049699783325]\n",
      "30000/30000 [==============================] - 64s 2ms/step - loss: 0.3372 - root_mean_squared_error: 0.5807 - my_r2_score: 0.9498 - val_loss: 1.1875 - val_root_mean_squared_error: 1.0897 - val_my_r2_score: 0.2936\n",
      "Epoch 4/15\n",
      "29985/30000 [============================>.] - ETA: 0s - loss: 0.2671 - root_mean_squared_error: 0.5168 - my_r2_score: 0.9604\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009000000078231095.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 0.9634 - root_mean_squared_error: 0.9815 - my_r2_score: 0.4477\n",
      "my_val_loss [0.963383138179779, 0.9815208315849304, 0.44770485162734985]\n",
      "30000/30000 [==============================] - 60s 2ms/step - loss: 0.2671 - root_mean_squared_error: 0.5168 - my_r2_score: 0.9604 - val_loss: 0.9634 - val_root_mean_squared_error: 0.9815 - val_my_r2_score: 0.4477\n",
      "Epoch 5/15\n",
      "29996/30000 [============================>.] - ETA: 0s - loss: 0.2478 - root_mean_squared_error: 0.4978 - my_r2_score: 0.9632\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00026999999536201356.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 1.0300 - root_mean_squared_error: 1.0149 - my_r2_score: 0.3950\n",
      "my_val_loss [1.030026912689209, 1.0149024724960327, 0.3949534296989441]\n",
      "30000/30000 [==============================] - 61s 2ms/step - loss: 0.2478 - root_mean_squared_error: 0.4978 - my_r2_score: 0.9632 - val_loss: 1.0300 - val_root_mean_squared_error: 1.0149 - val_my_r2_score: 0.3950\n",
      "Epoch 6/15\n",
      "29982/30000 [============================>.] - ETA: 0s - loss: 0.2413 - root_mean_squared_error: 0.4913 - my_r2_score: 0.9642\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 8.099999686237424e-05.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 0.9637 - root_mean_squared_error: 0.9817 - my_r2_score: 0.4412\n",
      "my_val_loss [0.9637491106987, 0.9817072153091431, 0.4412423074245453]\n",
      "30000/30000 [==============================] - 61s 2ms/step - loss: 0.2413 - root_mean_squared_error: 0.4912 - my_r2_score: 0.9642 - val_loss: 0.9637 - val_root_mean_squared_error: 0.9817 - val_my_r2_score: 0.4412\n",
      "Epoch 7/15\n",
      "29999/30000 [============================>.] - ETA: 0s - loss: 0.2392 - root_mean_squared_error: 0.4891 - my_r2_score: 0.9646\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-05.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 1.0034 - root_mean_squared_error: 1.0017 - my_r2_score: 0.4136\n",
      "my_val_loss [1.0034464597702026, 1.001721739768982, 0.4136286973953247]\n",
      "30000/30000 [==============================] - 64s 2ms/step - loss: 0.2392 - root_mean_squared_error: 0.4891 - my_r2_score: 0.9646 - val_loss: 1.0034 - val_root_mean_squared_error: 1.0017 - val_my_r2_score: 0.4136\n",
      "Epoch 8/15\n",
      "29992/30000 [============================>.] - ETA: 0s - loss: 0.2385 - root_mean_squared_error: 0.4884 - my_r2_score: 0.9646\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 7.289999848580919e-06.\n",
      "  1/599 [..............................] - ETA: 0s - loss: 0.7739 - root_mean_squared_error: 0.8797 - my_r2_score: -0.3837WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0020s). Check your callbacks.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 1.0177 - root_mean_squared_error: 1.0088 - my_r2_score: 0.4045\n",
      "my_val_loss [1.017685055732727, 1.0088037252426147, 0.4044897258281708]\n",
      "30000/30000 [==============================] - 64s 2ms/step - loss: 0.2386 - root_mean_squared_error: 0.4884 - my_r2_score: 0.9646 - val_loss: 1.0177 - val_root_mean_squared_error: 1.0088 - val_my_r2_score: 0.4045\n",
      "Epoch 9/15\n",
      "29986/30000 [============================>.] - ETA: 0s - loss: 0.2383 - root_mean_squared_error: 0.4882 - my_r2_score: 0.9646\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.186999927289435e-06.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 1.0088 - root_mean_squared_error: 1.0044 - my_r2_score: 0.4103\n",
      "my_val_loss [1.0087883472442627, 1.0043845176696777, 0.4103235602378845]\n",
      "30000/30000 [==============================] - 64s 2ms/step - loss: 0.2383 - root_mean_squared_error: 0.4882 - my_r2_score: 0.9646 - val_loss: 1.0088 - val_root_mean_squared_error: 1.0044 - val_my_r2_score: 0.4103\n",
      "Epoch 00009: early stopping\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 0.9481 - root_mean_squared_error: 0.9737 - my_r2_score: 0.4456\n",
      "Epoch 1/15\n",
      "    2/30000 [..............................] - ETA: 3:46:34 - loss: 2807.7415 - root_mean_squared_error: 52.9881 - my_r2_score: -303.2925WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.9013s). Check your callbacks.\n",
      "29997/30000 [============================>.] - ETA: 0s - loss: 1.1430 - root_mean_squared_error: 1.0691 - my_r2_score: 0.8473WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0020s). Check your callbacks.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 1.0799 - root_mean_squared_error: 1.0392 - my_r2_score: 0.3783\n",
      "my_val_loss [1.0799412727355957, 1.0392022132873535, 0.3782689571380615]\n",
      "30000/30000 [==============================] - 65s 2ms/step - loss: 1.1429 - root_mean_squared_error: 1.0691 - my_r2_score: 0.8473 - val_loss: 1.0799 - val_root_mean_squared_error: 1.0392 - val_my_r2_score: 0.3783\n",
      "Epoch 2/15\n",
      "  1/599 [..............................] - ETA: 0s - loss: 0.5928 - root_mean_squared_error: 0.7699 - my_r2_score: -0.0599443WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0020s). Check your callbacks.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 0.8808 - root_mean_squared_error: 0.9385 - my_r2_score: 0.4817\n",
      "my_val_loss [0.8807659149169922, 0.9384912848472595, 0.48169419169425964]\n",
      "30000/30000 [==============================] - 64s 2ms/step - loss: 0.3739 - root_mean_squared_error: 0.6115 - my_r2_score: 0.9443 - val_loss: 0.8808 - val_root_mean_squared_error: 0.9385 - val_my_r2_score: 0.4817\n",
      "Epoch 3/15\n",
      "29992/30000 [============================>.] - ETA: 0s - loss: 0.3294 - root_mean_squared_error: 0.5739 - my_r2_score: 0.9510\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0029999999329447745.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 1.0907 - root_mean_squared_error: 1.0444 - my_r2_score: 0.3686\n",
      "my_val_loss [1.0906720161437988, 1.044352412223816, 0.36856353282928467]\n",
      "30000/30000 [==============================] - 64s 2ms/step - loss: 0.3294 - root_mean_squared_error: 0.5739 - my_r2_score: 0.9510 - val_loss: 1.0907 - val_root_mean_squared_error: 1.0444 - val_my_r2_score: 0.3686\n",
      "Epoch 4/15\n",
      "29987/30000 [============================>.] - ETA: 0s - loss: 0.2648 - root_mean_squared_error: 0.5146 - my_r2_score: 0.9607\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009000000078231095.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 0.9967 - root_mean_squared_error: 0.9984 - my_r2_score: 0.4189\n",
      "my_val_loss [0.9967419505119324, 0.9983696341514587, 0.4188765585422516]\n",
      "30000/30000 [==============================] - 63s 2ms/step - loss: 0.2648 - root_mean_squared_error: 0.5146 - my_r2_score: 0.9607 - val_loss: 0.9967 - val_root_mean_squared_error: 0.9984 - val_my_r2_score: 0.4189\n",
      "Epoch 5/15\n",
      "29989/30000 [============================>.] - ETA: 0s - loss: 0.2479 - root_mean_squared_error: 0.4978 - my_r2_score: 0.9632\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00026999999536201356.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 0.9288 - root_mean_squared_error: 0.9637 - my_r2_score: 0.4626\n",
      "my_val_loss [0.9288061857223511, 0.9637458920478821, 0.46263378858566284]\n",
      "30000/30000 [==============================] - 61s 2ms/step - loss: 0.2478 - root_mean_squared_error: 0.4978 - my_r2_score: 0.9632 - val_loss: 0.9288 - val_root_mean_squared_error: 0.9637 - val_my_r2_score: 0.4626\n",
      "Epoch 6/15\n",
      "29990/30000 [============================>.] - ETA: 0s - loss: 0.2426 - root_mean_squared_error: 0.4925 - my_r2_score: 0.9640\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 8.099999686237424e-05.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 0.9664 - root_mean_squared_error: 0.9831 - my_r2_score: 0.4362\n",
      "my_val_loss [0.9663946032524109, 0.9830536842346191, 0.4362383484840393]\n",
      "30000/30000 [==============================] - 58s 2ms/step - loss: 0.2426 - root_mean_squared_error: 0.4925 - my_r2_score: 0.9640 - val_loss: 0.9664 - val_root_mean_squared_error: 0.9831 - val_my_r2_score: 0.4362\n",
      "Epoch 7/15\n",
      "29991/30000 [============================>.] - ETA: 0s - loss: 0.2408 - root_mean_squared_error: 0.4907 - my_r2_score: 0.9643\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-05.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 0.9644 - root_mean_squared_error: 0.9820 - my_r2_score: 0.4389\n",
      "my_val_loss [0.9643541574478149, 0.9820153713226318, 0.4388806223869324]\n",
      "30000/30000 [==============================] - 62s 2ms/step - loss: 0.2408 - root_mean_squared_error: 0.4907 - my_r2_score: 0.9643 - val_loss: 0.9644 - val_root_mean_squared_error: 0.9820 - val_my_r2_score: 0.4389\n",
      "Epoch 8/15\n",
      "29980/30000 [============================>.] - ETA: 0s - loss: 0.2403 - root_mean_squared_error: 0.4902 - my_r2_score: 0.9644\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 7.289999848580919e-06.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 0.9308 - root_mean_squared_error: 0.9648 - my_r2_score: 0.4594\n",
      "my_val_loss [0.9308156371116638, 0.9647879004478455, 0.4594147205352783]\n",
      "30000/30000 [==============================] - 64s 2ms/step - loss: 0.2403 - root_mean_squared_error: 0.4902 - my_r2_score: 0.9644 - val_loss: 0.9308 - val_root_mean_squared_error: 0.9648 - val_my_r2_score: 0.4594\n",
      "Epoch 9/15\n",
      "29993/30000 [============================>.] - ETA: 0s - loss: 0.2401 - root_mean_squared_error: 0.4900 - my_r2_score: 0.9644\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.186999927289435e-06.\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 0.9346 - root_mean_squared_error: 0.9667 - my_r2_score: 0.4575\n",
      "my_val_loss [0.9345729351043701, 0.9667330980300903, 0.45754048228263855]\n",
      "30000/30000 [==============================] - 64s 2ms/step - loss: 0.2401 - root_mean_squared_error: 0.4900 - my_r2_score: 0.9644 - val_loss: 0.9346 - val_root_mean_squared_error: 0.9667 - val_my_r2_score: 0.4575\n",
      "Epoch 00009: early stopping\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 0.8808 - root_mean_squared_error: 0.9385 - my_r2_score: 0.4817\n",
      "Epoch 1/15\n",
      "    2/12000 [..............................] - ETA: 2:05:04 - loss: 2979.3093 - root_mean_squared_error: 54.5830 - my_r2_score: -384.6497WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 1.2460s). Check your callbacks.\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0067 - root_mean_squared_error: 1.0033 - my_r2_score: 0.6823\n",
      "my_val_loss [1.006657361984253, 1.0033231973648071, 0.6822980642318726]\n",
      "12000/12000 [==============================] - 28s 2ms/step - loss: 5.8385 - root_mean_squared_error: 2.4163 - my_r2_score: 0.1789 - val_loss: 1.0067 - val_root_mean_squared_error: 1.0033 - val_my_r2_score: 0.6823\n",
      "Epoch 2/15\n",
      "11988/12000 [============================>.] - ETA: 0s - loss: 0.2371 - root_mean_squared_error: 0.4869 - my_r2_score: 0.9665\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.0029999999329447745.\n",
      "  1/240 [..............................] - ETA: 0s - loss: 1.1055 - root_mean_squared_error: 1.0514 - my_r2_score: 0.6726WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0020s). Check your callbacks.\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1866 - root_mean_squared_error: 1.0893 - my_r2_score: 0.6255\n",
      "my_val_loss [1.1865735054016113, 1.0892995595932007, 0.6255187392234802]\n",
      "12000/12000 [==============================] - 26s 2ms/step - loss: 0.2371 - root_mean_squared_error: 0.4869 - my_r2_score: 0.9665 - val_loss: 1.1866 - val_root_mean_squared_error: 1.0893 - val_my_r2_score: 0.6255\n",
      "Epoch 3/15\n",
      "11981/12000 [============================>.] - ETA: 0s - loss: 0.1835 - root_mean_squared_error: 0.4284 - my_r2_score: 0.9741\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0009000000078231095.\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0242 - root_mean_squared_error: 1.0120 - my_r2_score: 0.6803\n",
      "my_val_loss [1.0242422819137573, 1.012048602104187, 0.6803005933761597]\n",
      "12000/12000 [==============================] - 26s 2ms/step - loss: 0.1835 - root_mean_squared_error: 0.4284 - my_r2_score: 0.9741 - val_loss: 1.0242 - val_root_mean_squared_error: 1.0120 - val_my_r2_score: 0.6803\n",
      "Epoch 4/15\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9970 - root_mean_squared_error: 0.9985 - my_r2_score: 0.6888\n",
      "my_val_loss [0.9969980120658875, 0.9984979033470154, 0.6887843012809753]\n",
      "12000/12000 [==============================] - 26s 2ms/step - loss: 0.1667 - root_mean_squared_error: 0.4083 - my_r2_score: 0.9765 - val_loss: 0.9970 - val_root_mean_squared_error: 0.9985 - val_my_r2_score: 0.6888\n",
      "Epoch 5/15\n",
      "11996/12000 [============================>.] - ETA: 0s - loss: 0.1632 - root_mean_squared_error: 0.4039 - my_r2_score: 0.9770\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00026999999536201356.\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0114 - root_mean_squared_error: 1.0057 - my_r2_score: 0.6851\n",
      "my_val_loss [1.0114083290100098, 1.005687952041626, 0.68509441614151]\n",
      "12000/12000 [==============================] - 26s 2ms/step - loss: 0.1632 - root_mean_squared_error: 0.4039 - my_r2_score: 0.9770 - val_loss: 1.0114 - val_root_mean_squared_error: 1.0057 - val_my_r2_score: 0.6851\n",
      "Epoch 6/15\n",
      "11996/12000 [============================>.] - ETA: 0s - loss: 0.1586 - root_mean_squared_error: 0.3983 - my_r2_score: 0.9776\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 8.099999686237424e-05.\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0005 - root_mean_squared_error: 1.0002 - my_r2_score: 0.6881\n",
      "my_val_loss [1.0004799365997314, 1.0002399682998657, 0.688118040561676]\n",
      "12000/12000 [==============================] - 27s 2ms/step - loss: 0.1586 - root_mean_squared_error: 0.3983 - my_r2_score: 0.9776 - val_loss: 1.0005 - val_root_mean_squared_error: 1.0002 - val_my_r2_score: 0.6881\n",
      "Epoch 7/15\n",
      "11991/12000 [============================>.] - ETA: 0s - loss: 0.1570 - root_mean_squared_error: 0.3963 - my_r2_score: 0.9779\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-05.\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0130 - root_mean_squared_error: 1.0065 - my_r2_score: 0.6843\n",
      "my_val_loss [1.0130107402801514, 1.0064843893051147, 0.6842746138572693]\n",
      "12000/12000 [==============================] - 28s 2ms/step - loss: 0.1570 - root_mean_squared_error: 0.3963 - my_r2_score: 0.9779 - val_loss: 1.0130 - val_root_mean_squared_error: 1.0065 - val_my_r2_score: 0.6843\n",
      "Epoch 8/15\n",
      "11988/12000 [============================>.] - ETA: 0s - loss: 0.1565 - root_mean_squared_error: 0.3956 - my_r2_score: 0.9779\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 7.289999848580919e-06.\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9997 - root_mean_squared_error: 0.9999 - my_r2_score: 0.6885\n",
      "my_val_loss [0.9997448325157166, 0.9998723864555359, 0.6884920001029968]\n",
      "12000/12000 [==============================] - 27s 2ms/step - loss: 0.1565 - root_mean_squared_error: 0.3956 - my_r2_score: 0.9779 - val_loss: 0.9997 - val_root_mean_squared_error: 0.9999 - val_my_r2_score: 0.6885\n",
      "Epoch 9/15\n",
      "11992/12000 [============================>.] - ETA: 0s - loss: 0.1564 - root_mean_squared_error: 0.3954 - my_r2_score: 0.9780\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.186999927289435e-06.\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0106 - root_mean_squared_error: 1.0053 - my_r2_score: 0.6850\n",
      "my_val_loss [1.010589838027954, 1.0052809715270996, 0.6849899291992188]\n",
      "12000/12000 [==============================] - 26s 2ms/step - loss: 0.1564 - root_mean_squared_error: 0.3954 - my_r2_score: 0.9780 - val_loss: 1.0106 - val_root_mean_squared_error: 1.0053 - val_my_r2_score: 0.6850\n",
      "Epoch 10/15\n",
      "11991/12000 [============================>.] - ETA: 0s - loss: 0.1563 - root_mean_squared_error: 0.3954 - my_r2_score: 0.9780\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.560999509019894e-07.\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0109 - root_mean_squared_error: 1.0054 - my_r2_score: 0.6849\n",
      "my_val_loss [1.010884404182434, 1.0054274797439575, 0.6849079728126526]\n",
      "12000/12000 [==============================] - 26s 2ms/step - loss: 0.1563 - root_mean_squared_error: 0.3954 - my_r2_score: 0.9780 - val_loss: 1.0109 - val_root_mean_squared_error: 1.0054 - val_my_r2_score: 0.6849\n",
      "Epoch 11/15\n",
      "11983/12000 [============================>.] - ETA: 0s - loss: 0.1563 - root_mean_squared_error: 0.3954 - my_r2_score: 0.9780\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.9682997844938655e-07.\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0124 - root_mean_squared_error: 1.0062 - my_r2_score: 0.6844\n",
      "my_val_loss [1.0124176740646362, 1.0061897039413452, 0.684411346912384]\n",
      "12000/12000 [==============================] - 26s 2ms/step - loss: 0.1563 - root_mean_squared_error: 0.3954 - my_r2_score: 0.9780 - val_loss: 1.0124 - val_root_mean_squared_error: 1.0062 - val_my_r2_score: 0.6844\n",
      "Epoch 00011: early stopping\n",
      "599/599 [==============================] - 1s 2ms/step - loss: 0.9970 - root_mean_squared_error: 0.9985 - my_r2_score: 0.4184\n",
      "time: 24min 8s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "list_val_loss = []\n",
    "for num_units, activation, batch_size in zip(list_best_units, list_best_activation, list_best_batch_size):\n",
    "    model = build_and_compile_model(X_train, num_units=num_units, activation=activation)\n",
    "    model = train_model(model, X_train, y_train, X_test, y_test, checkpoint_name, logdir,\n",
    "                        batch_size=batch_size, epochs=15, re_train=True)\n",
    "    val_loss, _, _ = model.evaluate(X_test, y_test)\n",
    "    list_val_loss.append(val_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>activation</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.948114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.880766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.996998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  batch_size activation  val_loss\n",
       "0    280          32       relu  0.948114\n",
       "1    290          32       relu  0.880766\n",
       "2    110          80    sigmoid  0.996998"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "filter_balance_result = pd.DataFrame({'units':list_best_units,\n",
    "                            'batch_size': list_best_batch_size,\n",
    "                            'activation': list_best_activation,\n",
    "                            'val_loss': list_val_loss})\n",
    "filter_balance_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms\n"
     ]
    }
   ],
   "source": [
    "# Save improve_result\n",
    "filter_balance_result.to_csv('filter_balance_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <span style=\"color:blue\">Ta chọn bộ tham số tốt nhất:\n",
    "    - units: 260\n",
    "    - batch_size: 112\n",
    "    - activation: tanh\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "   2/4037 [..............................] - ETA: 31:30 - loss: 3128.4944 - root_mean_squared_error: 55.9329 - my_r2_score: -629.3411WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.9320s). Check your callbacks.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.7660 - root_mean_squared_error: 0.8752 - my_r2_score: 0.7887\n",
      "my_val_loss [0.7659750580787659, 0.8751999735832214, 0.7887331247329712]\n",
      "4037/4037 [==============================] - 14s 3ms/step - loss: 5.7225 - root_mean_squared_error: 2.3922 - my_r2_score: -0.1578 - val_loss: 0.7660 - val_root_mean_squared_error: 0.8752 - val_my_r2_score: 0.7887\n",
      "Epoch 2/15\n",
      "4027/4037 [============================>.] - ETA: 0s - loss: 0.5017 - root_mean_squared_error: 0.7083 - my_r2_score: 0.8915\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.0029999999329447745.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.9387 - root_mean_squared_error: 0.9689 - my_r2_score: 0.7367\n",
      "my_val_loss [0.9387310743331909, 0.968881368637085, 0.7366563081741333]\n",
      "4037/4037 [==============================] - 12s 3ms/step - loss: 0.5017 - root_mean_squared_error: 0.7083 - my_r2_score: 0.8915 - val_loss: 0.9387 - val_root_mean_squared_error: 0.9689 - val_my_r2_score: 0.7367\n",
      "Epoch 3/15\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.7206 - root_mean_squared_error: 0.8489 - my_r2_score: 0.8030\n",
      "my_val_loss [0.7206396460533142, 0.8489049673080444, 0.8029960989952087]\n",
      "4037/4037 [==============================] - 12s 3ms/step - loss: 0.4448 - root_mean_squared_error: 0.6670 - my_r2_score: 0.9038 - val_loss: 0.7206 - val_root_mean_squared_error: 0.8489 - val_my_r2_score: 0.8030\n",
      "Epoch 4/15\n",
      "  1/171 [..............................] - ETA: 0s - loss: 1.2193 - root_mean_squared_error: 1.1042 - my_r2_score: 0.723661WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0020s). Check your callbacks.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.7133 - root_mean_squared_error: 0.8446 - my_r2_score: 0.8057\n",
      "my_val_loss [0.7132818698883057, 0.8445601463317871, 0.8056554198265076]\n",
      "4037/4037 [==============================] - 12s 3ms/step - loss: 0.4342 - root_mean_squared_error: 0.6589 - my_r2_score: 0.9060 - val_loss: 0.7133 - val_root_mean_squared_error: 0.8446 - val_my_r2_score: 0.8057\n",
      "Epoch 5/15\n",
      "4031/4037 [============================>.] - ETA: 0s - loss: 0.4233 - root_mean_squared_error: 0.6506 - my_r2_score: 0.9085\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0009000000078231095.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.7421 - root_mean_squared_error: 0.8615 - my_r2_score: 0.7961\n",
      "my_val_loss [0.7421233654022217, 0.8614658117294312, 0.7961270809173584]\n",
      "4037/4037 [==============================] - 12s 3ms/step - loss: 0.4233 - root_mean_squared_error: 0.6506 - my_r2_score: 0.9085 - val_loss: 0.7421 - val_root_mean_squared_error: 0.8615 - val_my_r2_score: 0.7961\n",
      "Epoch 6/15\n",
      "4029/4037 [============================>.] - ETA: 0s - loss: 0.3926 - root_mean_squared_error: 0.6266 - my_r2_score: 0.9150\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00026999999536201356.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.7463 - root_mean_squared_error: 0.8639 - my_r2_score: 0.7958\n",
      "my_val_loss [0.7462936639785767, 0.8638828992843628, 0.795833945274353]\n",
      "4037/4037 [==============================] - 12s 3ms/step - loss: 0.3927 - root_mean_squared_error: 0.6266 - my_r2_score: 0.9150 - val_loss: 0.7463 - val_root_mean_squared_error: 0.8639 - val_my_r2_score: 0.7958\n",
      "Epoch 7/15\n",
      "4031/4037 [============================>.] - ETA: 0s - loss: 0.3782 - root_mean_squared_error: 0.6150 - my_r2_score: 0.9182\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 8.099999686237424e-05.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.7467 - root_mean_squared_error: 0.8641 - my_r2_score: 0.7960\n",
      "my_val_loss [0.7467442154884338, 0.8641436100006104, 0.7960271835327148]\n",
      "4037/4037 [==============================] - 12s 3ms/step - loss: 0.3782 - root_mean_squared_error: 0.6149 - my_r2_score: 0.9182 - val_loss: 0.7467 - val_root_mean_squared_error: 0.8641 - val_my_r2_score: 0.7960\n",
      "Epoch 8/15\n",
      "4033/4037 [============================>.] - ETA: 0s - loss: 0.3732 - root_mean_squared_error: 0.6109 - my_r2_score: 0.9192\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-05.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.7433 - root_mean_squared_error: 0.8622 - my_r2_score: 0.7967\n",
      "my_val_loss [0.7433152198791504, 0.8621572852134705, 0.7966516613960266]\n",
      "4037/4037 [==============================] - 12s 3ms/step - loss: 0.3732 - root_mean_squared_error: 0.6109 - my_r2_score: 0.9192 - val_loss: 0.7433 - val_root_mean_squared_error: 0.8622 - val_my_r2_score: 0.7967\n",
      "Epoch 9/15\n",
      "4020/4037 [============================>.] - ETA: 0s - loss: 0.3715 - root_mean_squared_error: 0.6095 - my_r2_score: 0.9196\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 7.289999848580919e-06.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.7443 - root_mean_squared_error: 0.8627 - my_r2_score: 0.7964\n",
      "my_val_loss [0.7442680597305298, 0.8627097010612488, 0.7964337468147278]\n",
      "4037/4037 [==============================] - 12s 3ms/step - loss: 0.3715 - root_mean_squared_error: 0.6095 - my_r2_score: 0.9196 - val_loss: 0.7443 - val_root_mean_squared_error: 0.8627 - val_my_r2_score: 0.7964\n",
      "Epoch 10/15\n",
      "4035/4037 [============================>.] - ETA: 0s - loss: 0.3710 - root_mean_squared_error: 0.6091 - my_r2_score: 0.9197\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.186999927289435e-06.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.7432 - root_mean_squared_error: 0.8621 - my_r2_score: 0.7967\n",
      "my_val_loss [0.7431530356407166, 0.8620632290840149, 0.7966877818107605]\n",
      "4037/4037 [==============================] - 12s 3ms/step - loss: 0.3710 - root_mean_squared_error: 0.6091 - my_r2_score: 0.9197 - val_loss: 0.7432 - val_root_mean_squared_error: 0.8621 - val_my_r2_score: 0.7967\n",
      "Epoch 11/15\n",
      "4037/4037 [==============================] - ETA: 0s - loss: 0.3708 - root_mean_squared_error: 0.6090 - my_r2_score: 0.9198\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 6.560999509019894e-07.\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.7413 - root_mean_squared_error: 0.8610 - my_r2_score: 0.7972\n",
      "my_val_loss [0.7413409352302551, 0.8610115647315979, 0.7972034811973572]\n",
      "4037/4037 [==============================] - 12s 3ms/step - loss: 0.3708 - root_mean_squared_error: 0.6090 - my_r2_score: 0.9198 - val_loss: 0.7413 - val_root_mean_squared_error: 0.8610 - val_my_r2_score: 0.7972\n",
      "Epoch 00011: early stopping\n",
      "time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "model = build_and_compile_model(X_train, num_units=260, activation='tanh')\n",
    "model = train_model(model, X_train, y_train, X_test, y_test, checkpoint_name, logdir,\n",
    "                        batch_size=112, epochs=15, re_train=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sai số rmse:                    0.648\n",
      "Hệ số xác định r2-score: 0.912\n",
      "Tỉ lệ True positive:           0.418\n",
      "time: 25 s\n"
     ]
    }
   ],
   "source": [
    "# On train\n",
    "train_result_df = evaluate(model, X_train, y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sai số rmse:                    0.845\n",
      "Hệ số xác định r2-score: 0.866\n",
      "Tỉ lệ True positive:           0.385\n",
      "time: 453 ms\n"
     ]
    }
   ],
   "source": [
    "# On test\n",
    "test_result_df = evaluate(model, X_test, y_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>my_r2_score</th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_my_r2_score</th>\n",
       "      <th>val_root_mean_squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.722518</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-0.157803</td>\n",
       "      <td>2.392179</td>\n",
       "      <td>0.765975</td>\n",
       "      <td>0.788733</td>\n",
       "      <td>0.875200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.501720</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.891503</td>\n",
       "      <td>0.708322</td>\n",
       "      <td>0.938731</td>\n",
       "      <td>0.736656</td>\n",
       "      <td>0.968881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.444827</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.903845</td>\n",
       "      <td>0.666953</td>\n",
       "      <td>0.720640</td>\n",
       "      <td>0.802996</td>\n",
       "      <td>0.848905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.434201</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.906033</td>\n",
       "      <td>0.658939</td>\n",
       "      <td>0.713282</td>\n",
       "      <td>0.805655</td>\n",
       "      <td>0.844560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.423324</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.908467</td>\n",
       "      <td>0.650634</td>\n",
       "      <td>0.742123</td>\n",
       "      <td>0.796127</td>\n",
       "      <td>0.861466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.392653</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.915026</td>\n",
       "      <td>0.626620</td>\n",
       "      <td>0.746294</td>\n",
       "      <td>0.795834</td>\n",
       "      <td>0.863883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.378159</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.918240</td>\n",
       "      <td>0.614947</td>\n",
       "      <td>0.746744</td>\n",
       "      <td>0.796027</td>\n",
       "      <td>0.864144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.373227</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.919205</td>\n",
       "      <td>0.610923</td>\n",
       "      <td>0.743315</td>\n",
       "      <td>0.796652</td>\n",
       "      <td>0.862157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.371548</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.919621</td>\n",
       "      <td>0.609547</td>\n",
       "      <td>0.744268</td>\n",
       "      <td>0.796434</td>\n",
       "      <td>0.862710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.370996</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.919730</td>\n",
       "      <td>0.609094</td>\n",
       "      <td>0.743153</td>\n",
       "      <td>0.796688</td>\n",
       "      <td>0.862063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.370821</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.919810</td>\n",
       "      <td>0.608951</td>\n",
       "      <td>0.741341</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.861012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch      loss        lr  my_r2_score  root_mean_squared_error  val_loss  \\\n",
       "0       1  5.722518  0.010000    -0.157803                 2.392179  0.765975   \n",
       "1       2  0.501720  0.010000     0.891503                 0.708322  0.938731   \n",
       "2       3  0.444827  0.003000     0.903845                 0.666953  0.720640   \n",
       "3       4  0.434201  0.003000     0.906033                 0.658939  0.713282   \n",
       "4       5  0.423324  0.003000     0.908467                 0.650634  0.742123   \n",
       "5       6  0.392653  0.000900     0.915026                 0.626620  0.746294   \n",
       "6       7  0.378159  0.000270     0.918240                 0.614947  0.746744   \n",
       "7       8  0.373227  0.000081     0.919205                 0.610923  0.743315   \n",
       "8       9  0.371548  0.000024     0.919621                 0.609547  0.744268   \n",
       "9      10  0.370996  0.000007     0.919730                 0.609094  0.743153   \n",
       "10     11  0.370821  0.000002     0.919810                 0.608951  0.741341   \n",
       "\n",
       "    val_my_r2_score  val_root_mean_squared_error  \n",
       "0          0.788733                     0.875200  \n",
       "1          0.736656                     0.968881  \n",
       "2          0.802996                     0.848905  \n",
       "3          0.805655                     0.844560  \n",
       "4          0.796127                     0.861466  \n",
       "5          0.795834                     0.863883  \n",
       "6          0.796027                     0.864144  \n",
       "7          0.796652                     0.862157  \n",
       "8          0.796434                     0.862710  \n",
       "9          0.796688                     0.862063  \n",
       "10         0.797203                     0.861012  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "log_data = pd.read_csv('log.log')\n",
    "log_data['epoch'] = log_data['epoch'] + 1\n",
    "log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 344 ms\n"
     ]
    }
   ],
   "source": [
    "def plot_loss(log_data):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    #fig.add_subplot(1, 2, 1)\n",
    "    sns.lineplot(x='epoch', y='root_mean_squared_error', data=log_data, marker='s', label='train_loss');\n",
    "    sns.lineplot(x='epoch', y='val_root_mean_squared_error', data=log_data, marker='s', label='val_loss');\n",
    "    plt.xlabel('Epoch', size=13)\n",
    "    plt.xticks(np.arange(1, log_data['epoch'].max()+1, step=1))\n",
    "    plt.ylabel('Error [speed]', size=13)\n",
    "    plt.legend()\n",
    "    plt.title('Learning-curve', size=15, y=1.02)\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_loss(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 281 ms\n"
     ]
    }
   ],
   "source": [
    "def plot_r2(log_data):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    #fig.add_subplot(1, 2, 1)\n",
    "    sns.lineplot(x='epoch', y='my_r2_score', data=log_data, marker='s', label='train_score');\n",
    "    sns.lineplot(x='epoch', y='val_my_r2_score', data=log_data, marker='s', label='val_score');\n",
    "    plt.xlabel('Epoch', size=13)\n",
    "    plt.xticks(np.arange(1, log_data['epoch'].max()+1, step=1))\n",
    "    plt.ylabel('rate', size=13)\n",
    "    plt.legend()\n",
    "    plt.title('Score-curve', size=15, y=1.02)\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_r2(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
